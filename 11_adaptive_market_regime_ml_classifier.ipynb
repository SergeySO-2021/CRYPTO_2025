{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ñ –ê–î–ê–ü–¢–ò–í–ù–´–ô ML-–ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –†–´–ù–û–ß–ù–´–• –†–ï–ñ–ò–ú–û–í\n",
        "\n",
        "## üìã **–ù–ê–£–ß–ù–´–ô –ü–û–î–•–û–î –ö –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –†–´–ù–û–ß–ù–´–• –ó–û–ù**\n",
        "\n",
        "–≠—Ç–æ—Ç notebook —Ä–µ–∞–ª–∏–∑—É–µ—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:\n",
        "- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è** –±–µ–∑ —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏\n",
        "- **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã** –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä—ã–Ω–∫–∞\n",
        "- **ML-–º–æ–¥–µ–ª–∏** –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "- **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Ä–µ—à–µ–Ω–∏–π\n",
        "\n",
        "### üéØ **–ü–†–ò–ù–¶–ò–ü–´ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò:**\n",
        "\n",
        "#### **–°–∏–≥–Ω–∞–ª—å–Ω—ã–µ vs –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:**\n",
        "- **–°–∏–≥–Ω–∞–ª—å–Ω—ã–µ:** RSI, MACD –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è, Stochastic ‚Üí —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞\n",
        "- **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ:** ADX, Bollinger Bands Width, Ichimoku ‚Üí –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä—ã–Ω–∫–∞\n",
        "\n",
        "#### **–ì—Ä—É–ø–ø—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤:**\n",
        "1. **–¢—Ä–µ–Ω–¥ –∏ —Å–∏–ª–∞:** ADX, Ichimoku Cloud\n",
        "2. **–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å:** Bollinger Bands Width, ATR\n",
        "3. **–ò–º–ø—É–ª—å—Å –∏ —Ü–∏–∫–ª—ã:** MACD Histogram, Elder's Impulse\n",
        "\n",
        "#### **–¶–µ–ª–µ–≤—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã:**\n",
        "- –°–∏–ª—å–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥\n",
        "- –°–∏–ª—å–Ω—ã–π –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥\n",
        "- –ë–æ–∫–æ–≤–∏–∫ –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ)\n",
        "- –ë–æ–∫–æ–≤–∏–∫ –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–±–µ—Å–ø–æ—Ä—è–¥–æ—á–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è)\n",
        "- –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—â–∏–π—Å—è –±—ã—á–∏–π (–ø–æ—Å–ª–µ –ø–∞–¥–µ–Ω–∏—è)\n",
        "- –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—â–∏–π—Å—è –º–µ–¥–≤–µ–∂–∏–π (–ø–æ—Å–ª–µ —Ä–æ—Å—Ç–∞)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ –ò–ú–ü–û–†–¢–´ –ò –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏ –¥–≤–∏–∂–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤\n",
        "%run 01_config.ipynb\n",
        "%run 08_indicator_engine_clean.ipynb\n",
        "\n",
        "print(\"‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\")\n",
        "print(\"ü§ñ –ì–æ—Ç–æ–≤ –∫ —Å–æ–∑–¥–∞–Ω–∏—é ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤\")\n",
        "print(\"üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –±–µ–∑ —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üèóÔ∏è –ö–õ–ê–°–° –ê–î–ê–ü–¢–ò–í–ù–û–ì–û ML-–ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê –†–´–ù–û–ß–ù–´–• –†–ï–ñ–ò–ú–û–í\n",
        "\n",
        "class AdaptiveMarketRegimeMLClassifier:\n",
        "    \"\"\"–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–µ–π\"\"\"\n",
        "    \n",
        "    def __init__(self, n_clusters=4, method='kmeans'):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.method = method\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = None\n",
        "        self.feature_names = []\n",
        "        self.cluster_labels = []\n",
        "        self.regime_names = {}\n",
        "        \n",
        "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç–æ–¥–∞\n",
        "        if method == 'kmeans':\n",
        "            self.model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "        elif method == 'dbscan':\n",
        "            self.model = DBSCAN(eps=0.5, min_samples=50)\n",
        "        elif method == 'gmm':\n",
        "            self.model = GaussianMixture(n_components=n_clusters, random_state=42)\n",
        "        \n",
        "        print(f\"‚úÖ AdaptiveMarketRegimeMLClassifier –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!\")\n",
        "        print(f\"ü§ñ –ú–µ—Ç–æ–¥ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {method.upper()}\")\n",
        "        print(f\"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {n_clusters}\")\n",
        "    \n",
        "    def extract_classification_features(self, data):\n",
        "        \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML\"\"\"\n",
        "        print(\"üîç –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏...\")\n",
        "        \n",
        "        # –°–æ–∑–¥–∞–µ–º –¥–≤–∏–∂–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤\n",
        "        engine = IndicatorEngine(data)\n",
        "        \n",
        "        features = pd.DataFrame(index=data.index)\n",
        "        \n",
        "        # ===== –ì–†–£–ü–ü–ê 1: –¢–†–ï–ù–î –ò –°–ò–õ–ê =====\n",
        "        \n",
        "        # ADX - —Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞\n",
        "        adx = engine.calculate_adx(data, period=14)\n",
        "        features['adx_value'] = adx\n",
        "        features['adx_trend'] = (adx > 25).astype(int)  # 1 = —Å–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥, 0 = –±–æ–∫–æ–≤–∏–∫\n",
        "        \n",
        "        # Ichimoku Cloud - –ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ–±–ª–∞–∫–∞\n",
        "        try:\n",
        "            ichimoku = engine.calculate_ichimoku_cloud()\n",
        "            if isinstance(ichimoku, dict):\n",
        "                leading_span_a = ichimoku['leading_span_a']\n",
        "                leading_span_b = ichimoku['leading_span_b']\n",
        "                \n",
        "                # –ü–æ–∑–∏—Ü–∏—è —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ–±–ª–∞–∫–∞\n",
        "                price = data['close']\n",
        "                cloud_upper = np.maximum(leading_span_a, leading_span_b)\n",
        "                cloud_lower = np.minimum(leading_span_a, leading_span_b)\n",
        "                \n",
        "                features['price_vs_ichimoku'] = np.where(\n",
        "                    price > cloud_upper, 1,  # –ù–∞–¥ –æ–±–ª–∞–∫–æ–º (–±—ã—á–∏–π)\n",
        "                    np.where(price < cloud_lower, -1, 0)  # –ü–æ–¥ –æ–±–ª–∞–∫–æ–º (–º–µ–¥–≤–µ–∂–∏–π), –≤ –æ–±–ª–∞–∫–µ (–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å)\n",
        "                )\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ Ichimoku: {e}\")\n",
        "            features['price_vs_ichimoku'] = 0\n",
        "        \n",
        "        # ===== –ì–†–£–ü–ü–ê 2: –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨ =====\n",
        "        \n",
        "        # Bollinger Bands Width - —à–∏—Ä–∏–Ω–∞ –ø–æ–ª–æ—Å\n",
        "        try:\n",
        "            bb = engine.calculate_bollinger_bands()\n",
        "            if isinstance(bb, dict):\n",
        "                bb_width = (bb['upper'] - bb['lower']) / bb['basis']\n",
        "                features['bb_width'] = bb_width\n",
        "                features['bb_squeeze'] = (bb_width < bb_width.rolling(20).mean() * 0.8).astype(int)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ Bollinger Bands: {e}\")\n",
        "            features['bb_width'] = 0.05\n",
        "            features['bb_squeeze'] = 0\n",
        "        \n",
        "        # ATR - —Å—Ä–µ–¥–Ω–∏–π –∏—Å—Ç–∏–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω\n",
        "        try:\n",
        "            atr = engine.calculate_atr(data, period=14)\n",
        "            atr_ma = atr.rolling(20).mean()\n",
        "            features['atr_value'] = atr\n",
        "            features['atr_ratio'] = atr / atr_ma  # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ —Å—Ä–µ–¥–Ω–µ–º—É\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ ATR: {e}\")\n",
        "            features['atr_value'] = 1000\n",
        "            features['atr_ratio'] = 1.0\n",
        "        \n",
        "        # ===== –ì–†–£–ü–ü–ê 3: –ò–ú–ü–£–õ–¨–° –ò –¶–ò–ö–õ–´ =====\n",
        "        \n",
        "        # MACD Histogram - –∏–º–ø—É–ª—å—Å\n",
        "        try:\n",
        "            macd = engine.calculate_macd()\n",
        "            if isinstance(macd, tuple) and len(macd) >= 3:\n",
        "                macd_line, signal_line, histogram = macd\n",
        "                features['macd_histogram'] = histogram\n",
        "                features['macd_histogram_slope'] = histogram.diff(5)  # –ù–∞–∫–ª–æ–Ω –∑–∞ 5 –ø–µ—Ä–∏–æ–¥–æ–≤\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ MACD: {e}\")\n",
        "            features['macd_histogram'] = 0\n",
        "            features['macd_histogram_slope'] = 0\n",
        "        \n",
        "        # RSI - –Ω–∞–∫–ª–æ–Ω –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–º–ø—É–ª—å—Å–∞\n",
        "        try:\n",
        "            rsi = engine.calculate_rsi(data['close'], length=14)\n",
        "            features['rsi_value'] = rsi\n",
        "            features['rsi_trend'] = rsi.diff(5)  # –ù–∞–∫–ª–æ–Ω RSI\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ RSI: {e}\")\n",
        "            features['rsi_value'] = 50\n",
        "            features['rsi_trend'] = 0\n",
        "        \n",
        "        # ===== –ì–†–£–ü–ü–ê 4: –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò =====\n",
        "        \n",
        "        # –ü–æ–∑–∏—Ü–∏—è —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ä–µ–¥–Ω–∏—Ö\n",
        "        try:\n",
        "            ma_50 = engine.calculate_ma(data['close'], 50)\n",
        "            ma_200 = engine.calculate_ma(data['close'], 200)\n",
        "            \n",
        "            price = data['close']\n",
        "            features['price_vs_ma50'] = (price / ma_50 - 1) * 100  # –ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç MA50\n",
        "            features['price_vs_ma200'] = (price / ma_200 - 1) * 100  # –ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç MA200\n",
        "            features['ma50_vs_ma200'] = (ma_50 / ma_200 - 1) * 100  # –û—Ç–Ω–æ—à–µ–Ω–∏–µ MA50 –∫ MA200\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ MA: {e}\")\n",
        "            features['price_vs_ma50'] = 0\n",
        "            features['price_vs_ma200'] = 0\n",
        "            features['ma50_vs_ma200'] = 0\n",
        "        \n",
        "        # –î–∏–Ω–∞–º–∏–∫–∞ –æ–±—ä–µ–º–∞\n",
        "        if 'volume' in data.columns:\n",
        "            try:\n",
        "                volume_ma = data['volume'].rolling(20).mean()\n",
        "                features['volume_ratio'] = data['volume'] / volume_ma\n",
        "                features['volume_trend'] = data['volume'].rolling(5).mean().diff(5)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –æ–±—ä–µ–º–∞: {e}\")\n",
        "                features['volume_ratio'] = 1.0\n",
        "                features['volume_trend'] = 0\n",
        "        else:\n",
        "            features['volume_ratio'] = 1.0\n",
        "            features['volume_trend'] = 0\n",
        "        \n",
        "        # –£–¥–∞–ª—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è\n",
        "        features = features.dropna()\n",
        "        \n",
        "        self.feature_names = features.columns.tolist()\n",
        "        \n",
        "        print(f\"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(features.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\")\n",
        "        print(f\"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(features)} –∑–∞–ø–∏—Å–µ–π\")\n",
        "        print(f\"üîß –ü—Ä–∏–∑–Ω–∞–∫–∏: {', '.join(features.columns[:5])}...\")\n",
        "        \n",
        "        return features\n",
        "    \n",
        "    def extract_classification_features_fixed(self, data):\n",
        "        \"\"\"–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ë–ï–ó DATA LEAKAGE\"\"\"\n",
        "        print(\"üîç –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)...\")\n",
        "        \n",
        "        # –°–æ–∑–¥–∞–µ–º –¥–≤–∏–∂–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤\n",
        "        engine = IndicatorEngine(data)\n",
        "        \n",
        "        features = pd.DataFrame(index=data.index)\n",
        "        \n",
        "        # ===== –ì–†–£–ü–ü–ê 1: –¢–†–ï–ù–î –ò –°–ò–õ–ê =====\n",
        "        \n",
        "        # ADX - —Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞\n",
        "        adx = engine.calculate_adx(data, period=14)\n",
        "        features['adx_value'] = adx\n",
        "        features['adx_trend'] = (adx > 25).astype(int)  # 1 = —Å–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥, 0 = –±–æ–∫–æ–≤–∏–∫\n",
        "        \n",
        "        # Ichimoku Cloud - –ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ–±–ª–∞–∫–∞\n",
        "        try:\n",
        "            ichimoku = engine.calculate_ichimoku_cloud()\n",
        "            if isinstance(ichimoku, dict):\n",
        "                leading_span_a = ichimoku['leading_span_a']\n",
        "                leading_span_b = ichimoku['leading_span_b']\n",
        "                \n",
        "                # –ü–æ–∑–∏—Ü–∏—è —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ–±–ª–∞–∫–∞\n",
        "                price = data['close']\n",
        "                cloud_upper = np.maximum(leading_span_a, leading_span_b)\n",
        "                cloud_lower = np.minimum(leading_span_a, leading_span_b)\n",
        "                \n",
        "                features['price_vs_ichimoku'] = np.where(\n",
        "                    price > cloud_upper, 1,  # –ù–∞–¥ –æ–±–ª–∞–∫–æ–º (–±—ã—á–∏–π)\n",
        "                    np.where(price < cloud_lower, -1, 0)  # –ü–æ–¥ –æ–±–ª–∞–∫–æ–º (–º–µ–¥–≤–µ–∂–∏–π), –≤ –æ–±–ª–∞–∫–µ (–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å)\n",
        "                )\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ Ichimoku: {e}\")\n",
        "            features['price_vs_ichimoku'] = 0\n",
        "        \n",
        "        # ===== –ì–†–£–ü–ü–ê 2: –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨ =====\n",
        "        \n",
        "        # Bollinger Bands Width - —à–∏—Ä–∏–Ω–∞ –ø–æ–ª–æ—Å (–ò–°–ü–†–ê–í–õ–ï–ù–û: –±–µ–∑ look-ahead bias)\n",
        "        try:\n",
        "            bb = engine.calculate_bollinger_bands()\n",
        "            if isinstance(bb, dict):\n",
        "                bb_width = (bb['upper'] - bb['lower']) / bb['basis']\n",
        "                features['bb_width'] = bb_width\n",
        "                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º shift(1) –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è look-ahead bias\n",
        "                bb_width_ma = bb_width.shift(1).rolling(20).mean()\n",
        "                features['bb_squeeze'] = (bb_width < bb_width_ma * 0.8).astype(int)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ Bollinger Bands: {e}\")\n",
        "            features['bb_width'] = 0.05\n",
        "            features['bb_squeeze'] = 0\n",
        "        \n",
        "        # ATR - —Å—Ä–µ–¥–Ω–∏–π –∏—Å—Ç–∏–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (–ò–°–ü–†–ê–í–õ–ï–ù–û: –±–µ–∑ look-ahead bias)\n",
        "        try:\n",
        "            atr = engine.calculate_atr(data, period=14)\n",
        "            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º shift(1) –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è look-ahead bias\n",
        "            atr_ma = atr.shift(1).rolling(20).mean()\n",
        "            features['atr_value'] = atr\n",
        "            features['atr_ratio'] = atr / atr_ma  # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ —Å—Ä–µ–¥–Ω–µ–º—É\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ ATR: {e}\")\n",
        "            features['atr_value'] = 1000\n",
        "            features['atr_ratio'] = 1.0\n",
        "        \n",
        "        # ===== –ì–†–£–ü–ü–ê 3: –ò–ú–ü–£–õ–¨–° –ò –¶–ò–ö–õ–´ =====\n",
        "        \n",
        "        # MACD Histogram - –∏–º–ø—É–ª—å—Å (–ò–°–ü–†–ê–í–õ–ï–ù–û: –±–µ–∑ look-ahead bias)\n",
        "        try:\n",
        "            macd = engine.calculate_macd()\n",
        "            if isinstance(macd, tuple) and len(macd) >= 3:\n",
        "                macd_line, signal_line, histogram = macd\n",
        "                features['macd_histogram'] = histogram\n",
        "                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º diff(1) –≤–º–µ—Å—Ç–æ diff(5) –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è look-ahead bias\n",
        "                features['macd_histogram_slope'] = histogram.diff(1)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ MACD: {e}\")\n",
        "            features['macd_histogram'] = 0\n",
        "            features['macd_histogram_slope'] = 0\n",
        "        \n",
        "        # RSI - –Ω–∞–∫–ª–æ–Ω –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–º–ø—É–ª—å—Å–∞ (–ò–°–ü–†–ê–í–õ–ï–ù–û: –±–µ–∑ look-ahead bias)\n",
        "        try:\n",
        "            rsi = engine.calculate_rsi(data['close'], length=14)\n",
        "            features['rsi_value'] = rsi\n",
        "            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º diff(1) –≤–º–µ—Å—Ç–æ diff(5) –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è look-ahead bias\n",
        "            features['rsi_trend'] = rsi.diff(1)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ RSI: {e}\")\n",
        "            features['rsi_value'] = 50\n",
        "            features['rsi_trend'] = 0\n",
        "        \n",
        "        # ===== –ì–†–£–ü–ü–ê 4: –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò =====\n",
        "        \n",
        "        # –ü–æ–∑–∏—Ü–∏—è —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ä–µ–¥–Ω–∏—Ö\n",
        "        try:\n",
        "            ma_50 = engine.calculate_ma(data['close'], 50)\n",
        "            ma_200 = engine.calculate_ma(data['close'], 200)\n",
        "            \n",
        "            price = data['close']\n",
        "            features['price_vs_ma50'] = (price / ma_50 - 1) * 100  # –ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç MA50\n",
        "            features['price_vs_ma200'] = (price / ma_200 - 1) * 100  # –ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç MA200\n",
        "            features['ma50_vs_ma200'] = (ma_50 / ma_200 - 1) * 100  # –û—Ç–Ω–æ—à–µ–Ω–∏–µ MA50 –∫ MA200\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ MA: {e}\")\n",
        "            features['price_vs_ma50'] = 0\n",
        "            features['price_vs_ma200'] = 0\n",
        "            features['ma50_vs_ma200'] = 0\n",
        "        \n",
        "        # –î–∏–Ω–∞–º–∏–∫–∞ –æ–±—ä–µ–º–∞ (–ò–°–ü–†–ê–í–õ–ï–ù–û: –±–µ–∑ look-ahead bias)\n",
        "        if 'volume' in data.columns:\n",
        "            try:\n",
        "                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º shift(1) –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è look-ahead bias\n",
        "                volume_ma = data['volume'].shift(1).rolling(20).mean()\n",
        "                features['volume_ratio'] = data['volume'] / volume_ma\n",
        "                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º diff(1) –≤–º–µ—Å—Ç–æ diff(5)\n",
        "                features['volume_trend'] = data['volume'].diff(1)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –æ–±—ä–µ–º–∞: {e}\")\n",
        "                features['volume_ratio'] = 1.0\n",
        "                features['volume_trend'] = 0\n",
        "        else:\n",
        "            features['volume_ratio'] = 1.0\n",
        "            features['volume_trend'] = 0\n",
        "        \n",
        "        # –£–¥–∞–ª—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è\n",
        "        features = features.dropna()\n",
        "        \n",
        "        self.feature_names = features.columns.tolist()\n",
        "        \n",
        "        print(f\"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(features.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)\")\n",
        "        print(f\"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(features)} –∑–∞–ø–∏—Å–µ–π\")\n",
        "        print(f\"üîß –ü—Ä–∏–∑–Ω–∞–∫–∏: {', '.join(features.columns[:5])}...\")\n",
        "        print(\"üîí DATA LEAKAGE –ò–°–ü–†–ê–í–õ–ï–ù: –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª—ã–µ –¥–∞–Ω–Ω—ã–µ\")\n",
        "        \n",
        "        return features\n",
        "    \n",
        "    def find_optimal_clusters(self, features, max_clusters=8):\n",
        "        \"\"\"–ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –º–µ—Ç–æ–¥–æ–º –ª–æ–∫—Ç—è –∏ —Å–∏–ª—É—ç—Ç–∞\"\"\"\n",
        "        print(\"üîç –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...\")\n",
        "        \n",
        "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "        scaled_features = self.scaler.fit_transform(features)\n",
        "        \n",
        "        inertias = []\n",
        "        silhouette_scores = []\n",
        "        k_range = range(2, max_clusters + 1)\n",
        "        \n",
        "        for k in k_range:\n",
        "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "            cluster_labels = kmeans.fit_predict(scaled_features)\n",
        "            \n",
        "            inertias.append(kmeans.inertia_)\n",
        "            silhouette_scores.append(silhouette_score(scaled_features, cluster_labels))\n",
        "        \n",
        "        # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
        "        optimal_k = k_range[np.argmax(silhouette_scores)]\n",
        "        \n",
        "        print(f\"‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {optimal_k}\")\n",
        "        print(f\"üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å–∏–ª—É—ç—Ç: {max(silhouette_scores):.3f}\")\n",
        "        \n",
        "        return optimal_k, inertias, silhouette_scores\n",
        "    \n",
        "    def honest_data_split(self, data, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
        "        \"\"\"–ß–µ—Å—Ç–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ë–ï–ó LOOK-AHEAD BIAS\"\"\"\n",
        "        print(f\"üîí –ß–µ—Å—Ç–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö: train={train_ratio}, val={val_ratio}, test={test_ratio}\")\n",
        "        \n",
        "        n = len(data)\n",
        "        train_end = int(n * train_ratio)\n",
        "        val_end = int(n * (train_ratio + val_ratio))\n",
        "        \n",
        "        train_data = data.iloc[:train_end]\n",
        "        val_data = data.iloc[train_end:val_end]\n",
        "        test_data = data.iloc[val_end:]\n",
        "        \n",
        "        print(f\"üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:\")\n",
        "        print(f\"   Train: {len(train_data)} –∑–∞–ø–∏—Å–µ–π ({train_data.index[0]} - {train_data.index[-1]})\")\n",
        "        print(f\"   Val:   {len(val_data)} –∑–∞–ø–∏—Å–µ–π ({val_data.index[0]} - {val_data.index[-1]})\")\n",
        "        print(f\"   Test:  {len(test_data)} –∑–∞–ø–∏—Å–µ–π ({test_data.index[0]} - {test_data.index[-1]})\")\n",
        "        \n",
        "        return train_data, val_data, test_data\n",
        "    \n",
        "    def train_classifier(self, data):\n",
        "        \"\"\"–û–±—É—á–µ–Ω–∏–µ ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
        "        print(\"ü§ñ –û–±—É—á–µ–Ω–∏–µ ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...\")\n",
        "        \n",
        "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "        features = self.extract_classification_features(data)\n",
        "        \n",
        "        # –ï—Å–ª–∏ –º–µ—Ç–æ–¥ K-Means, –∏—â–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
        "        if self.method == 'kmeans':\n",
        "            optimal_k, inertias, silhouette_scores = self.find_optimal_clusters(features)\n",
        "            self.n_clusters = optimal_k\n",
        "            self.model = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "        \n",
        "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "        scaled_features = self.scaler.fit_transform(features)\n",
        "        \n",
        "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "        if self.method in ['kmeans', 'dbscan']:\n",
        "            self.cluster_labels = self.model.fit_predict(scaled_features)\n",
        "        elif self.method == 'gmm':\n",
        "            self.model.fit(scaled_features)\n",
        "            self.cluster_labels = self.model.predict(scaled_features)\n",
        "        \n",
        "        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è DBSCAN\n",
        "        if self.method == 'dbscan':\n",
        "            self.n_clusters = len(set(self.cluster_labels)) - (1 if -1 in self.cluster_labels else 0)\n",
        "        \n",
        "        print(f\"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±—É—á–µ–Ω!\")\n",
        "        print(f\"üìä –ù–∞–π–¥–µ–Ω–æ {self.n_clusters} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\")\n",
        "        print(f\"üìà –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(features)}\")\n",
        "        \n",
        "        return features, self.cluster_labels\n",
        "    \n",
        "    def train_classifier_fixed(self, data):\n",
        "        \"\"\"–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –æ–±—É—á–µ–Ω–∏–µ ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å —á–µ—Å—Ç–Ω—ã–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
        "        print(\"ü§ñ –û–±—É—á–µ–Ω–∏–µ ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)...\")\n",
        "        \n",
        "        # –ß–µ—Å—Ç–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "        train_data, val_data, test_data = self.honest_data_split(data)\n",
        "        \n",
        "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–ª—å–∫–æ –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "        features = self.extract_classification_features_fixed(train_data)\n",
        "        \n",
        "        # –ï—Å–ª–∏ –º–µ—Ç–æ–¥ K-Means, –∏—â–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
        "        if self.method == 'kmeans':\n",
        "            optimal_k, inertias, silhouette_scores = self.find_optimal_clusters(features)\n",
        "            self.n_clusters = optimal_k\n",
        "            self.model = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "        \n",
        "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "        scaled_features = self.scaler.fit_transform(features)\n",
        "        \n",
        "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "        if self.method in ['kmeans', 'dbscan']:\n",
        "            self.cluster_labels = self.model.fit_predict(scaled_features)\n",
        "        elif self.method == 'gmm':\n",
        "            self.model.fit(scaled_features)\n",
        "            self.cluster_labels = self.model.predict(scaled_features)\n",
        "        \n",
        "        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è DBSCAN\n",
        "        if self.method == 'dbscan':\n",
        "            self.n_clusters = len(set(self.cluster_labels)) - (1 if -1 in self.cluster_labels else 0)\n",
        "        \n",
        "        print(f\"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±—É—á–µ–Ω (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)!\")\n",
        "        print(f\"üìä –ù–∞–π–¥–µ–Ω–æ {self.n_clusters} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\")\n",
        "        print(f\"üìà –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(features)}\")\n",
        "        print(\"üîí –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ –ë–ï–ó DATA LEAKAGE\")\n",
        "        \n",
        "        return features, self.cluster_labels, train_data, val_data, test_data\n",
        "\n",
        "print(\"‚úÖ –ö–ª–∞—Å—Å AdaptiveMarketRegimeMLClassifier —Å–æ–∑–¥–∞–Ω!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîç –ú–ï–¢–û–î–´ –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–ò –ò –ê–ù–ê–õ–ò–ó–ê –ö–õ–ê–°–¢–ï–†–û–í\n",
        "\n",
        "def interpret_clusters(self, features, cluster_labels):\n",
        "    \"\"\"–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∏ –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π —Ä—ã–Ω–æ—á–Ω—ã–º —Ä–µ–∂–∏–º–∞–º\"\"\"\n",
        "    print(\"üîç –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...\")\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–µ–º DataFrame —Å –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏\n",
        "    cluster_data = features.copy()\n",
        "    cluster_data['cluster'] = cluster_labels\n",
        "    \n",
        "    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
        "    cluster_centers = cluster_data.groupby('cluster').mean()\n",
        "    \n",
        "    print(\"üìä –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:\")\n",
        "    for cluster_id in sorted(cluster_centers.index):\n",
        "        if cluster_id == -1:  # –®—É–º–æ–≤—ã–µ —Ç–æ—á–∫–∏ –¥–ª—è DBSCAN\n",
        "            continue\n",
        "            \n",
        "        center = cluster_centers.loc[cluster_id]\n",
        "        print(f\"\\nüéØ –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}:\")\n",
        "        print(f\"   ADX: {center['adx_value']:.1f} ({'–°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥' if center['adx_trend'] > 0.5 else '–ë–æ–∫–æ–≤–∏–∫'})\")\n",
        "        print(f\"   BB Width: {center['bb_width']:.4f}\")\n",
        "        print(f\"   ATR Ratio: {center['atr_ratio']:.2f}\")\n",
        "        print(f\"   Price vs Ichimoku: {center['price_vs_ichimoku']:.1f}\")\n",
        "        print(f\"   RSI Trend: {center['rsi_trend']:.2f}\")\n",
        "    \n",
        "    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n",
        "    regime_names = self._assign_regime_names(cluster_centers)\n",
        "    self.regime_names = regime_names\n",
        "    \n",
        "    print(\"\\n‚úÖ –ù–∞–∑–≤–∞–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤:\")\n",
        "    for cluster_id, regime_name in regime_names.items():\n",
        "        print(f\"   –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {regime_name}\")\n",
        "    \n",
        "    return cluster_centers, regime_names\n",
        "\n",
        "def _assign_regime_names(self, cluster_centers):\n",
        "    \"\"\"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π —Ä—ã–Ω–æ—á–Ω—ã–º —Ä–µ–∂–∏–º–∞–º\"\"\"\n",
        "    regime_names = {}\n",
        "    \n",
        "    for cluster_id in cluster_centers.index:\n",
        "        if cluster_id == -1:  # –®—É–º–æ–≤—ã–µ —Ç–æ—á–∫–∏\n",
        "            regime_names[cluster_id] = \"–®—É–º/–ê–Ω–æ–º–∞–ª–∏–∏\"\n",
        "            continue\n",
        "        \n",
        "        center = cluster_centers.loc[cluster_id]\n",
        "        \n",
        "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n",
        "        adx_strong = center['adx_trend'] > 0.5\n",
        "        price_above_cloud = center['price_vs_ichimoku'] > 0.5\n",
        "        price_below_cloud = center['price_vs_ichimoku'] < -0.5\n",
        "        high_volatility = center['bb_width'] > cluster_centers['bb_width'].median()\n",
        "        high_atr = center['atr_ratio'] > 1.1\n",
        "        rsi_rising = center['rsi_trend'] > 0\n",
        "        \n",
        "        # –õ–æ–≥–∏–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "        if adx_strong and price_above_cloud and rsi_rising:\n",
        "            regime_names[cluster_id] = \"–°–∏–ª—å–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥\"\n",
        "        elif adx_strong and price_below_cloud and not rsi_rising:\n",
        "            regime_names[cluster_id] = \"–°–∏–ª—å–Ω—ã–π –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥\"\n",
        "        elif not adx_strong and not high_volatility and not high_atr:\n",
        "            regime_names[cluster_id] = \"–ë–æ–∫–æ–≤–∏–∫ –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ)\"\n",
        "        elif not adx_strong and high_volatility:\n",
        "            regime_names[cluster_id] = \"–ë–æ–∫–æ–≤–∏–∫ –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏\"\n",
        "        elif adx_strong and price_above_cloud and not rsi_rising:\n",
        "            regime_names[cluster_id] = \"–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—â–∏–π—Å—è –±—ã—á–∏–π\"\n",
        "        elif adx_strong and price_below_cloud and rsi_rising:\n",
        "            regime_names[cluster_id] = \"–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—â–∏–π—Å—è –º–µ–¥–≤–µ–∂–∏–π\"\n",
        "        else:\n",
        "            regime_names[cluster_id] = f\"–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º {cluster_id}\"\n",
        "    \n",
        "    return regime_names\n",
        "\n",
        "def predict_current_regime(self, current_data):\n",
        "    \"\"\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞\"\"\"\n",
        "    if self.model is None:\n",
        "        raise ValueError(\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –æ–±—É—á–µ–Ω! –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ train_classifier()\")\n",
        "    \n",
        "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "    features = self.extract_classification_features(current_data)\n",
        "    \n",
        "    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ\n",
        "    latest_features = features.iloc[-1:]\n",
        "    \n",
        "    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "    scaled_features = self.scaler.transform(latest_features)\n",
        "    \n",
        "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
        "    if self.method in ['kmeans', 'dbscan']:\n",
        "        cluster_id = self.model.predict(scaled_features)[0]\n",
        "    elif self.method == 'gmm':\n",
        "        cluster_id = self.model.predict(scaled_features)[0]\n",
        "    \n",
        "    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–∂–∏–º–∞\n",
        "    regime_name = self.regime_names.get(cluster_id, f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º {cluster_id}\")\n",
        "    \n",
        "    return cluster_id, regime_name\n",
        "\n",
        "def get_regime_statistics(self, data, cluster_labels):\n",
        "    \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Ä—ã–Ω–æ—á–Ω—ã–º —Ä–µ–∂–∏–º–∞–º\"\"\"\n",
        "    print(\"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä—ã–Ω–æ—á–Ω—ã–º —Ä–µ–∂–∏–º–∞–º:\")\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–µ–º DataFrame —Å –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏\n",
        "    regime_data = data.copy()\n",
        "    regime_data['regime'] = cluster_labels\n",
        "    \n",
        "    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–µ–∂–∏–º–∞–º\n",
        "    regime_stats = regime_data.groupby('regime').agg({\n",
        "        'close': ['count', 'mean', 'std'],\n",
        "        'volume': 'mean' if 'volume' in data.columns else lambda x: 0\n",
        "    }).round(2)\n",
        "    \n",
        "    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤\n",
        "    regime_stats['regime_name'] = regime_stats.index.map(self.regime_names)\n",
        "    \n",
        "    print(regime_stats)\n",
        "    \n",
        "    return regime_stats\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–æ–¥—ã –∫ –∫–ª–∞—Å—Å—É\n",
        "AdaptiveMarketRegimeMLClassifier.interpret_clusters = interpret_clusters\n",
        "AdaptiveMarketRegimeMLClassifier._assign_regime_names = _assign_regime_names\n",
        "AdaptiveMarketRegimeMLClassifier.predict_current_regime = predict_current_regime\n",
        "AdaptiveMarketRegimeMLClassifier.get_regime_statistics = get_regime_statistics\n",
        "\n",
        "print(\"‚úÖ –ú–µ—Ç–æ–¥—ã –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–±–∞–≤–ª–µ–Ω—ã –∫ –∫–ª–∞—Å—Å—É!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìà –ú–ï–¢–û–î–´ –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\n",
        "\n",
        "def visualize_regimes(self, data, features, cluster_labels, title=\"ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤\"):\n",
        "    \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\"\"\"\n",
        "    print(\"üìà –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...\")\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É —Å –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞–º–∏\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
        "    \n",
        "    # –ì—Ä–∞—Ñ–∏–∫ 1: –¶–µ–Ω–∞ —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π —Ä–µ–∂–∏–º–æ–≤\n",
        "    ax1 = axes[0]\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–µ–º —Ü–≤–µ—Ç–æ–≤—É—é –∫–∞—Ä—Ç—É –¥–ª—è —Ä–µ–∂–∏–º–æ–≤\n",
        "    unique_clusters = sorted(set(cluster_labels))\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_clusters)))\n",
        "    color_map = dict(zip(unique_clusters, colors))\n",
        "    \n",
        "    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ —Ü–µ–Ω—ã\n",
        "    ax1.plot(data.index, data['close'], 'k-', alpha=0.7, linewidth=1, label='–¶–µ–Ω–∞ BTC')\n",
        "    \n",
        "    # –î–æ–±–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—ã–µ –ø–æ–ª–æ—Å—ã –¥–ª—è —Ä–µ–∂–∏–º–æ–≤\n",
        "    for i, cluster in enumerate(cluster_labels):\n",
        "        if i < len(data) - 1:\n",
        "            ax1.axvspan(data.index[i], data.index[i+1], \n",
        "                       color=color_map[cluster], alpha=0.3, \n",
        "                       label=self.regime_names.get(cluster, f\"–†–µ–∂–∏–º {cluster}\") if i == 0 else \"\")\n",
        "    \n",
        "    ax1.set_title(f\"{title} - –¶–µ–Ω–∞ —Å —Ä–µ–∂–∏–º–∞–º–∏\", fontsize=14, fontweight='bold')\n",
        "    ax1.set_ylabel('–¶–µ–Ω–∞ BTC (USD)')\n",
        "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # –ì—Ä–∞—Ñ–∏–∫ 2: ADX –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\n",
        "    ax2 = axes[1]\n",
        "    \n",
        "    # ADX\n",
        "    ax2_twin = ax2.twinx()\n",
        "    \n",
        "    # ADX –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–º –≥—Ä–∞—Ñ–∏–∫–µ\n",
        "    ax2.plot(data.index, features['adx_value'], 'b-', linewidth=2, label='ADX')\n",
        "    ax2.axhline(y=25, color='r', linestyle='--', alpha=0.7, label='ADX > 25 (—Ç—Ä–µ–Ω–¥)')\n",
        "    ax2.axhline(y=20, color='orange', linestyle='--', alpha=0.7, label='ADX < 20 (–±–æ–∫–æ–≤–∏–∫)')\n",
        "    ax2.set_ylabel('ADX (—Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞)', color='b')\n",
        "    ax2.tick_params(axis='y', labelcolor='b')\n",
        "    \n",
        "    # BB Width –Ω–∞ –≤—Ç–æ—Ä–æ–º –≥—Ä–∞—Ñ–∏–∫–µ\n",
        "    ax2_twin.plot(data.index, features['bb_width'], 'g-', linewidth=2, label='BB Width')\n",
        "    ax2_twin.set_ylabel('BB Width (–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)', color='g')\n",
        "    ax2_twin.tick_params(axis='y', labelcolor='g')\n",
        "    \n",
        "    ax2.set_title('ADX (—Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞) –∏ BB Width (–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)', fontsize=12)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.legend(loc='upper left')\n",
        "    ax2_twin.legend(loc='upper right')\n",
        "    \n",
        "    # –ì—Ä–∞—Ñ–∏–∫ 3: RSI –∏ –∏–º–ø—É–ª—å—Å\n",
        "    ax3 = axes[2]\n",
        "    \n",
        "    # RSI\n",
        "    ax3_twin = ax3.twinx()\n",
        "    \n",
        "    ax3.plot(data.index, features['rsi_value'], 'purple', linewidth=2, label='RSI')\n",
        "    ax3.axhline(y=70, color='r', linestyle='--', alpha=0.7, label='RSI > 70 (–ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å)')\n",
        "    ax3.axhline(y=30, color='g', linestyle='--', alpha=0.7, label='RSI < 30 (–ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å)')\n",
        "    ax3.axhline(y=50, color='gray', linestyle='-', alpha=0.5, label='RSI = 50 (–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ)')\n",
        "    ax3.set_ylabel('RSI', color='purple')\n",
        "    ax3.tick_params(axis='y', labelcolor='purple')\n",
        "    ax3.set_ylim(0, 100)\n",
        "    \n",
        "    # MACD Histogram –Ω–∞ –≤—Ç–æ—Ä–æ–º –≥—Ä–∞—Ñ–∏–∫–µ\n",
        "    ax3_twin.bar(data.index, features['macd_histogram'], alpha=0.6, color='orange', label='MACD Histogram')\n",
        "    ax3_twin.set_ylabel('MACD Histogram (–∏–º–ø—É–ª—å—Å)', color='orange')\n",
        "    ax3_twin.tick_params(axis='y', labelcolor='orange')\n",
        "    \n",
        "    ax3.set_title('RSI –∏ MACD Histogram (–∏–º–ø—É–ª—å—Å)', fontsize=12)\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    ax3.legend(loc='upper left')\n",
        "    ax3_twin.legend(loc='upper right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –≤ 2D\n",
        "    self._visualize_clusters_2d(features, cluster_labels)\n",
        "\n",
        "def _visualize_clusters_2d(self, features, cluster_labels):\n",
        "    \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –≤ 2D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ —Å –ø–æ–º–æ—â—å—é PCA\"\"\"\n",
        "    # –ü—Ä–∏–º–µ–Ω—è–µ–º PCA –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
        "    pca = PCA(n_components=2)\n",
        "    features_2d = pca.fit_transform(self.scaler.transform(features))\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    \n",
        "    # –¶–≤–µ—Ç–æ–≤–∞—è –∫–∞—Ä—Ç–∞\n",
        "    unique_clusters = sorted(set(cluster_labels))\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_clusters)))\n",
        "    \n",
        "    for cluster_id in unique_clusters:\n",
        "        if cluster_id == -1:  # –®—É–º–æ–≤—ã–µ —Ç–æ—á–∫–∏\n",
        "            mask = np.array(cluster_labels) == cluster_id\n",
        "            plt.scatter(features_2d[mask, 0], features_2d[mask, 1], \n",
        "                      c='black', marker='x', s=50, alpha=0.6, label='–®—É–º')\n",
        "        else:\n",
        "            mask = np.array(cluster_labels) == cluster_id\n",
        "            plt.scatter(features_2d[mask, 0], features_2d[mask, 1], \n",
        "                      c=[colors[i] for i in range(len(unique_clusters)) if unique_clusters[i] == cluster_id][0], \n",
        "                      s=50, alpha=0.7, \n",
        "                      label=self.regime_names.get(cluster_id, f\"–†–µ–∂–∏–º {cluster_id}\"))\n",
        "    \n",
        "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "    plt.title('–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ –≤ 2D (PCA)', fontsize=14, fontweight='bold')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"üìä PCA –æ–±—ä—è—Å–Ω—è–µ—Ç {pca.explained_variance_ratio_.sum():.1%} –æ–±—â–µ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏\")\n",
        "    print(f\"üîç PC1: {pca.explained_variance_ratio_[0]:.1%}, PC2: {pca.explained_variance_ratio_[1]:.1%}\")\n",
        "\n",
        "# –¢–æ—Ä–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —É–±—Ä–∞–Ω—ã - –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –ø–æ–∑–∂–µ –ø–æ—Å–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–æ–¥—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∫ –∫–ª–∞—Å—Å—É\n",
        "AdaptiveMarketRegimeMLClassifier.visualize_regimes = visualize_regimes\n",
        "AdaptiveMarketRegimeMLClassifier._visualize_clusters_2d = _visualize_clusters_2d\n",
        "\n",
        "print(\"‚úÖ –ú–µ—Ç–æ–¥—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –∫ –∫–ª–∞—Å—Å—É!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ì–û ML-–ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê\n",
        "\n",
        "print(\"üéØ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ì–û ML-–ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê –†–´–ù–û–ß–ù–´–• –†–ï–ñ–ò–ú–û–í\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ BTC\n",
        "data = pd.read_csv('df_btc_4h.csv', index_col=0, parse_dates=True)\n",
        "print(f\"üìä –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ BTC: {len(data)} –∑–∞–ø–∏—Å–µ–π\")\n",
        "print(f\"üìÖ –ü–µ—Ä–∏–æ–¥: {data.index[0]} - {data.index[-1]}\")\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
        "ml_classifier = AdaptiveMarketRegimeMLClassifier(n_clusters=4, method='kmeans')\n",
        "\n",
        "# –û–±—É—á–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π\n",
        "features, cluster_labels, train_data, val_data, test_data = ml_classifier.train_classifier_fixed(data)\n",
        "\n",
        "# –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã\n",
        "cluster_centers, regime_names = ml_classifier.interpret_clusters(features, cluster_labels)\n",
        "\n",
        "# –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
        "regime_stats = ml_classifier.get_regime_statistics(train_data, cluster_labels)\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "ml_classifier.visualize_regimes(train_data, features, cluster_labels)\n",
        "\n",
        "print(\"\\nüéâ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô ML-–ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù –ò –ü–†–û–¢–ï–°–¢–ò–†–û–í–ê–ù!\")\n",
        "print(\"üîí DATA LEAKAGE –ò–°–ü–†–ê–í–õ–ï–ù!\")\n",
        "print(\"üí° –°–∏—Å—Ç–µ–º–∞ –º–æ–∂–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ä—ã–Ω–æ—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã\")\n",
        "print(\"ü§ñ –ë–µ–∑ —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã\")\n",
        "print(\"üìä –ß–µ—Å—Ç–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö: train/val/test –ø–æ –≤—Ä–µ–º–µ–Ω–∏\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üî¨ –°–†–ê–í–ù–ï–ù–ò–ï –ú–ï–¢–û–î–û–í –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò\n",
        "\n",
        "print(\"üî¨ –°–†–ê–í–ù–ï–ù–ò–ï –†–ê–ó–õ–ò–ß–ù–´–• –ú–ï–¢–û–î–û–í –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "methods = ['kmeans', 'dbscan', 'gmm']\n",
        "results = {}\n",
        "\n",
        "for method in methods:\n",
        "    print(f\"\\nü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞: {method.upper()}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    try:\n",
        "        # –°–æ–∑–¥–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
        "        classifier = AdaptiveMarketRegimeMLClassifier(n_clusters=4, method=method)\n",
        "        \n",
        "        # –û–±—É—á–∞–µ–º\n",
        "        features, labels = classifier.train_classifier(data)\n",
        "        \n",
        "        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º\n",
        "        centers, names = classifier.interpret_clusters(features, labels)\n",
        "        \n",
        "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "        results[method] = {\n",
        "            'classifier': classifier,\n",
        "            'features': features,\n",
        "            'labels': labels,\n",
        "            'centers': centers,\n",
        "            'names': names,\n",
        "            'n_clusters': len(set(labels)) - (1 if -1 in labels else 0)\n",
        "        }\n",
        "        \n",
        "        print(f\"‚úÖ –ú–µ—Ç–æ–¥ {method.upper()} –∑–∞–≤–µ—Ä—à–µ–Ω\")\n",
        "        print(f\"üìä –ù–∞–π–¥–µ–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {results[method]['n_clusters']}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ –≤ –º–µ—Ç–æ–¥–µ {method.upper()}: {e}\")\n",
        "        results[method] = None\n",
        "\n",
        "# –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
        "print(\"\\nüìä –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –ú–ï–¢–û–î–û–í:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'–ú–µ—Ç–æ–¥':<10} {'–ö–ª–∞—Å—Ç–µ—Ä—ã':<10} {'–°—Ç–∞—Ç—É—Å':<15}\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "for method, result in results.items():\n",
        "    if result is not None:\n",
        "        print(f\"{method.upper():<10} {result['n_clusters']:<10} {'–£—Å–ø–µ—à–Ω–æ':<15}\")\n",
        "    else:\n",
        "        print(f\"{method.upper():<10} {'N/A':<10} {'–û—à–∏–±–∫–∞':<15}\")\n",
        "\n",
        "print(\"\\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ —Å –Ω–∞–∏–ª—É—á—à–µ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìà –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –î–õ–Ø –¢–û–†–ì–û–í–´–• –†–ï–®–ï–ù–ò–ô\n",
        "\n",
        "print(\"üìà –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø ML-–ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê –î–õ–Ø –¢–û–†–ì–û–í–´–• –†–ï–®–ï–ù–ò–ô\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (K-Means)\n",
        "best_classifier = results['kmeans']['classifier']\n",
        "\n",
        "# –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "print(\"üîç –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 —Ç–æ—á–µ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
        "recent_data = data.tail(100)\n",
        "\n",
        "for i in range(-5, 0):  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –ø–µ—Ä–∏–æ–¥–æ–≤\n",
        "    current_data = recent_data.iloc[:len(recent_data) + i + 1]\n",
        "    \n",
        "    try:\n",
        "        cluster_id, regime_name = best_classifier.predict_current_regime(current_data)\n",
        "        recommendation = best_classifier.get_trading_recommendations(regime_name)\n",
        "        \n",
        "        print(f\"\\nüìÖ –ü–µ—Ä–∏–æ–¥: {current_data.index[-1]}\")\n",
        "        print(f\"üéØ –†–µ–∂–∏–º: {regime_name}\")\n",
        "        print(f\"üí° –î–µ–π—Å—Ç–≤–∏–µ: {recommendation['action']}\")\n",
        "        print(f\"üìä –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: {recommendation['indicators']}\")\n",
        "        print(f\"‚ö†Ô∏è –†–∏—Å–∫: {recommendation['risk']}\")\n",
        "        print(f\"üéØ –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {recommendation['strategy']}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–∏–æ–¥–∞ {current_data.index[-1]}: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ ML-–ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –ì–û–¢–û–í –ö –ò–ù–¢–ï–ì–†–ê–¶–ò–ò –° –¢–û–†–ì–û–í–û–ô –°–ò–°–¢–ï–ú–û–ô!\")\n",
        "print(\"ü§ñ –°–∏—Å—Ç–µ–º–∞ –º–æ–∂–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ–¥ —Ç–µ–∫—É—â–∏–π —Ä—ã–Ω–æ—á–Ω—ã–π —Ä–µ–∂–∏–º\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìã **–†–ï–ó–Æ–ú–ï –ò –í–´–í–û–î–´**\n",
        "\n",
        "## ‚úÖ **–ß–¢–û –†–ï–ê–õ–ò–ó–û–í–ê–ù–û:**\n",
        "\n",
        "### **ü§ñ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤**\n",
        "- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è** –±–µ–∑ —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏\n",
        "- **3 –º–µ—Ç–æ–¥–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏:** K-Means, DBSCAN, GMM\n",
        "- **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:** ADX, Ichimoku, BB Width, ATR, MACD Histogram\n",
        "- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è** –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∏ –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π\n",
        "\n",
        "### **üìä –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:**\n",
        "1. **–¢—Ä–µ–Ω–¥ –∏ —Å–∏–ª–∞:** ADX, Ichimoku Cloud, –ø–æ–∑–∏—Ü–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ MA\n",
        "2. **–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å:** Bollinger Bands Width, ATR ratio\n",
        "3. **–ò–º–ø—É–ª—å—Å –∏ —Ü–∏–∫–ª—ã:** MACD Histogram, RSI trend\n",
        "4. **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ:** Volume dynamics, Price vs MA ratios\n",
        "\n",
        "### **üéØ –û–ø—Ä–µ–¥–µ–ª—è–µ–º—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã:**\n",
        "- –°–∏–ª—å–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥\n",
        "- –°–∏–ª—å–Ω—ã–π –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥\n",
        "- –ë–æ–∫–æ–≤–∏–∫ –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ)\n",
        "- –ë–æ–∫–æ–≤–∏–∫ –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–±–µ—Å–ø–æ—Ä—è–¥–æ—á–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è)\n",
        "- –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—â–∏–π—Å—è –±—ã—á–∏–π (–ø–æ—Å–ª–µ –ø–∞–¥–µ–Ω–∏—è)\n",
        "- –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—â–∏–π—Å—è –º–µ–¥–≤–µ–∂–∏–π (–ø–æ—Å–ª–µ —Ä–æ—Å—Ç–∞)\n",
        "\n",
        "## üöÄ **–ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê –ü–û–î–•–û–î–ê:**\n",
        "\n",
        "### **üìà –ù–∞—É—á–Ω–∞—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å:**\n",
        "- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª—å–Ω—ã—Ö –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤\n",
        "- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
        "- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –±–µ–∑ —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏\n",
        "\n",
        "### **ü§ñ –ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å:**\n",
        "- –ú–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –ø–æ–¥ —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è\n",
        "- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "- –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –≤–º–µ—Å—Ç–æ —Å—Ç–∞—Ç–∏—á–Ω—ã—Ö\n",
        "\n",
        "### **üí° –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å:**\n",
        "- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
        "- –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ–¥ —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º\n",
        "- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
        "\n",
        "## üîÑ **–°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:**\n",
        "\n",
        "1. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏** - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
        "2. **Walk-Forward Analysis** - —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–∏\n",
        "3. **–ê–Ω–∞–ª–∏–∑ –∫—Ä–∏–≤—ã—Ö —ç–∫–≤–∏—Ç–∏** - –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –ø–æ —Ä–µ–∂–∏–º–∞–º\n",
        "4. **–†–µ–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** - –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "## üí° **–ö–õ–Æ–ß–ï–í–´–ï –ò–ù–°–ê–ô–¢–´:**\n",
        "\n",
        "- **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã** –±–æ–ª–µ–µ –≤–∞–∂–Ω—ã –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —á–µ–º –¥–ª—è —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞\n",
        "- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è** –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏\n",
        "- **ML-–ø–æ–¥—Ö–æ–¥** –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å –∫ –∏–∑–º–µ–Ω—è—é—â–∏–º—Å—è —Ä—ã–Ω–æ—á–Ω—ã–º —É—Å–ª–æ–≤–∏—è–º\n",
        "- **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏** –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –∏ —Å–∏–≥–Ω–∞–ª—å–Ω—ã–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –ø–æ–≤—ã—à–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã\n",
        "\n",
        "**–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Ç–æ—Ä–≥–æ–≤–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π!** üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
