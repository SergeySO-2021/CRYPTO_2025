{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –†–´–ù–û–ß–ù–´–• –†–ï–ñ–ò–ú–û–í\n",
        "\n",
        "## üìä –ù–ê–ó–ù–ê–ß–ï–ù–ò–ï\n",
        "–°—Ç–∞—Ç–∏—á–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ –±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
        "\n",
        "### üéØ –ü–†–ò–ù–¶–ò–ü–´:\n",
        "- ‚úÖ **–°–¢–ê–¢–ò–ß–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò** - –Ω–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –ø–æ–¥ –¥–∞–Ω–Ω—ã–µ\n",
        "- ‚úÖ **–¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ò –û–ë–û–°–ù–û–í–ê–ù–ù–´–ï** - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
        "- ‚úÖ **–û–ë–™–ï–ö–¢–ò–í–ù–ê–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø** - –∏–∑–±–µ–≥–∞–µ–º –ø–æ—Ä–æ—á–Ω–æ–≥–æ –∫—Ä—É–≥–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
        "\n",
        "### üîç –†–´–ù–û–ß–ù–´–ï –†–ï–ñ–ò–ú–´:\n",
        "1. **–°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥ –≤–≤–µ—Ä—Ö** - ADX > 30, Choppiness < 38.2, —Ü–µ–Ω–∞ —Ä–∞—Å—Ç–µ—Ç\n",
        "2. **–°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥ –≤–Ω–∏–∑** - ADX > 30, Choppiness < 38.2, —Ü–µ–Ω–∞ –ø–∞–¥–∞–µ—Ç\n",
        "3. **–§–ª–µ—Ç** - ADX < 20, Choppiness > 61.8\n",
        "4. **–í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å** - Bollinger Bands Width –≤ –≤–µ—Ä—Ö–Ω–∏—Ö 20%\n",
        "5. **–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ** - –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "EPS = 1e-12\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ –ò–º–ø–æ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è –°–û–ó–î–ê–ù–ò–ï –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê –†–´–ù–û–ß–ù–´–• –†–ï–ñ–ò–ú–û–í\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AdvancedMarketRegimeClassifier:\n",
        "    \"\"\"\n",
        "    –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ô –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –†–´–ù–û–ß–ù–´–• –†–ï–ñ–ò–ú–û–í (–±–µ–∑ ML)\n",
        "\n",
        "    –ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n",
        "    - Wilder RSI, ADX/DI (—É—Å—Ç–æ–π—á–∏–≤—ã–µ —Ñ–æ—Ä–º—É–ª—ã –∏ –∑–∞—â–∏—Ç–∞ –¥–µ–ª–µ–Ω–∏–π)\n",
        "    - –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π BB width\n",
        "    - –≠–∫–∑–æ-–ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–∏ (ex-ante) –¥–ª—è –ø–æ—Ä–æ–≥–æ–≤ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (shift +1)\n",
        "    - –ö–æ–º–ø–æ–∑–∏—Ç–Ω–∞—è —Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞: SMA cross + DI sign + –æ–±—ä–µ–º\n",
        "    - –ì–∏—Å—Ç–µ—Ä–µ–∑–∏—Å –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–µ–∂–∏–º–∞\n",
        "    - –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.parameters = {\n",
        "            'adx': {'strong_trend': 30, 'weak_trend': 20, 'no_trend': 15, 'period': 14},\n",
        "            'choppiness': {'trend_threshold': 38.2, 'flat_threshold': 61.8, 'period': 14},\n",
        "            'volatility': {\n",
        "                'lookback_percentile': 252,\n",
        "                'low_percentile': 0.20,\n",
        "                'high_percentile': 0.80,\n",
        "                'bb_period': 20,\n",
        "                'bb_std': 2.0\n",
        "            },\n",
        "            'rsi': {'period': 14, 'overbought': 70, 'oversold': 30},\n",
        "            'statistical': {'z_score_threshold': 2.0, 'min_trend_bars': 5, 'regime_persistence': 3}\n",
        "        }\n",
        "        self.regime_hierarchy = [\n",
        "            'high_volatility_crash', 'high_volatility_rally',\n",
        "            'strong_trend_up', 'strong_trend_down',\n",
        "            'weak_trend_up', 'weak_trend_down',\n",
        "            'consolidation_high_vol', 'consolidation_low_vol',\n",
        "            'ranging_market', 'uncertain'\n",
        "        ]\n",
        "        print(\"üéØ AdvancedMarketRegimeClassifier –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!\")\n",
        "\n",
        "    # ---------- –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ----------\n",
        "    def _rsi_wilder(self, close: pd.Series) -> pd.Series:\n",
        "        period = self.parameters['rsi']['period']\n",
        "        delta = close.diff()\n",
        "        gain = delta.clip(lower=0.0)\n",
        "        loss = -delta.clip(upper=0.0)\n",
        "        avg_gain = gain.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
        "        avg_loss = loss.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
        "        rs = avg_gain / (avg_loss + EPS)\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "        return rsi\n",
        "\n",
        "    def _bb_width_relative(self, close: pd.Series) -> pd.Series:\n",
        "        period = self.parameters['volatility']['bb_period']\n",
        "        std_mult = self.parameters['volatility']['bb_std']\n",
        "        sma = close.rolling(window=period, min_periods=period).mean()\n",
        "        std = close.rolling(window=period, min_periods=period).std(ddof=0)\n",
        "        upper = sma + std_mult * std\n",
        "        lower = sma - std_mult * std\n",
        "        width = (upper - lower) / (sma.abs() + EPS)\n",
        "        return width\n",
        "\n",
        "    def _adx_di_wilder(self, high: pd.Series, low: pd.Series, close: pd.Series) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
        "        period = self.parameters['adx']['period']\n",
        "        up_move = high.diff()\n",
        "        down_move = -low.diff()\n",
        "        plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0.0)\n",
        "        minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)\n",
        "        plus_dm = pd.Series(plus_dm, index=high.index)\n",
        "        minus_dm = pd.Series(minus_dm, index=high.index)\n",
        "        prev_close = close.shift(1)\n",
        "        tr = pd.concat([(high - low), (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)\n",
        "        atr = tr.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
        "        plus_di = 100 * (plus_dm.ewm(alpha=1/period, adjust=False, min_periods=period).mean() / (atr + EPS))\n",
        "        minus_di = 100 * (minus_dm.ewm(alpha=1/period, adjust=False, min_periods=period).mean() / (atr + EPS))\n",
        "        dx = 100 * (plus_di - minus_di).abs() / (plus_di + minus_di + EPS)\n",
        "        adx = dx.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
        "        return adx, plus_di, minus_di\n",
        "\n",
        "    def _choppiness_index(self, high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:\n",
        "        period = self.parameters['choppiness']['period']\n",
        "        prev_close = close.shift(1)\n",
        "        tr = pd.concat([(high - low), (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)\n",
        "        sum_tr = tr.rolling(window=period, min_periods=period).sum()\n",
        "        highest_high = high.rolling(window=period, min_periods=period).max()\n",
        "        lowest_low = low.rolling(window=period, min_periods=period).min()\n",
        "        range_hl = (highest_high - lowest_low).replace(0, np.nan)\n",
        "        chop = 100 * np.log10((sum_tr + EPS) / (range_hl + EPS)) / np.log10(period)\n",
        "        return chop\n",
        "\n",
        "    def _rolling_percentiles_ex_ante(self, series: pd.Series) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
        "        lookback = self.parameters['volatility']['lookback_percentile']\n",
        "        low_q = self.parameters['volatility']['low_percentile']\n",
        "        high_q = self.parameters['volatility']['high_percentile']\n",
        "        low_thr = series.rolling(window=lookback, min_periods=lookback).quantile(low_q).shift(1)\n",
        "        high_thr = series.rolling(window=lookback, min_periods=lookback).quantile(high_q).shift(1)\n",
        "        def ex_ante_pct(window: pd.Series) -> float:\n",
        "            vals = window[:-1].values\n",
        "            if len(vals) == 0:\n",
        "                return np.nan\n",
        "            current = window.iloc[-1]\n",
        "            return (np.searchsorted(np.sort(vals), current, side='right') / len(vals))\n",
        "        pct = series.rolling(window=lookback + 1, min_periods=lookback + 1).apply(ex_ante_pct, raw=False)\n",
        "        return low_thr, high_thr, pct\n",
        "\n",
        "    def _volume_profile(self, volume: pd.Series, lookback: int = 20) -> pd.Series:\n",
        "        volume_ma = volume.rolling(window=lookback, min_periods=lookback).mean()\n",
        "        return volume / (volume_ma + EPS)\n",
        "\n",
        "    def _atr_pct(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:\n",
        "        prev_close = close.shift(1)\n",
        "        tr = pd.concat([(high - low), (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)\n",
        "        atr = tr.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
        "        return atr / (close.abs() + EPS)\n",
        "\n",
        "    def _return_zscore(self, close: pd.Series, lookback: int = 63) -> pd.Series:\n",
        "        ret = close.pct_change()\n",
        "        mean = ret.rolling(window=lookback, min_periods=lookback).mean().shift(1)\n",
        "        std = ret.rolling(window=lookback, min_periods=lookback).std(ddof=0).shift(1)\n",
        "        z = (ret - mean) / (std + EPS)\n",
        "        return z\n",
        "\n",
        "    # ---------- –ö–æ–º–ø–æ–∑–∏—Ç–Ω–∞—è –ª–æ–≥–∏–∫–∞ ----------\n",
        "    def _trend_strength(self, close: pd.Series, adx: pd.Series, choppiness: pd.Series, volume_ratio: pd.Series, plus_di: pd.Series, minus_di: pd.Series) -> pd.Series:\n",
        "        sma_short = close.rolling(window=20, min_periods=20).mean()\n",
        "        sma_long = close.rolling(window=50, min_periods=50).mean()\n",
        "        price_trend = np.where(sma_short > sma_long, 1, -1)\n",
        "        adx_strength = np.select([\n",
        "            adx > self.parameters['adx']['strong_trend'],\n",
        "            adx > self.parameters['adx']['weak_trend'],\n",
        "            adx > self.parameters['adx']['no_trend']\n",
        "        ], [2, 1, 0], default=0)\n",
        "        choppy_trend = np.where(choppiness < self.parameters['choppiness']['trend_threshold'], 1, 0)\n",
        "        di_sign = np.where(plus_di > minus_di, 1, -1)\n",
        "        volume_support = np.where(volume_ratio > 1.2, 1, 0)\n",
        "        strength = (price_trend * 0.4 + di_sign * 0.3) * (adx_strength * 0.2 + choppy_trend * 0.3 + volume_support * 0.5)\n",
        "        return pd.Series(strength, index=close.index)\n",
        "\n",
        "    def _hysteresis(self, series: pd.Series, enter: float, exit: float) -> pd.Series:\n",
        "        state = False\n",
        "        out = []\n",
        "        for v in series.fillna(0).values:\n",
        "            if not state and v >= enter:\n",
        "                state = True\n",
        "            elif state and v <= exit:\n",
        "                state = False\n",
        "            out.append(1 if state else 0)\n",
        "        return pd.Series(out, index=series.index)\n",
        "\n",
        "    # ---------- –ü—É–±–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã ----------\n",
        "    def classify_market_regime(self, data: pd.DataFrame) -> Tuple[List[str], pd.DataFrame]:\n",
        "        print(\"üîç –ù–∞—á–∏–Ω–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤...\")\n",
        "        adx, plus_di, minus_di = self._adx_di_wilder(data['high'], data['low'], data['close'])\n",
        "        choppiness = self._choppiness_index(data['high'], data['low'], data['close'])\n",
        "        bb_width = self._bb_width_relative(data['close'])\n",
        "        rsi = self._rsi_wilder(data['close'])\n",
        "        volume_ratio = self._volume_profile(data['volume']) if 'volume' in data.columns else pd.Series(np.nan, index=data.index)\n",
        "        low_thr, high_thr, vol_pct = self._rolling_percentiles_ex_ante(bb_width)\n",
        "        trend_strength = self._trend_strength(data['close'], adx, choppiness, volume_ratio, plus_di, minus_di)\n",
        "        atr_pct = self._atr_pct(data['high'], data['low'], data['close'])\n",
        "        ret_z = self._return_zscore(data['close'])\n",
        "\n",
        "        regimes = []\n",
        "        details = []\n",
        "        for i in range(len(data)):\n",
        "            if i < max(252, 50):\n",
        "                regimes.append('insufficient_data')\n",
        "                details.append({'reason': 'insufficient_data'})\n",
        "                continue\n",
        "            cur = {\n",
        "                'adx': adx.iloc[i],\n",
        "                'chop': choppiness.iloc[i],\n",
        "                'bb': bb_width.iloc[i],\n",
        "                'rsi': rsi.iloc[i],\n",
        "                'vol_ratio': volume_ratio.iloc[i] if 'volume' in data.columns else np.nan,\n",
        "                'ts': trend_strength.iloc[i],\n",
        "                'low_thr': low_thr.iloc[i],\n",
        "                'high_thr': high_thr.iloc[i],\n",
        "                'vol_pct': vol_pct.iloc[i],\n",
        "                'plus_di': plus_di.iloc[i],\n",
        "                'minus_di': minus_di.iloc[i],\n",
        "                'atr_pct': atr_pct.iloc[i],\n",
        "                'ret_z': ret_z.iloc[i],\n",
        "                'open': data['open'].iloc[i] if 'open' in data.columns else data['close'].iloc[i-1],\n",
        "                'close': data['close'].iloc[i]\n",
        "            }\n",
        "            if any(pd.isna([cur['adx'], cur['chop'], cur['bb'], cur['ts'], cur['low_thr'], cur['high_thr'], cur['vol_pct']])):\n",
        "                regimes.append('insufficient_data')\n",
        "                details.append({'reason': 'nan_values'})\n",
        "                continue\n",
        "            is_high_vol = cur['bb'] > cur['high_thr']\n",
        "            is_low_vol = cur['bb'] < cur['low_thr']\n",
        "            is_strong_trend = cur['adx'] > self.parameters['adx']['strong_trend']\n",
        "            is_weak_trend = self.parameters['adx']['weak_trend'] <= cur['adx'] <= self.parameters['adx']['strong_trend']\n",
        "            is_choppy_trend = cur['chop'] < self.parameters['choppiness']['trend_threshold']\n",
        "            is_choppy_flat = cur['chop'] > self.parameters['choppiness']['flat_threshold']\n",
        "            price_up = cur['close'] > cur['open']\n",
        "\n",
        "            # Crash / rally —É—Ç–æ—á–Ω–µ–Ω–∏–µ: –≤—ã—Å–æ–∫–∏–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ + —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π ret_z –∏/–∏–ª–∏ –≤—ã—Å–æ–∫–∏–π ATR%\n",
        "            if is_high_vol and (cur['ts'] < -1.5) and (cur['vol_pct'] > 0.9) and ((cur['ret_z'] < -2.0) or (cur['atr_pct'] > 0.03)):\n",
        "                regimes.append('high_volatility_crash')\n",
        "                details.append({'reason': 'high_volatility_crash', 'vol_pct': cur['vol_pct'], 'ts': cur['ts'], 'ret_z': cur['ret_z'], 'atr_pct': cur['atr_pct']})\n",
        "            elif is_high_vol and (cur['ts'] > 1.5) and (cur['vol_pct'] > 0.9) and ((cur['ret_z'] > 2.0) or (cur['atr_pct'] > 0.03)):\n",
        "                regimes.append('high_volatility_rally')\n",
        "                details.append({'reason': 'high_volatility_rally', 'vol_pct': cur['vol_pct'], 'ts': cur['ts'], 'ret_z': cur['ret_z'], 'atr_pct': cur['atr_pct']})\n",
        "            elif is_strong_trend and is_choppy_trend and cur['ts'] > 1.0 and price_up:\n",
        "                regimes.append('strong_trend_up')\n",
        "                details.append({'reason': 'strong_trend_up'})\n",
        "            elif is_strong_trend and is_choppy_trend and cur['ts'] < -1.0 and not price_up:\n",
        "                regimes.append('strong_trend_down')\n",
        "                details.append({'reason': 'strong_trend_down'})\n",
        "            elif is_weak_trend and is_choppy_trend and cur['ts'] > 0.5 and price_up:\n",
        "                regimes.append('weak_trend_up')\n",
        "                details.append({'reason': 'weak_trend_up'})\n",
        "            elif is_weak_trend and is_choppy_trend and cur['ts'] < -0.5 and not price_up:\n",
        "                regimes.append('weak_trend_down')\n",
        "                details.append({'reason': 'weak_trend_down'})\n",
        "            elif is_high_vol and is_choppy_flat and abs(cur['ts']) < 0.5:\n",
        "                regimes.append('consolidation_high_vol')\n",
        "                details.append({'reason': 'consolidation_high_vol'})\n",
        "            elif is_low_vol and is_choppy_flat and abs(cur['ts']) < 0.5:\n",
        "                regimes.append('consolidation_low_vol')\n",
        "                details.append({'reason': 'consolidation_low_vol'})\n",
        "            elif is_choppy_flat and abs(cur['ts']) < 1.0:\n",
        "                regimes.append('ranging_market')\n",
        "                details.append({'reason': 'ranging_market'})\n",
        "            else:\n",
        "                regimes.append('uncertain')\n",
        "                details.append({'reason': 'uncertain'})\n",
        "\n",
        "        regimes = self._apply_persistence(regimes)\n",
        "        classification_data = pd.DataFrame({\n",
        "            'adx': adx,\n",
        "            'plus_di': plus_di,\n",
        "            'minus_di': minus_di,\n",
        "            'choppiness': choppiness,\n",
        "            'bb_width': bb_width,\n",
        "            'rsi': rsi,\n",
        "            'volume_ratio': volume_ratio,\n",
        "            'trend_strength': trend_strength,\n",
        "            'volatility_percentile': vol_pct,\n",
        "            'regime': regimes\n",
        "        }, index=data.index)\n",
        "        classification_data['classification_details'] = details\n",
        "        self._print_regime_stats(regimes)\n",
        "        return regimes, classification_data\n",
        "\n",
        "    def _apply_persistence(self, regimes: List[str]) -> List[str]:\n",
        "        if len(regimes) < 3:\n",
        "            return regimes\n",
        "        min_persist = self.parameters['statistical']['regime_persistence']\n",
        "        smoothed = regimes.copy()\n",
        "        i = 0\n",
        "        while i < len(regimes):\n",
        "            j = i\n",
        "            while j < len(regimes) and regimes[j] == regimes[i]:\n",
        "                j += 1\n",
        "            run_len = j - i\n",
        "            if run_len < min_persist:\n",
        "                # –∑–∞–º–µ–Ω—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–±–µ–≥ –Ω–∞ —Å–æ—Å–µ–¥–Ω–∏–π –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π —Ä–µ–∂–∏–º\n",
        "                left = regimes[i-1] if i - 1 >= 0 else None\n",
        "                right = regimes[j] if j < len(regimes) else None\n",
        "                fill = right if right is not None else left\n",
        "                for k in range(i, j):\n",
        "                    smoothed[k] = fill if fill is not None else regimes[k]\n",
        "            i = j\n",
        "        return smoothed\n",
        "\n",
        "    def _print_regime_stats(self, regimes: List[str]):\n",
        "        counts = pd.Series(regimes).value_counts()\n",
        "        total = len(regimes)\n",
        "        print(\"\\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–´–ù–û–ß–ù–´–• –†–ï–ñ–ò–ú–û–í:\")\n",
        "        print(\"=\" * 50)\n",
        "        for regime in self.regime_hierarchy:\n",
        "            if regime in counts:\n",
        "                c = counts[regime]\n",
        "                print(f\"   ‚Ä¢ {regime:25s}: {c:4d} –±–∞—Ä–æ–≤ ({(c/total)*100:5.1f}%)\")\n",
        "        sufficient = [r for r in regimes if r != 'insufficient_data']\n",
        "        if sufficient:\n",
        "            print(f\"\\n   ‚Ä¢ –í—Å–µ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {len(sufficient)} –±–∞—Ä–æ–≤\")\n",
        "            print(f\"   ‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {total - len(sufficient)} –±–∞—Ä–æ–≤\")\n",
        "\n",
        "    # ---------- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ----------\n",
        "    def get_detailed_statistics(self, classification_data: pd.DataFrame) -> Dict:\n",
        "        valid = classification_data[classification_data['regime'] != 'insufficient_data']\n",
        "        def transitions(series: pd.Series) -> pd.DataFrame:\n",
        "            pairs = []\n",
        "            prev = None\n",
        "            for r in series:\n",
        "                if prev and prev != r:\n",
        "                    pairs.append((prev, r))\n",
        "                prev = r\n",
        "            if not pairs:\n",
        "                return pd.DataFrame()\n",
        "            df = pd.DataFrame(pairs, columns=['from', 'to'])\n",
        "            return pd.crosstab(df['from'], df['to'], normalize='index')\n",
        "        def durations(series: pd.Series) -> Dict[str, float]:\n",
        "            dur = {}\n",
        "            cur = None\n",
        "            run = 0\n",
        "            for r in series:\n",
        "                if r == cur:\n",
        "                    run += 1\n",
        "                else:\n",
        "                    if cur:\n",
        "                        dur.setdefault(cur, []).append(run)\n",
        "                    cur = r\n",
        "                    run = 1\n",
        "            if cur:\n",
        "                dur.setdefault(cur, []).append(run)\n",
        "            return {k: float(np.mean(v)) for k, v in dur.items()}\n",
        "        stats = {\n",
        "            'regime_counts': valid['regime'].value_counts(),\n",
        "            'regime_percentages': valid['regime'].value_counts(normalize=True) * 100,\n",
        "            'indicators_by_regime': valid.groupby('regime').agg({\n",
        "                'adx': ['mean', 'std', 'min', 'max'],\n",
        "                'choppiness': ['mean', 'std', 'min', 'max'],\n",
        "                'bb_width': ['mean', 'std', 'min', 'max'],\n",
        "                'rsi': ['mean', 'std', 'min', 'max'],\n",
        "                'volume_ratio': ['mean', 'std', 'min', 'max'],\n",
        "                'trend_strength': ['mean', 'std', 'min', 'max']\n",
        "            }),\n",
        "            'regime_transitions': transitions(valid['regime']),\n",
        "            'regime_durations': durations(valid['regime'])\n",
        "        }\n",
        "        return stats\n",
        "\n",
        "    def visualize_regime_analysis(self, data: pd.DataFrame, classification_data: pd.DataFrame, title: str = \"–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ BTC\"):\n",
        "        fig, axes = plt.subplots(4, 1, figsize=(16, 14))\n",
        "        regime_colors = {\n",
        "            'strong_trend_up': '#00ff00',\n",
        "            'strong_trend_down': '#ff0000',\n",
        "            'weak_trend_up': '#90ee90',\n",
        "            'weak_trend_down': '#ffcccb',\n",
        "            'high_volatility_rally': '#ffa500',\n",
        "            'high_volatility_crash': '#8b0000',\n",
        "            'consolidation_high_vol': '#ff69b4',\n",
        "            'consolidation_low_vol': '#9370db',\n",
        "            'ranging_market': '#1e90ff',\n",
        "            'uncertain': '#a9a9a9',\n",
        "            'insufficient_data': '#000000'\n",
        "        }\n",
        "        axes[0].plot(data.index, data['close'], label='BTC Price', color='black', alpha=0.8, linewidth=1)\n",
        "        for regime in classification_data['regime'].unique():\n",
        "            if regime in regime_colors:\n",
        "                mask = classification_data['regime'] == regime\n",
        "                if mask.any():\n",
        "                    axes[0].scatter(data.index[mask], data['close'][mask], c=regime_colors[regime], label=regime, alpha=0.7, s=12)\n",
        "        axes[0].set_title(f'{title}\\n–¶–µ–Ω–∞ BTC —Å —Ä—ã–Ω–æ—á–Ω—ã–º–∏ —Ä–µ–∂–∏–º–∞–º–∏', fontsize=14, fontweight='bold')\n",
        "        axes[0].set_ylabel('–¶–µ–Ω–∞ BTC', fontweight='bold')\n",
        "        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –ª–µ–≥–µ–Ω–¥–µ, –µ—Å–ª–∏ –∏—Ö —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ\n",
        "        handles, labels = axes[0].get_legend_handles_labels()\n",
        "        if len(labels) > 9:\n",
        "            axes[0].legend(handles[:9], labels[:9], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        else:\n",
        "            axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        axes[1].plot(classification_data.index, classification_data['adx'], label='ADX', color='purple', linewidth=1)\n",
        "        axes[1].axhline(y=self.parameters['adx']['strong_trend'], color='red', linestyle='--', alpha=0.7, label='–°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥')\n",
        "        axes[1].axhline(y=self.parameters['adx']['weak_trend'], color='orange', linestyle='--', alpha=0.7, label='–°–ª–∞–±—ã–π —Ç—Ä–µ–Ω–¥')\n",
        "        axes[1].set_ylabel('ADX', fontweight='bold')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        axes[2].plot(classification_data.index, classification_data['choppiness'], label='Choppiness Index', color='blue', linewidth=1)\n",
        "        axes[2].axhline(y=self.parameters['choppiness']['flat_threshold'], color='red', linestyle='--', alpha=0.7, label='–§–ª–µ—Ç')\n",
        "        axes[2].axhline(y=self.parameters['choppiness']['trend_threshold'], color='green', linestyle='--', alpha=0.7, label='–¢—Ä–µ–Ω–¥')\n",
        "        axes[2].set_ylabel('Choppiness Index', fontweight='bold')\n",
        "        axes[2].legend()\n",
        "        axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "        ax4 = axes[3]\n",
        "        ax4_twin = ax4.twinx()\n",
        "        ax4.plot(classification_data.index, classification_data['bb_width'], label='–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (BB Width)', color='brown', linewidth=1)\n",
        "        ax4.set_ylabel('–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å', fontweight='bold', color='brown')\n",
        "        ax4.tick_params(axis='y', labelcolor='brown')\n",
        "\n",
        "        ax4_twin.plot(classification_data.index, classification_data['rsi'], label='RSI', color='gray', linewidth=1, alpha=0.7)\n",
        "        ax4_twin.axhline(y=70, color='red', linestyle='--', alpha=0.5, label='–ü–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å')\n",
        "        ax4_twin.axhline(y=30, color='green', linestyle='--', alpha=0.5, label='–ü–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å')\n",
        "        ax4_twin.axhline(y=50, color='black', linestyle='-', alpha=0.3)\n",
        "        ax4_twin.set_ylabel('RSI', fontweight='bold', color='gray')\n",
        "        ax4_twin.tick_params(axis='y', labelcolor='gray')\n",
        "        ax4_twin.set_ylim(0, 100)\n",
        "\n",
        "        ax4.set_xlabel('–î–∞—Ç–∞', fontweight='bold')\n",
        "        # –°—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ–º –ª–µ–≥–µ–Ω–¥—ã –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º –≥—Ä–∞—Ñ–∏–∫–µ\n",
        "        l1, l2 = ax4.get_legend_handles_labels()\n",
        "        r1, r2 = ax4_twin.get_legend_handles_labels()\n",
        "        ax4.legend(l1 + r1, r2 + r2, loc='upper left')\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        return fig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ BTC –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "print(\"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö BTC –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...\")\n",
        "df = pd.read_csv('df_btc_1h.csv', index_col=0, parse_dates=True)\n",
        "print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π\")\n",
        "print(f\"üìÖ –ü–µ—Ä–∏–æ–¥: {df.index[0]} - {df.index[-1]}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–∑–¥–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ–º\n",
        "print(\"üéØ –°–û–ó–î–ê–ù–ò–ï –ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "classifier = AdvancedMarketRegimeClassifier()\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)\n",
        "print(\"üîç –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –†–´–ù–û–ß–ù–´–• –†–ï–ñ–ò–ú–û–í\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "regimes, classification_data = classifier.classify_market_regime(df)\n",
        "\n",
        "print(\"\\n‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
        "print(f\"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(regimes)} –±–∞—Ä–æ–≤\")\n",
        "print(f\"üìà –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤: {len(set(regimes))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–µ–∂–∏–º–∞–º (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è)\n",
        "print(\"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –†–´–ù–û–ß–ù–´–ú –†–ï–ñ–ò–ú–ê–ú\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "stats = classifier.get_detailed_statistics(classification_data)\n",
        "\n",
        "print(\"\\nüìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤:\")\n",
        "for regime, count in stats['regime_counts'].items():\n",
        "    percentage = stats['regime_percentages'][regime]\n",
        "    print(f\"   ‚Ä¢ {regime}: {count} –±–∞—Ä–æ–≤ ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\nüìä –°–≤–æ–¥–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–æ —Ä–µ–∂–∏–º–∞–º:\")\n",
        "print(stats['indicators_by_regime'])\n",
        "\n",
        "print(\"\\nüîÅ –ú–∞—Ç—Ä–∏—Ü–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (–Ω–æ—Ä–º.):\")\n",
        "print(stats['regime_transitions'])\n",
        "\n",
        "print(\"\\n‚è± –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–µ–∂–∏–º–æ–≤ (–±–∞—Ä—ã):\")\n",
        "print(stats['regime_durations'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑)\n",
        "print(\"üìä –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–´–ù–û–ß–ù–´–• –†–ï–ñ–ò–ú–û–í\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 –±–∞—Ä–æ–≤ –¥–ª—è –ª—É—á—à–µ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "recent_data = df.tail(1000)\n",
        "recent_classification = classification_data.tail(1000)\n",
        "\n",
        "fig = classifier.visualize_regime_analysis(recent_data, recent_classification, \"BTC 1H - –ü–æ—Å–ª–µ–¥–Ω–∏–µ 1000 –±–∞—Ä–æ–≤\")\n",
        "\n",
        "print(\"‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 20 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "print(\"üìã –ü–ï–†–í–´–ï 20 –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "sample_data = classification_data.head(20)[['adx', 'choppiness', 'bb_width', 'regime']]\n",
        "print(sample_data.to_string())\n",
        "\n",
        "print(\"\\nüìä –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –†–ï–ñ–ò–ú–û–í:\")\n",
        "print(\"   ‚Ä¢ strong_trend_up: –°–∏–ª—å–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥\")\n",
        "print(\"   ‚Ä¢ strong_trend_down: –°–∏–ª—å–Ω—ã–π –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥\")\n",
        "print(\"   ‚Ä¢ weak_trend_up: –°–ª–∞–±—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥\")\n",
        "print(\"   ‚Ä¢ weak_trend_down: –°–ª–∞–±—ã–π –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥\")\n",
        "print(\"   ‚Ä¢ flat_market: –ë–æ–∫–æ–≤–æ–π —Ä—ã–Ω–æ–∫ (—Ñ–ª–µ—Ç)\")\n",
        "print(\"   ‚Ä¢ volatile_market: –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\")\n",
        "print(\"   ‚Ä¢ uncertain: –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ\")\n",
        "print(\"   ‚Ä¢ insufficient_data: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï\n",
        "\n",
        "### ‚úÖ **–ß–¢–û –ú–´ –°–û–ó–î–ê–õ–ò:**\n",
        "1. **–°—Ç–∞—Ç–∏—á–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤** - –±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "2. **–û–±—ä–µ–∫—Ç–∏–≤–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é** - –æ—Å–Ω–æ–≤–∞–Ω–Ω—É—é –Ω–∞ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö\n",
        "3. **7 —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤** - –æ—Ç —Å–∏–ª—å–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤ –¥–æ —Ñ–ª–µ—Ç–∞\n",
        "4. **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤** - –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–∞–±–æ—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞\n",
        "\n",
        "### üéØ **–°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:**\n",
        "1. **–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–∏–≥–Ω–∞–ª—å–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤** –ø–æ –≤—ã—è–≤–ª–µ–Ω–Ω—ã–º —Ä–µ–∂–∏–º–∞–º\n",
        "2. **–¶–µ–ª–µ–≤–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** —Å–∏–≥–Ω–∞–ª—å–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∂–∏–º—ã\n",
        "3. **–°–æ–∑–¥–∞–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã** - –≤—ã–±–æ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞\n",
        "\n",
        "### üí° **–ö–õ–Æ–ß–ï–í–´–ï –ü–†–ò–ù–¶–ò–ü–´:**\n",
        "- ‚úÖ **–ù–ï –û–ü–¢–ò–ú–ò–ó–ò–†–£–ï–ú** –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤\n",
        "- ‚úÖ **–ò–°–ü–û–õ–¨–ó–£–ï–ú** —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
        "- ‚úÖ **–ò–ó–ë–ï–ì–ê–ï–ú** –ø–æ—Ä–æ—á–Ω–æ–≥–æ –∫—Ä—É–≥–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
        "- ‚úÖ **–°–û–ó–î–ê–ï–ú** –æ–±—ä–µ–∫—Ç–∏–≤–Ω—É—é –æ—Å–Ω–æ–≤—É –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ä–∞–±–æ—Ç—ã\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –û–¶–ï–ù–ö–ò –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "FORWARD_HORIZONS = [1, 3, 5, 10]\n",
        "\n",
        "def compute_forward_returns(close: pd.Series, horizons=FORWARD_HORIZONS) -> pd.DataFrame:\n",
        "    out = {}\n",
        "    for h in horizons:\n",
        "        out[f'r_forward_{h}'] = close.shift(-h) / close - 1.0\n",
        "    return pd.DataFrame(out, index=close.index)\n",
        "\n",
        "def sharpe_ratio(returns: pd.Series) -> float:\n",
        "    mu = returns.mean()\n",
        "    sd = returns.std(ddof=0)\n",
        "    if sd == 0 or np.isnan(sd):\n",
        "        return np.nan\n",
        "    return mu / sd\n",
        "\n",
        "def sign_accuracy(returns: pd.Series, direction: int) -> float:\n",
        "    if direction not in (-1, 1):\n",
        "        return np.nan\n",
        "    valid = returns.dropna()\n",
        "    if len(valid) == 0:\n",
        "        return np.nan\n",
        "    return (np.sign(valid) == direction).mean()\n",
        "\n",
        "def regime_run_lengths(regimes: pd.Series) -> pd.Series:\n",
        "    lengths = []\n",
        "    prev = None\n",
        "    run = 0\n",
        "    for r in regimes:\n",
        "        if r == prev:\n",
        "            run += 1\n",
        "        else:\n",
        "            if prev is not None:\n",
        "                lengths.append(run)\n",
        "            prev = r\n",
        "            run = 1\n",
        "    if prev is not None:\n",
        "        lengths.append(run)\n",
        "    return pd.Series(lengths, dtype=float)\n",
        "\n",
        "def stability_metrics(regimes: pd.Series) -> dict:\n",
        "    runs = regime_run_lengths(regimes)\n",
        "    switches_per_1000 = 0.0 if len(regimes) == 0 else (len(runs) - 1) / max(len(regimes), 1) * 1000.0\n",
        "    uncertain_share = (regimes == 'uncertain').mean()\n",
        "    return {\n",
        "        'avg_run_length': runs.mean() if len(runs) else np.nan,\n",
        "        'switches_per_1000': switches_per_1000,\n",
        "        'uncertain_share': uncertain_share,\n",
        "    }\n",
        "\n",
        "def simple_regime_position(regime: str) -> int:\n",
        "    if regime in ('strong_trend_up', 'weak_trend_up'):\n",
        "        return 1\n",
        "    if regime in ('strong_trend_down', 'weak_trend_down'):\n",
        "        return -1\n",
        "    return 0\n",
        "\n",
        "def backtest_regime_on_off(close: pd.Series, regimes: pd.Series) -> dict:\n",
        "    ret = close.pct_change()\n",
        "    pos = regimes.fillna('uncertain').map(simple_regime_position).astype(float)\n",
        "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–∑–∏—Ü–∏—é —Å–æ —Å–¥–≤–∏–≥–æ–º, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ look-ahead\n",
        "    strat_ret = pos.shift(1) * ret\n",
        "    bh_ret = ret\n",
        "    out = {\n",
        "        'strat_return_mean': strat_ret.mean(),\n",
        "        'strat_return_std': strat_ret.std(ddof=0),\n",
        "        'strat_sharpe': sharpe_ratio(strat_ret),\n",
        "        'bh_return_mean': bh_ret.mean(),\n",
        "        'bh_return_std': bh_ret.std(ddof=0),\n",
        "        'bh_sharpe': sharpe_ratio(bh_ret),\n",
        "        'strat_cumret': float((1 + strat_ret.fillna(0)).prod() - 1),\n",
        "        'bh_cumret': float((1 + bh_ret.fillna(0)).prod() - 1),\n",
        "    }\n",
        "    return out\n",
        "\n",
        "def crash_rally_analysis(close: pd.Series, regimes: pd.Series, window: int = 10) -> dict:\n",
        "    ret = close.pct_change()\n",
        "    idx = close.index\n",
        "    results = {}\n",
        "    for tag in ('high_volatility_crash', 'high_volatility_rally'):\n",
        "        starts = idx[regimes == tag]\n",
        "        if len(starts) == 0:\n",
        "            results[tag] = {'signals': 0}\n",
        "            continue\n",
        "        prof = []\n",
        "        falses = 0\n",
        "        for t in starts:\n",
        "            if t not in idx:\n",
        "                continue\n",
        "            start_loc = idx.get_loc(t)\n",
        "            end_loc = min(start_loc + window, len(idx) - 1)\n",
        "            seg = ret.iloc[start_loc+1:end_loc+1]  # –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ —Å–∏–≥–Ω–∞–ª–∞\n",
        "            cum = (1 + seg.fillna(0)).prod() - 1\n",
        "            prof.append(cum)\n",
        "            if tag == 'high_volatility_crash' and cum > 0:\n",
        "                falses += 1\n",
        "            if tag == 'high_volatility_rally' and cum < 0:\n",
        "                falses += 1\n",
        "        prof = pd.Series(prof, dtype=float)\n",
        "        results[tag] = {\n",
        "            'signals': int(len(starts)),\n",
        "            'mean_cum_return_w'+str(window): float(prof.mean()) if len(prof) else np.nan,\n",
        "            'median_cum_return_w'+str(window): float(prof.median()) if len(prof) else np.nan,\n",
        "            'false_rate': float(falses / len(starts)) if len(starts) else np.nan,\n",
        "        }\n",
        "    return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üßÆ –û–¶–ï–ù–ö–ê –ù–ê –û–î–ù–û–ú –¢–ê–ô–ú–§–†–ï–ô–ú–ï (–ü–†–ò–ú–ï–†: 1H)\n",
        "print(\"üîé –û–¶–ï–ù–ö–ê –ù–ê 1H\")\n",
        "\n",
        "# 1) –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∂–∏–º—ã —É–∂–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –≤—ã—à–µ: classification_data\n",
        "fr = compute_forward_returns(df['close'])\n",
        "joined = classification_data.join(fr)\n",
        "\n",
        "# 2) –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–µ–∂–∏–º–∞–º\n",
        "rows = []\n",
        "for regime, grp in joined.groupby('regime'):\n",
        "    row = {'regime': regime}\n",
        "    for h in FORWARD_HORIZONS:\n",
        "        r = grp[f'r_forward_{h}']\n",
        "        row[f'mean_{h}'] = r.mean()\n",
        "        row[f'median_{h}'] = r.median()\n",
        "        row[f'sharpe_{h}'] = sharpe_ratio(r)\n",
        "    rows.append(row)\n",
        "per_regime_metrics_1h = pd.DataFrame(rows).set_index('regime').sort_index()\n",
        "print(per_regime_metrics_1h)\n",
        "\n",
        "# 3) –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–µ–∂–∏–º–æ–≤\n",
        "stab = stability_metrics(classification_data['regime'])\n",
        "print(\"\\n–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–µ–∂–∏–º–æ–≤:\", stab)\n",
        "\n",
        "# 4) –ê–Ω–∞–ª–∏–∑ crash/rally\n",
        "cr = crash_rally_analysis(df['close'], classification_data['regime'], window=10)\n",
        "print(\"\\nCrash/Rally –∞–Ω–∞–ª–∏–∑ (–æ–∫–Ω–æ=10):\", cr)\n",
        "\n",
        "# 5) –ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç —Ä–µ–∂–∏–º–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø—Ä–æ—Ç–∏–≤ buy&hold\n",
        "bt = backtest_regime_on_off(df['close'], classification_data['regime'])\n",
        "print(\"\\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–µ–∂–∏–º–æ–≤ vs buy&hold:\")\n",
        "print(bt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üåê –ú–£–õ–¨–¢–ò‚Äë–¢–ê–ô–ú–§–†–ï–ô–ú: –°–†–ê–í–ù–ï–ù–ò–ï –ú–ï–¢–†–ò–ö –ü–û –í–°–ï–ú 5 –¢–§\n",
        "import os\n",
        "\n",
        "files = [\n",
        "    ('15m', 'df_btc_15m.csv'),\n",
        "    ('30m', 'df_btc_30m.csv'),\n",
        "    ('1h', 'df_btc_1h.csv'),\n",
        "    ('4h', 'df_btc_4h.csv'),\n",
        "    ('1d', 'df_btc_1d.csv'),\n",
        "]\n",
        "\n",
        "summary_rows = []\n",
        "per_tf_tables = {}\n",
        "\n",
        "for tf, fname in files:\n",
        "    if not os.path.exists(fname):\n",
        "        print(f\"‚ö†Ô∏è –§–∞–π–ª {fname} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞—é {tf}\")\n",
        "        continue\n",
        "    print(f\"\\n‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {tf} ({fname})\")\n",
        "    d = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
        "    clf = AdvancedMarketRegimeClassifier()\n",
        "    regimes, cls = clf.classify_market_regime(d)\n",
        "\n",
        "    fr = compute_forward_returns(d['close'])\n",
        "    joined = cls.join(fr)\n",
        "\n",
        "    # –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫\n",
        "    rows = []\n",
        "    for regime, grp in joined.groupby('regime'):\n",
        "        row = {'regime': regime}\n",
        "        for h in FORWARD_HORIZONS:\n",
        "            r = grp[f'r_forward_{h}']\n",
        "            row[f'mean_{h}'] = r.mean()\n",
        "            row[f'median_{h}'] = r.median()\n",
        "            row[f'sharpe_{h}'] = sharpe_ratio(r)\n",
        "        rows.append(row)\n",
        "    table = pd.DataFrame(rows).set_index('regime').sort_index()\n",
        "    per_tf_tables[tf] = table\n",
        "\n",
        "    # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∏ –±—ç–∫—Ç–µ—Å—Ç\n",
        "    stab = stability_metrics(cls['regime'])\n",
        "    bt = backtest_regime_on_off(d['close'], cls['regime'])\n",
        "\n",
        "    summary_rows.append({\n",
        "        'tf': tf,\n",
        "        'avg_run_length': stab['avg_run_length'],\n",
        "        'switches_per_1000': stab['switches_per_1000'],\n",
        "        'uncertain_share': stab['uncertain_share'],\n",
        "        'strat_sharpe': bt['strat_sharpe'],\n",
        "        'bh_sharpe': bt['bh_sharpe'],\n",
        "        'strat_cumret': bt['strat_cumret'],\n",
        "        'bh_cumret': bt['bh_cumret']\n",
        "    })\n",
        "\n",
        "summary = pd.DataFrame(summary_rows).set_index('tf').sort_index()\n",
        "print(\"\\nüìä –°–≤–æ–¥–∫–∞ –ø–æ –¢–§:\")\n",
        "print(summary)\n",
        "\n",
        "print(\"\\nüìã –ü—Ä–∏–º–µ—Ä—ã —Ç–∞–±–ª–∏—Ü –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–µ–∂–∏–º–∞–º (1-2 –¢–§):\")\n",
        "for tf in list(per_tf_tables.keys())[:2]:\n",
        "    print(f\"\\n‚Äî {tf} ‚Äî\")\n",
        "    print(per_tf_tables[tf])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üß≠ TOP-DOWN –ê–ì–†–ï–ì–ê–¶–ò–Ø (HTF 1d/4h ‚Üí –±–∞–∑–æ–≤—ã–π –¢–§)\n",
        "import os\n",
        "\n",
        "def classify_df(file):\n",
        "    d = pd.read_csv(file, index_col=0, parse_dates=True)\n",
        "    clf = AdvancedMarketRegimeClassifier()\n",
        "    regimes, cls = clf.classify_market_regime(d)\n",
        "    return d, cls\n",
        "\n",
        "# 1) –ó–∞–≥—Ä—É–∂–∞–µ–º HTF: 1d –∏ 4h\n",
        "htf_files = [('1d', 'df_btc_1d.csv'), ('4h', 'df_btc_4h.csv')]\n",
        "htf_cls = {}\n",
        "for tf, fname in htf_files:\n",
        "    if os.path.exists(fname):\n",
        "        d_tf, cls_tf = classify_df(fname)\n",
        "        htf_cls[tf] = (d_tf, cls_tf)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è –ù–µ—Ç —Ñ–∞–π–ª–∞ {fname}, HTF {tf} –ø—Ä–æ–ø—É—â–µ–Ω\")\n",
        "\n",
        "# 2) –ë–∞–∑–æ–≤—ã–π –¢–§ (–ø—Ä–∏–º–µ—Ä ‚Äî 1h)\n",
        "base_tf = ('1h', 'df_btc_1h.csv')\n",
        "if not os.path.exists(base_tf[1]):\n",
        "    print(f\"‚ö†Ô∏è –ù–µ—Ç —Ñ–∞–π–ª–∞ {base_tf[1]}, –ø—Ä–æ–ø—É—Å–∫ top-down\")\n",
        "else:\n",
        "    d_base, cls_base = classify_df(base_tf[1])\n",
        "\n",
        "    # 3) –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º HTF –ø–æ –∏–Ω–¥–µ–∫—Å—É –±–∞–∑–æ–≤–æ–≥–æ –¢–§ (forward-fill –ø–æ –≤—Ä–µ–º–µ–Ω–∏)\n",
        "    def align_htf_to_base(htf_df):\n",
        "        htf_on_base = htf_df.reindex(d_base.index, method='ffill')\n",
        "        return htf_on_base\n",
        "\n",
        "    aligned = {}\n",
        "    for tf, (d_tf, cls_tf) in htf_cls.items():\n",
        "        aligned[tf] = align_htf_to_base(cls_tf[['regime']])\n",
        "\n",
        "    # 4) –ü—Ä–æ—Å—Ç–µ–π—à–µ–µ –ø—Ä–∞–≤–∏–ª–æ top-down\n",
        "    # –ï—Å–ª–∏ –¥–Ω–µ–≤–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤–∞—è ‚Äî –ø—Ä–∏–Ω–∏–º–∞–µ–º —Ç—Ä–µ–Ω–¥; –µ—Å–ª–∏ –¥–Ω–µ–≤–∫–∞ —Ñ–ª–µ—Ç/–∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è ‚Äî LTF —Ç—Ä–µ–Ω–¥—ã –ø–æ–Ω–∏–∂–∞–µ–º –¥–æ ranging\n",
        "    def gate_regime(htf_regime: str, ltf_regime: str) -> str:\n",
        "        trend_up = ('strong_trend_up', 'weak_trend_up')\n",
        "        trend_down = ('strong_trend_down', 'weak_trend_down')\n",
        "        cons = ('ranging_market', 'consolidation_high_vol', 'consolidation_low_vol')\n",
        "        if htf_regime in trend_up + trend_down:\n",
        "            return ltf_regime\n",
        "        if htf_regime in cons or htf_regime == 'uncertain':\n",
        "            if ltf_regime in trend_up + trend_down:\n",
        "                return 'ranging_market'\n",
        "            return ltf_regime\n",
        "        return ltf_regime\n",
        "\n",
        "    # 5) –§–æ—Ä–º–∏—Ä—É–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º 1d, –ø—Ä–∏ –µ–≥–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ ‚Äî 4h)\n",
        "    htf_primary = aligned.get('1d', aligned.get('4h'))\n",
        "    if htf_primary is None:\n",
        "        print(\"‚ö†Ô∏è –ù–µ—Ç HTF –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é top-down\")\n",
        "    else:\n",
        "        htf_series = htf_primary['regime']\n",
        "        ltf_series = cls_base['regime']\n",
        "        agg_regime = []\n",
        "        for t in d_base.index:\n",
        "            r_htf = htf_series.loc[t] if t in htf_series.index else 'uncertain'\n",
        "            r_ltf = ltf_series.loc[t] if t in ltf_series.index else 'uncertain'\n",
        "            agg_regime.append(gate_regime(r_htf, r_ltf))\n",
        "        agg_regime = pd.Series(agg_regime, index=d_base.index, name='regime_topdown')\n",
        "\n",
        "        # 6) –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ\n",
        "        fr = compute_forward_returns(d_base['close'])\n",
        "        joined = pd.concat([cls_base, agg_regime], axis=1).join(fr)\n",
        "\n",
        "        # –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ –ø–æ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Ä–µ–∂–∏–º—É\n",
        "        rows = []\n",
        "        for regime, grp in joined.groupby('regime_topdown'):\n",
        "            row = {'regime': regime}\n",
        "            for h in FORWARD_HORIZONS:\n",
        "                r = grp[f'r_forward_{h}']\n",
        "                row[f'mean_{h}'] = r.mean()\n",
        "                row[f'median_{h}'] = r.median()\n",
        "                row[f'sharpe_{h}'] = sharpe_ratio(r)\n",
        "            rows.append(row)\n",
        "        table_topdown = pd.DataFrame(rows).set_index('regime').sort_index()\n",
        "        print(\"\\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Ä–µ–∂–∏–º—É (top-down, –±–∞–∑–æ–≤—ã–π 1h):\")\n",
        "        print(table_topdown)\n",
        "\n",
        "        # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∏ –±—ç–∫—Ç–µ—Å—Ç\n",
        "        stab_td = stability_metrics(agg_regime)\n",
        "        bt_td = backtest_regime_on_off(d_base['close'], agg_regime)\n",
        "        print(\"\\n–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å top-down:\", stab_td)\n",
        "        print(\"\\n–ë—ç–∫—Ç–µ—Å—Ç top-down vs buy&hold:\")\n",
        "        print(bt_td)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
