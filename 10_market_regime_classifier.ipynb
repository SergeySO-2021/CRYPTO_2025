{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🎯 КЛАССИФИКАТОР РЫНОЧНЫХ РЕЖИМОВ\n",
        "\n",
        "## 📊 НАЗНАЧЕНИЕ\n",
        "Статичный классификатор для определения рыночных режимов без оптимизации параметров.\n",
        "\n",
        "### 🎯 ПРИНЦИПЫ:\n",
        "- ✅ **СТАТИЧНЫЕ НАСТРОЙКИ** - не оптимизируем под данные\n",
        "- ✅ **ТЕОРЕТИЧЕСКИ ОБОСНОВАННЫЕ** - используем семантически значимые значения\n",
        "- ✅ **ОБЪЕКТИВНАЯ КЛАССИФИКАЦИЯ** - избегаем порочного круга оптимизации\n",
        "\n",
        "### 🔍 РЫНОЧНЫЕ РЕЖИМЫ:\n",
        "1. **Сильный тренд вверх** - ADX > 30, Choppiness < 38.2, цена растет\n",
        "2. **Сильный тренд вниз** - ADX > 30, Choppiness < 38.2, цена падает\n",
        "3. **Флет** - ADX < 20, Choppiness > 61.8\n",
        "4. **Высокая волатильность** - Bollinger Bands Width в верхних 20%\n",
        "5. **Неопределенное состояние** - остальные случаи\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "EPS = 1e-12\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ Импорты загружены!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🏗️ СОЗДАНИЕ КЛАССИФИКАТОРА РЫНОЧНЫХ РЕЖИМОВ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AdvancedMarketRegimeClassifier:\n",
        "    \"\"\"\n",
        "    ПРОФЕССИОНАЛЬНЫЙ КЛАССИФИКАТОР РЫНОЧНЫХ РЕЖИМОВ (без ML)\n",
        "\n",
        "    Ключевые характеристики:\n",
        "    - Wilder RSI, ADX/DI (устойчивые формулы и защита делений)\n",
        "    - Волатильность через безопасный BB width\n",
        "    - Экзо-перцентили (ex-ante) для порогов волатильности (shift +1)\n",
        "    - Композитная сила тренда: SMA cross + DI sign + объем\n",
        "    - Гистерезис и минимальная длительность режима\n",
        "    - Детальная статистика и визуализация\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.parameters = {\n",
        "            'adx': {'strong_trend': 30, 'weak_trend': 20, 'no_trend': 15, 'period': 14},\n",
        "            'choppiness': {'trend_threshold': 38.2, 'flat_threshold': 61.8, 'period': 14},\n",
        "            'volatility': {\n",
        "                'lookback_percentile': 252,\n",
        "                'low_percentile': 0.20,\n",
        "                'high_percentile': 0.80,\n",
        "                'bb_period': 20,\n",
        "                'bb_std': 2.0\n",
        "            },\n",
        "            'rsi': {'period': 14, 'overbought': 70, 'oversold': 30},\n",
        "            'statistical': {'z_score_threshold': 2.0, 'min_trend_bars': 5, 'regime_persistence': 3}\n",
        "        }\n",
        "        self.regime_hierarchy = [\n",
        "            'high_volatility_crash', 'high_volatility_rally',\n",
        "            'strong_trend_up', 'strong_trend_down',\n",
        "            'weak_trend_up', 'weak_trend_down',\n",
        "            'consolidation_high_vol', 'consolidation_low_vol',\n",
        "            'ranging_market', 'uncertain'\n",
        "        ]\n",
        "        print(\"🎯 AdvancedMarketRegimeClassifier инициализирован!\")\n",
        "\n",
        "    # ---------- Индикаторы ----------\n",
        "    def _rsi_wilder(self, close: pd.Series) -> pd.Series:\n",
        "        period = self.parameters['rsi']['period']\n",
        "        delta = close.diff()\n",
        "        gain = delta.clip(lower=0.0)\n",
        "        loss = -delta.clip(upper=0.0)\n",
        "        avg_gain = gain.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
        "        avg_loss = loss.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
        "        rs = avg_gain / (avg_loss + EPS)\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "        return rsi\n",
        "\n",
        "    def _bb_width_relative(self, close: pd.Series) -> pd.Series:\n",
        "        period = self.parameters['volatility']['bb_period']\n",
        "        std_mult = self.parameters['volatility']['bb_std']\n",
        "        sma = close.rolling(window=period, min_periods=period).mean()\n",
        "        std = close.rolling(window=period, min_periods=period).std(ddof=0)\n",
        "        upper = sma + std_mult * std\n",
        "        lower = sma - std_mult * std\n",
        "        width = (upper - lower) / (sma.abs() + EPS)\n",
        "        return width\n",
        "\n",
        "    def _adx_di_wilder(self, high: pd.Series, low: pd.Series, close: pd.Series) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
        "        period = self.parameters['adx']['period']\n",
        "        up_move = high.diff()\n",
        "        down_move = -low.diff()\n",
        "        plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0.0)\n",
        "        minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)\n",
        "        plus_dm = pd.Series(plus_dm, index=high.index)\n",
        "        minus_dm = pd.Series(minus_dm, index=high.index)\n",
        "        prev_close = close.shift(1)\n",
        "        tr = pd.concat([(high - low), (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)\n",
        "        atr = tr.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
        "        plus_di = 100 * (plus_dm.ewm(alpha=1/period, adjust=False, min_periods=period).mean() / (atr + EPS))\n",
        "        minus_di = 100 * (minus_dm.ewm(alpha=1/period, adjust=False, min_periods=period).mean() / (atr + EPS))\n",
        "        dx = 100 * (plus_di - minus_di).abs() / (plus_di + minus_di + EPS)\n",
        "        adx = dx.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
        "        return adx, plus_di, minus_di\n",
        "\n",
        "    def _choppiness_index(self, high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:\n",
        "        period = self.parameters['choppiness']['period']\n",
        "        prev_close = close.shift(1)\n",
        "        tr = pd.concat([(high - low), (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)\n",
        "        sum_tr = tr.rolling(window=period, min_periods=period).sum()\n",
        "        highest_high = high.rolling(window=period, min_periods=period).max()\n",
        "        lowest_low = low.rolling(window=period, min_periods=period).min()\n",
        "        range_hl = (highest_high - lowest_low).replace(0, np.nan)\n",
        "        chop = 100 * np.log10((sum_tr + EPS) / (range_hl + EPS)) / np.log10(period)\n",
        "        return chop\n",
        "\n",
        "    def _rolling_percentiles_ex_ante(self, series: pd.Series) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
        "        lookback = self.parameters['volatility']['lookback_percentile']\n",
        "        low_q = self.parameters['volatility']['low_percentile']\n",
        "        high_q = self.parameters['volatility']['high_percentile']\n",
        "        low_thr = series.rolling(window=lookback, min_periods=lookback).quantile(low_q).shift(1)\n",
        "        high_thr = series.rolling(window=lookback, min_periods=lookback).quantile(high_q).shift(1)\n",
        "        def ex_ante_pct(window: pd.Series) -> float:\n",
        "            vals = window[:-1].values\n",
        "            if len(vals) == 0:\n",
        "                return np.nan\n",
        "            current = window.iloc[-1]\n",
        "            return (np.searchsorted(np.sort(vals), current, side='right') / len(vals))\n",
        "        pct = series.rolling(window=lookback + 1, min_periods=lookback + 1).apply(ex_ante_pct, raw=False)\n",
        "        return low_thr, high_thr, pct\n",
        "\n",
        "    def _volume_profile(self, volume: pd.Series, lookback: int = 20) -> pd.Series:\n",
        "        volume_ma = volume.rolling(window=lookback, min_periods=lookback).mean()\n",
        "        return volume / (volume_ma + EPS)\n",
        "\n",
        "    def _atr_pct(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:\n",
        "        prev_close = close.shift(1)\n",
        "        tr = pd.concat([(high - low), (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)\n",
        "        atr = tr.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
        "        return atr / (close.abs() + EPS)\n",
        "\n",
        "    def _return_zscore(self, close: pd.Series, lookback: int = 63) -> pd.Series:\n",
        "        ret = close.pct_change()\n",
        "        mean = ret.rolling(window=lookback, min_periods=lookback).mean().shift(1)\n",
        "        std = ret.rolling(window=lookback, min_periods=lookback).std(ddof=0).shift(1)\n",
        "        z = (ret - mean) / (std + EPS)\n",
        "        return z\n",
        "\n",
        "    # ---------- Композитная логика ----------\n",
        "    def _trend_strength(self, close: pd.Series, adx: pd.Series, choppiness: pd.Series, volume_ratio: pd.Series, plus_di: pd.Series, minus_di: pd.Series) -> pd.Series:\n",
        "        sma_short = close.rolling(window=20, min_periods=20).mean()\n",
        "        sma_long = close.rolling(window=50, min_periods=50).mean()\n",
        "        price_trend = np.where(sma_short > sma_long, 1, -1)\n",
        "        adx_strength = np.select([\n",
        "            adx > self.parameters['adx']['strong_trend'],\n",
        "            adx > self.parameters['adx']['weak_trend'],\n",
        "            adx > self.parameters['adx']['no_trend']\n",
        "        ], [2, 1, 0], default=0)\n",
        "        choppy_trend = np.where(choppiness < self.parameters['choppiness']['trend_threshold'], 1, 0)\n",
        "        di_sign = np.where(plus_di > minus_di, 1, -1)\n",
        "        volume_support = np.where(volume_ratio > 1.2, 1, 0)\n",
        "        strength = (price_trend * 0.4 + di_sign * 0.3) * (adx_strength * 0.2 + choppy_trend * 0.3 + volume_support * 0.5)\n",
        "        return pd.Series(strength, index=close.index)\n",
        "\n",
        "    def _hysteresis(self, series: pd.Series, enter: float, exit: float) -> pd.Series:\n",
        "        state = False\n",
        "        out = []\n",
        "        for v in series.fillna(0).values:\n",
        "            if not state and v >= enter:\n",
        "                state = True\n",
        "            elif state and v <= exit:\n",
        "                state = False\n",
        "            out.append(1 if state else 0)\n",
        "        return pd.Series(out, index=series.index)\n",
        "\n",
        "    # ---------- Публичные методы ----------\n",
        "    def classify_market_regime(self, data: pd.DataFrame) -> Tuple[List[str], pd.DataFrame]:\n",
        "        print(\"🔍 Начинаем расширенную классификацию рыночных режимов...\")\n",
        "        adx, plus_di, minus_di = self._adx_di_wilder(data['high'], data['low'], data['close'])\n",
        "        choppiness = self._choppiness_index(data['high'], data['low'], data['close'])\n",
        "        bb_width = self._bb_width_relative(data['close'])\n",
        "        rsi = self._rsi_wilder(data['close'])\n",
        "        volume_ratio = self._volume_profile(data['volume']) if 'volume' in data.columns else pd.Series(np.nan, index=data.index)\n",
        "        low_thr, high_thr, vol_pct = self._rolling_percentiles_ex_ante(bb_width)\n",
        "        trend_strength = self._trend_strength(data['close'], adx, choppiness, volume_ratio, plus_di, minus_di)\n",
        "        atr_pct = self._atr_pct(data['high'], data['low'], data['close'])\n",
        "        ret_z = self._return_zscore(data['close'])\n",
        "\n",
        "        regimes = []\n",
        "        details = []\n",
        "        for i in range(len(data)):\n",
        "            if i < max(252, 50):\n",
        "                regimes.append('insufficient_data')\n",
        "                details.append({'reason': 'insufficient_data'})\n",
        "                continue\n",
        "            cur = {\n",
        "                'adx': adx.iloc[i],\n",
        "                'chop': choppiness.iloc[i],\n",
        "                'bb': bb_width.iloc[i],\n",
        "                'rsi': rsi.iloc[i],\n",
        "                'vol_ratio': volume_ratio.iloc[i] if 'volume' in data.columns else np.nan,\n",
        "                'ts': trend_strength.iloc[i],\n",
        "                'low_thr': low_thr.iloc[i],\n",
        "                'high_thr': high_thr.iloc[i],\n",
        "                'vol_pct': vol_pct.iloc[i],\n",
        "                'plus_di': plus_di.iloc[i],\n",
        "                'minus_di': minus_di.iloc[i],\n",
        "                'atr_pct': atr_pct.iloc[i],\n",
        "                'ret_z': ret_z.iloc[i],\n",
        "                'open': data['open'].iloc[i] if 'open' in data.columns else data['close'].iloc[i-1],\n",
        "                'close': data['close'].iloc[i]\n",
        "            }\n",
        "            if any(pd.isna([cur['adx'], cur['chop'], cur['bb'], cur['ts'], cur['low_thr'], cur['high_thr'], cur['vol_pct']])):\n",
        "                regimes.append('insufficient_data')\n",
        "                details.append({'reason': 'nan_values'})\n",
        "                continue\n",
        "            is_high_vol = cur['bb'] > cur['high_thr']\n",
        "            is_low_vol = cur['bb'] < cur['low_thr']\n",
        "            is_strong_trend = cur['adx'] > self.parameters['adx']['strong_trend']\n",
        "            is_weak_trend = self.parameters['adx']['weak_trend'] <= cur['adx'] <= self.parameters['adx']['strong_trend']\n",
        "            is_choppy_trend = cur['chop'] < self.parameters['choppiness']['trend_threshold']\n",
        "            is_choppy_flat = cur['chop'] > self.parameters['choppiness']['flat_threshold']\n",
        "            price_up = cur['close'] > cur['open']\n",
        "\n",
        "            # Crash / rally уточнение: высокий перцентиль волатильности + экстремальный ret_z и/или высокий ATR%\n",
        "            if is_high_vol and (cur['ts'] < -1.5) and (cur['vol_pct'] > 0.9) and ((cur['ret_z'] < -2.0) or (cur['atr_pct'] > 0.03)):\n",
        "                regimes.append('high_volatility_crash')\n",
        "                details.append({'reason': 'high_volatility_crash', 'vol_pct': cur['vol_pct'], 'ts': cur['ts'], 'ret_z': cur['ret_z'], 'atr_pct': cur['atr_pct']})\n",
        "            elif is_high_vol and (cur['ts'] > 1.5) and (cur['vol_pct'] > 0.9) and ((cur['ret_z'] > 2.0) or (cur['atr_pct'] > 0.03)):\n",
        "                regimes.append('high_volatility_rally')\n",
        "                details.append({'reason': 'high_volatility_rally', 'vol_pct': cur['vol_pct'], 'ts': cur['ts'], 'ret_z': cur['ret_z'], 'atr_pct': cur['atr_pct']})\n",
        "            elif is_strong_trend and is_choppy_trend and cur['ts'] > 1.0 and price_up:\n",
        "                regimes.append('strong_trend_up')\n",
        "                details.append({'reason': 'strong_trend_up'})\n",
        "            elif is_strong_trend and is_choppy_trend and cur['ts'] < -1.0 and not price_up:\n",
        "                regimes.append('strong_trend_down')\n",
        "                details.append({'reason': 'strong_trend_down'})\n",
        "            elif is_weak_trend and is_choppy_trend and cur['ts'] > 0.5 and price_up:\n",
        "                regimes.append('weak_trend_up')\n",
        "                details.append({'reason': 'weak_trend_up'})\n",
        "            elif is_weak_trend and is_choppy_trend and cur['ts'] < -0.5 and not price_up:\n",
        "                regimes.append('weak_trend_down')\n",
        "                details.append({'reason': 'weak_trend_down'})\n",
        "            elif is_high_vol and is_choppy_flat and abs(cur['ts']) < 0.5:\n",
        "                regimes.append('consolidation_high_vol')\n",
        "                details.append({'reason': 'consolidation_high_vol'})\n",
        "            elif is_low_vol and is_choppy_flat and abs(cur['ts']) < 0.5:\n",
        "                regimes.append('consolidation_low_vol')\n",
        "                details.append({'reason': 'consolidation_low_vol'})\n",
        "            elif is_choppy_flat and abs(cur['ts']) < 1.0:\n",
        "                regimes.append('ranging_market')\n",
        "                details.append({'reason': 'ranging_market'})\n",
        "            else:\n",
        "                regimes.append('uncertain')\n",
        "                details.append({'reason': 'uncertain'})\n",
        "\n",
        "        regimes = self._apply_persistence(regimes)\n",
        "        classification_data = pd.DataFrame({\n",
        "            'adx': adx,\n",
        "            'plus_di': plus_di,\n",
        "            'minus_di': minus_di,\n",
        "            'choppiness': choppiness,\n",
        "            'bb_width': bb_width,\n",
        "            'rsi': rsi,\n",
        "            'volume_ratio': volume_ratio,\n",
        "            'trend_strength': trend_strength,\n",
        "            'volatility_percentile': vol_pct,\n",
        "            'regime': regimes\n",
        "        }, index=data.index)\n",
        "        classification_data['classification_details'] = details\n",
        "        self._print_regime_stats(regimes)\n",
        "        return regimes, classification_data\n",
        "\n",
        "    def _apply_persistence(self, regimes: List[str]) -> List[str]:\n",
        "        if len(regimes) < 3:\n",
        "            return regimes\n",
        "        min_persist = self.parameters['statistical']['regime_persistence']\n",
        "        smoothed = regimes.copy()\n",
        "        i = 0\n",
        "        while i < len(regimes):\n",
        "            j = i\n",
        "            while j < len(regimes) and regimes[j] == regimes[i]:\n",
        "                j += 1\n",
        "            run_len = j - i\n",
        "            if run_len < min_persist:\n",
        "                # заменяем короткий пробег на соседний доминирующий режим\n",
        "                left = regimes[i-1] if i - 1 >= 0 else None\n",
        "                right = regimes[j] if j < len(regimes) else None\n",
        "                fill = right if right is not None else left\n",
        "                for k in range(i, j):\n",
        "                    smoothed[k] = fill if fill is not None else regimes[k]\n",
        "            i = j\n",
        "        return smoothed\n",
        "\n",
        "    def _print_regime_stats(self, regimes: List[str]):\n",
        "        counts = pd.Series(regimes).value_counts()\n",
        "        total = len(regimes)\n",
        "        print(\"\\n📊 СТАТИСТИКА РЫНОЧНЫХ РЕЖИМОВ:\")\n",
        "        print(\"=\" * 50)\n",
        "        for regime in self.regime_hierarchy:\n",
        "            if regime in counts:\n",
        "                c = counts[regime]\n",
        "                print(f\"   • {regime:25s}: {c:4d} баров ({(c/total)*100:5.1f}%)\")\n",
        "        sufficient = [r for r in regimes if r != 'insufficient_data']\n",
        "        if sufficient:\n",
        "            print(f\"\\n   • Всего классифицировано: {len(sufficient)} баров\")\n",
        "            print(f\"   • Недостаточно данных: {total - len(sufficient)} баров\")\n",
        "\n",
        "    # ---------- Статистика и визуализация ----------\n",
        "    def get_detailed_statistics(self, classification_data: pd.DataFrame) -> Dict:\n",
        "        valid = classification_data[classification_data['regime'] != 'insufficient_data']\n",
        "        def transitions(series: pd.Series) -> pd.DataFrame:\n",
        "            pairs = []\n",
        "            prev = None\n",
        "            for r in series:\n",
        "                if prev and prev != r:\n",
        "                    pairs.append((prev, r))\n",
        "                prev = r\n",
        "            if not pairs:\n",
        "                return pd.DataFrame()\n",
        "            df = pd.DataFrame(pairs, columns=['from', 'to'])\n",
        "            return pd.crosstab(df['from'], df['to'], normalize='index')\n",
        "        def durations(series: pd.Series) -> Dict[str, float]:\n",
        "            dur = {}\n",
        "            cur = None\n",
        "            run = 0\n",
        "            for r in series:\n",
        "                if r == cur:\n",
        "                    run += 1\n",
        "                else:\n",
        "                    if cur:\n",
        "                        dur.setdefault(cur, []).append(run)\n",
        "                    cur = r\n",
        "                    run = 1\n",
        "            if cur:\n",
        "                dur.setdefault(cur, []).append(run)\n",
        "            return {k: float(np.mean(v)) for k, v in dur.items()}\n",
        "        stats = {\n",
        "            'regime_counts': valid['regime'].value_counts(),\n",
        "            'regime_percentages': valid['regime'].value_counts(normalize=True) * 100,\n",
        "            'indicators_by_regime': valid.groupby('regime').agg({\n",
        "                'adx': ['mean', 'std', 'min', 'max'],\n",
        "                'choppiness': ['mean', 'std', 'min', 'max'],\n",
        "                'bb_width': ['mean', 'std', 'min', 'max'],\n",
        "                'rsi': ['mean', 'std', 'min', 'max'],\n",
        "                'volume_ratio': ['mean', 'std', 'min', 'max'],\n",
        "                'trend_strength': ['mean', 'std', 'min', 'max']\n",
        "            }),\n",
        "            'regime_transitions': transitions(valid['regime']),\n",
        "            'regime_durations': durations(valid['regime'])\n",
        "        }\n",
        "        return stats\n",
        "\n",
        "    def visualize_regime_analysis(self, data: pd.DataFrame, classification_data: pd.DataFrame, title: str = \"Расширенный анализ рыночных режимов BTC\"):\n",
        "        fig, axes = plt.subplots(4, 1, figsize=(16, 14))\n",
        "        regime_colors = {\n",
        "            'strong_trend_up': '#00ff00',\n",
        "            'strong_trend_down': '#ff0000',\n",
        "            'weak_trend_up': '#90ee90',\n",
        "            'weak_trend_down': '#ffcccb',\n",
        "            'high_volatility_rally': '#ffa500',\n",
        "            'high_volatility_crash': '#8b0000',\n",
        "            'consolidation_high_vol': '#ff69b4',\n",
        "            'consolidation_low_vol': '#9370db',\n",
        "            'ranging_market': '#1e90ff',\n",
        "            'uncertain': '#a9a9a9',\n",
        "            'insufficient_data': '#000000'\n",
        "        }\n",
        "        axes[0].plot(data.index, data['close'], label='BTC Price', color='black', alpha=0.8, linewidth=1)\n",
        "        for regime in classification_data['regime'].unique():\n",
        "            if regime in regime_colors:\n",
        "                mask = classification_data['regime'] == regime\n",
        "                if mask.any():\n",
        "                    axes[0].scatter(data.index[mask], data['close'][mask], c=regime_colors[regime], label=regime, alpha=0.7, s=12)\n",
        "        axes[0].set_title(f'{title}\\nЦена BTC с рыночными режимами', fontsize=14, fontweight='bold')\n",
        "        axes[0].set_ylabel('Цена BTC', fontweight='bold')\n",
        "        # Ограничиваем количество элементов в легенде, если их слишком много\n",
        "        handles, labels = axes[0].get_legend_handles_labels()\n",
        "        if len(labels) > 9:\n",
        "            axes[0].legend(handles[:9], labels[:9], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        else:\n",
        "            axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        axes[1].plot(classification_data.index, classification_data['adx'], label='ADX', color='purple', linewidth=1)\n",
        "        axes[1].axhline(y=self.parameters['adx']['strong_trend'], color='red', linestyle='--', alpha=0.7, label='Сильный тренд')\n",
        "        axes[1].axhline(y=self.parameters['adx']['weak_trend'], color='orange', linestyle='--', alpha=0.7, label='Слабый тренд')\n",
        "        axes[1].set_ylabel('ADX', fontweight='bold')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        axes[2].plot(classification_data.index, classification_data['choppiness'], label='Choppiness Index', color='blue', linewidth=1)\n",
        "        axes[2].axhline(y=self.parameters['choppiness']['flat_threshold'], color='red', linestyle='--', alpha=0.7, label='Флет')\n",
        "        axes[2].axhline(y=self.parameters['choppiness']['trend_threshold'], color='green', linestyle='--', alpha=0.7, label='Тренд')\n",
        "        axes[2].set_ylabel('Choppiness Index', fontweight='bold')\n",
        "        axes[2].legend()\n",
        "        axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "        ax4 = axes[3]\n",
        "        ax4_twin = ax4.twinx()\n",
        "        ax4.plot(classification_data.index, classification_data['bb_width'], label='Волатильность (BB Width)', color='brown', linewidth=1)\n",
        "        ax4.set_ylabel('Волатильность', fontweight='bold', color='brown')\n",
        "        ax4.tick_params(axis='y', labelcolor='brown')\n",
        "\n",
        "        ax4_twin.plot(classification_data.index, classification_data['rsi'], label='RSI', color='gray', linewidth=1, alpha=0.7)\n",
        "        ax4_twin.axhline(y=70, color='red', linestyle='--', alpha=0.5, label='Перекупленность')\n",
        "        ax4_twin.axhline(y=30, color='green', linestyle='--', alpha=0.5, label='Перепроданность')\n",
        "        ax4_twin.axhline(y=50, color='black', linestyle='-', alpha=0.3)\n",
        "        ax4_twin.set_ylabel('RSI', fontweight='bold', color='gray')\n",
        "        ax4_twin.tick_params(axis='y', labelcolor='gray')\n",
        "        ax4_twin.set_ylim(0, 100)\n",
        "\n",
        "        ax4.set_xlabel('Дата', fontweight='bold')\n",
        "        # Стабилизируем легенды на последнем графике\n",
        "        l1, l2 = ax4.get_legend_handles_labels()\n",
        "        r1, r2 = ax4_twin.get_legend_handles_labels()\n",
        "        ax4.legend(l1 + r1, r2 + r2, loc='upper left')\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        return fig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧪 ТЕСТИРОВАНИЕ КЛАССИФИКАТОРА\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загружаем данные BTC для тестирования\n",
        "print(\"📊 Загрузка данных BTC для тестирования...\")\n",
        "df = pd.read_csv('df_btc_1h.csv', index_col=0, parse_dates=True)\n",
        "print(f\"✅ Загружено {len(df)} записей\")\n",
        "print(f\"📅 Период: {df.index[0]} - {df.index[-1]}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создаем классификатор и тестируем\n",
        "print(\"🎯 СОЗДАНИЕ И ТЕСТИРОВАНИЕ КЛАССИФИКАТОРА\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "classifier = AdvancedMarketRegimeClassifier()\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Классифицируем рыночные режимы (расширенная версия)\n",
        "print(\"🔍 КЛАССИФИКАЦИЯ РЫНОЧНЫХ РЕЖИМОВ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "regimes, classification_data = classifier.classify_market_regime(df)\n",
        "\n",
        "print(\"\\n✅ Классификация завершена!\")\n",
        "print(f\"📊 Обработано {len(regimes)} баров\")\n",
        "print(f\"📈 Уникальных режимов: {len(set(regimes))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Получаем статистику по режимам (расширенная)\n",
        "print(\"📊 СТАТИСТИКА ПО РЫНОЧНЫМ РЕЖИМАМ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "stats = classifier.get_detailed_statistics(classification_data)\n",
        "\n",
        "print(\"\\n📈 Распределение режимов:\")\n",
        "for regime, count in stats['regime_counts'].items():\n",
        "    percentage = stats['regime_percentages'][regime]\n",
        "    print(f\"   • {regime}: {count} баров ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\n📊 Сводные индикаторы по режимам:\")\n",
        "print(stats['indicators_by_regime'])\n",
        "\n",
        "print(\"\\n🔁 Матрица переходов (норм.):\")\n",
        "print(stats['regime_transitions'])\n",
        "\n",
        "print(\"\\n⏱ Средняя длительность режимов (бары):\")\n",
        "print(stats['regime_durations'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализируем результаты (расширенный анализ)\n",
        "print(\"📊 ВИЗУАЛИЗАЦИЯ РЫНОЧНЫХ РЕЖИМОВ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Берем последние 1000 баров для лучшей визуализации\n",
        "recent_data = df.tail(1000)\n",
        "recent_classification = classification_data.tail(1000)\n",
        "\n",
        "fig = classifier.visualize_regime_analysis(recent_data, recent_classification, \"BTC 1H - Последние 1000 баров\")\n",
        "\n",
        "print(\"✅ Визуализация завершена!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📋 РЕЗУЛЬТАТЫ КЛАССИФИКАЦИИ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Показываем первые 20 результатов классификации\n",
        "print(\"📋 ПЕРВЫЕ 20 РЕЗУЛЬТАТОВ КЛАССИФИКАЦИИ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "sample_data = classification_data.head(20)[['adx', 'choppiness', 'bb_width', 'regime']]\n",
        "print(sample_data.to_string())\n",
        "\n",
        "print(\"\\n📊 ИНТЕРПРЕТАЦИЯ РЕЖИМОВ:\")\n",
        "print(\"   • strong_trend_up: Сильный восходящий тренд\")\n",
        "print(\"   • strong_trend_down: Сильный нисходящий тренд\")\n",
        "print(\"   • weak_trend_up: Слабый восходящий тренд\")\n",
        "print(\"   • weak_trend_down: Слабый нисходящий тренд\")\n",
        "print(\"   • flat_market: Боковой рынок (флет)\")\n",
        "print(\"   • volatile_market: Высокая волатильность\")\n",
        "print(\"   • uncertain: Неопределенное состояние\")\n",
        "print(\"   • insufficient_data: Недостаточно данных для анализа\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 ЗАКЛЮЧЕНИЕ\n",
        "\n",
        "### ✅ **ЧТО МЫ СОЗДАЛИ:**\n",
        "1. **Статичный классификатор рыночных режимов** - без оптимизации параметров\n",
        "2. **Объективную классификацию** - основанную на теоретически обоснованных значениях\n",
        "3. **7 различных рыночных режимов** - от сильных трендов до флета\n",
        "4. **Визуализацию результатов** - для понимания работы классификатора\n",
        "\n",
        "### 🎯 **СЛЕДУЮЩИЕ ШАГИ:**\n",
        "1. **Анализ эффективности сигнальных индикаторов** по выявленным режимам\n",
        "2. **Целевая оптимизация** сигнальных индикаторов под конкретные режимы\n",
        "3. **Создание адаптивной системы** - выбор индикаторов в зависимости от режима\n",
        "\n",
        "### 💡 **КЛЮЧЕВЫЕ ПРИНЦИПЫ:**\n",
        "- ✅ **НЕ ОПТИМИЗИРУЕМ** параметры классификаторов\n",
        "- ✅ **ИСПОЛЬЗУЕМ** теоретически обоснованные значения\n",
        "- ✅ **ИЗБЕГАЕМ** порочного круга оптимизации\n",
        "- ✅ **СОЗДАЕМ** объективную основу для дальнейшей работы\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📦 ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ ДЛЯ ОЦЕНКИ ЭФФЕКТИВНОСТИ\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "FORWARD_HORIZONS = [1, 3, 5, 10]\n",
        "\n",
        "def compute_forward_returns(close: pd.Series, horizons=FORWARD_HORIZONS) -> pd.DataFrame:\n",
        "    out = {}\n",
        "    for h in horizons:\n",
        "        out[f'r_forward_{h}'] = close.shift(-h) / close - 1.0\n",
        "    return pd.DataFrame(out, index=close.index)\n",
        "\n",
        "def sharpe_ratio(returns: pd.Series) -> float:\n",
        "    mu = returns.mean()\n",
        "    sd = returns.std(ddof=0)\n",
        "    if sd == 0 or np.isnan(sd):\n",
        "        return np.nan\n",
        "    return mu / sd\n",
        "\n",
        "def sign_accuracy(returns: pd.Series, direction: int) -> float:\n",
        "    if direction not in (-1, 1):\n",
        "        return np.nan\n",
        "    valid = returns.dropna()\n",
        "    if len(valid) == 0:\n",
        "        return np.nan\n",
        "    return (np.sign(valid) == direction).mean()\n",
        "\n",
        "def regime_run_lengths(regimes: pd.Series) -> pd.Series:\n",
        "    lengths = []\n",
        "    prev = None\n",
        "    run = 0\n",
        "    for r in regimes:\n",
        "        if r == prev:\n",
        "            run += 1\n",
        "        else:\n",
        "            if prev is not None:\n",
        "                lengths.append(run)\n",
        "            prev = r\n",
        "            run = 1\n",
        "    if prev is not None:\n",
        "        lengths.append(run)\n",
        "    return pd.Series(lengths, dtype=float)\n",
        "\n",
        "def stability_metrics(regimes: pd.Series) -> dict:\n",
        "    runs = regime_run_lengths(regimes)\n",
        "    switches_per_1000 = 0.0 if len(regimes) == 0 else (len(runs) - 1) / max(len(regimes), 1) * 1000.0\n",
        "    uncertain_share = (regimes == 'uncertain').mean()\n",
        "    return {\n",
        "        'avg_run_length': runs.mean() if len(runs) else np.nan,\n",
        "        'switches_per_1000': switches_per_1000,\n",
        "        'uncertain_share': uncertain_share,\n",
        "    }\n",
        "\n",
        "def simple_regime_position(regime: str) -> int:\n",
        "    if regime in ('strong_trend_up', 'weak_trend_up'):\n",
        "        return 1\n",
        "    if regime in ('strong_trend_down', 'weak_trend_down'):\n",
        "        return -1\n",
        "    return 0\n",
        "\n",
        "def backtest_regime_on_off(close: pd.Series, regimes: pd.Series) -> dict:\n",
        "    ret = close.pct_change()\n",
        "    pos = regimes.fillna('uncertain').map(simple_regime_position).astype(float)\n",
        "    # Используем позицию со сдвигом, чтобы не было look-ahead\n",
        "    strat_ret = pos.shift(1) * ret\n",
        "    bh_ret = ret\n",
        "    out = {\n",
        "        'strat_return_mean': strat_ret.mean(),\n",
        "        'strat_return_std': strat_ret.std(ddof=0),\n",
        "        'strat_sharpe': sharpe_ratio(strat_ret),\n",
        "        'bh_return_mean': bh_ret.mean(),\n",
        "        'bh_return_std': bh_ret.std(ddof=0),\n",
        "        'bh_sharpe': sharpe_ratio(bh_ret),\n",
        "        'strat_cumret': float((1 + strat_ret.fillna(0)).prod() - 1),\n",
        "        'bh_cumret': float((1 + bh_ret.fillna(0)).prod() - 1),\n",
        "    }\n",
        "    return out\n",
        "\n",
        "def crash_rally_analysis(close: pd.Series, regimes: pd.Series, window: int = 10) -> dict:\n",
        "    ret = close.pct_change()\n",
        "    idx = close.index\n",
        "    results = {}\n",
        "    for tag in ('high_volatility_crash', 'high_volatility_rally'):\n",
        "        starts = idx[regimes == tag]\n",
        "        if len(starts) == 0:\n",
        "            results[tag] = {'signals': 0}\n",
        "            continue\n",
        "        prof = []\n",
        "        falses = 0\n",
        "        for t in starts:\n",
        "            if t not in idx:\n",
        "                continue\n",
        "            start_loc = idx.get_loc(t)\n",
        "            end_loc = min(start_loc + window, len(idx) - 1)\n",
        "            seg = ret.iloc[start_loc+1:end_loc+1]  # доходности после сигнала\n",
        "            cum = (1 + seg.fillna(0)).prod() - 1\n",
        "            prof.append(cum)\n",
        "            if tag == 'high_volatility_crash' and cum > 0:\n",
        "                falses += 1\n",
        "            if tag == 'high_volatility_rally' and cum < 0:\n",
        "                falses += 1\n",
        "        prof = pd.Series(prof, dtype=float)\n",
        "        results[tag] = {\n",
        "            'signals': int(len(starts)),\n",
        "            'mean_cum_return_w'+str(window): float(prof.mean()) if len(prof) else np.nan,\n",
        "            'median_cum_return_w'+str(window): float(prof.median()) if len(prof) else np.nan,\n",
        "            'false_rate': float(falses / len(starts)) if len(starts) else np.nan,\n",
        "        }\n",
        "    return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🧮 ОЦЕНКА НА ОДНОМ ТАЙМФРЕЙМЕ (ПРИМЕР: 1H)\n",
        "print(\"🔎 ОЦЕНКА НА 1H\")\n",
        "\n",
        "# 1) Получаем режимы уже рассчитанные выше: classification_data\n",
        "fr = compute_forward_returns(df['close'])\n",
        "joined = classification_data.join(fr)\n",
        "\n",
        "# 2) Таблица метрик по режимам\n",
        "rows = []\n",
        "for regime, grp in joined.groupby('regime'):\n",
        "    row = {'regime': regime}\n",
        "    for h in FORWARD_HORIZONS:\n",
        "        r = grp[f'r_forward_{h}']\n",
        "        row[f'mean_{h}'] = r.mean()\n",
        "        row[f'median_{h}'] = r.median()\n",
        "        row[f'sharpe_{h}'] = sharpe_ratio(r)\n",
        "    rows.append(row)\n",
        "per_regime_metrics_1h = pd.DataFrame(rows).set_index('regime').sort_index()\n",
        "print(per_regime_metrics_1h)\n",
        "\n",
        "# 3) Стабильность режимов\n",
        "stab = stability_metrics(classification_data['regime'])\n",
        "print(\"\\nСтабильность режимов:\", stab)\n",
        "\n",
        "# 4) Анализ crash/rally\n",
        "cr = crash_rally_analysis(df['close'], classification_data['regime'], window=10)\n",
        "print(\"\\nCrash/Rally анализ (окно=10):\", cr)\n",
        "\n",
        "# 5) Простой бэктест режимной стратегии против buy&hold\n",
        "bt = backtest_regime_on_off(df['close'], classification_data['regime'])\n",
        "print(\"\\nСравнение стратегии режимов vs buy&hold:\")\n",
        "print(bt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🌐 МУЛЬТИ‑ТАЙМФРЕЙМ: СРАВНЕНИЕ МЕТРИК ПО ВСЕМ 5 ТФ\n",
        "import os\n",
        "\n",
        "files = [\n",
        "    ('15m', 'df_btc_15m.csv'),\n",
        "    ('30m', 'df_btc_30m.csv'),\n",
        "    ('1h', 'df_btc_1h.csv'),\n",
        "    ('4h', 'df_btc_4h.csv'),\n",
        "    ('1d', 'df_btc_1d.csv'),\n",
        "]\n",
        "\n",
        "summary_rows = []\n",
        "per_tf_tables = {}\n",
        "\n",
        "for tf, fname in files:\n",
        "    if not os.path.exists(fname):\n",
        "        print(f\"⚠️ Файл {fname} не найден, пропускаю {tf}\")\n",
        "        continue\n",
        "    print(f\"\\n⏱ Обработка {tf} ({fname})\")\n",
        "    d = pd.read_csv(fname, index_col=0, parse_dates=True)\n",
        "    clf = AdvancedMarketRegimeClassifier()\n",
        "    regimes, cls = clf.classify_market_regime(d)\n",
        "\n",
        "    fr = compute_forward_returns(d['close'])\n",
        "    joined = cls.join(fr)\n",
        "\n",
        "    # Таблица метрик\n",
        "    rows = []\n",
        "    for regime, grp in joined.groupby('regime'):\n",
        "        row = {'regime': regime}\n",
        "        for h in FORWARD_HORIZONS:\n",
        "            r = grp[f'r_forward_{h}']\n",
        "            row[f'mean_{h}'] = r.mean()\n",
        "            row[f'median_{h}'] = r.median()\n",
        "            row[f'sharpe_{h}'] = sharpe_ratio(r)\n",
        "        rows.append(row)\n",
        "    table = pd.DataFrame(rows).set_index('regime').sort_index()\n",
        "    per_tf_tables[tf] = table\n",
        "\n",
        "    # Стабильность и бэктест\n",
        "    stab = stability_metrics(cls['regime'])\n",
        "    bt = backtest_regime_on_off(d['close'], cls['regime'])\n",
        "\n",
        "    summary_rows.append({\n",
        "        'tf': tf,\n",
        "        'avg_run_length': stab['avg_run_length'],\n",
        "        'switches_per_1000': stab['switches_per_1000'],\n",
        "        'uncertain_share': stab['uncertain_share'],\n",
        "        'strat_sharpe': bt['strat_sharpe'],\n",
        "        'bh_sharpe': bt['bh_sharpe'],\n",
        "        'strat_cumret': bt['strat_cumret'],\n",
        "        'bh_cumret': bt['bh_cumret']\n",
        "    })\n",
        "\n",
        "summary = pd.DataFrame(summary_rows).set_index('tf').sort_index()\n",
        "print(\"\\n📊 Сводка по ТФ:\")\n",
        "print(summary)\n",
        "\n",
        "print(\"\\n📋 Примеры таблиц метрик по режимам (1-2 ТФ):\")\n",
        "for tf in list(per_tf_tables.keys())[:2]:\n",
        "    print(f\"\\n— {tf} —\")\n",
        "    print(per_tf_tables[tf])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🧭 TOP-DOWN АГРЕГАЦИЯ (HTF 1d/4h → базовый ТФ)\n",
        "import os\n",
        "\n",
        "def classify_df(file):\n",
        "    d = pd.read_csv(file, index_col=0, parse_dates=True)\n",
        "    clf = AdvancedMarketRegimeClassifier()\n",
        "    regimes, cls = clf.classify_market_regime(d)\n",
        "    return d, cls\n",
        "\n",
        "# 1) Загружаем HTF: 1d и 4h\n",
        "htf_files = [('1d', 'df_btc_1d.csv'), ('4h', 'df_btc_4h.csv')]\n",
        "htf_cls = {}\n",
        "for tf, fname in htf_files:\n",
        "    if os.path.exists(fname):\n",
        "        d_tf, cls_tf = classify_df(fname)\n",
        "        htf_cls[tf] = (d_tf, cls_tf)\n",
        "    else:\n",
        "        print(f\"⚠️ Нет файла {fname}, HTF {tf} пропущен\")\n",
        "\n",
        "# 2) Базовый ТФ (пример — 1h)\n",
        "base_tf = ('1h', 'df_btc_1h.csv')\n",
        "if not os.path.exists(base_tf[1]):\n",
        "    print(f\"⚠️ Нет файла {base_tf[1]}, пропуск top-down\")\n",
        "else:\n",
        "    d_base, cls_base = classify_df(base_tf[1])\n",
        "\n",
        "    # 3) Выравниваем HTF по индексу базового ТФ (forward-fill по времени)\n",
        "    def align_htf_to_base(htf_df):\n",
        "        htf_on_base = htf_df.reindex(d_base.index, method='ffill')\n",
        "        return htf_on_base\n",
        "\n",
        "    aligned = {}\n",
        "    for tf, (d_tf, cls_tf) in htf_cls.items():\n",
        "        aligned[tf] = align_htf_to_base(cls_tf[['regime']])\n",
        "\n",
        "    # 4) Простейшее правило top-down\n",
        "    # Если дневка трендовая — принимаем тренд; если дневка флет/консолидация — LTF тренды понижаем до ranging\n",
        "    def gate_regime(htf_regime: str, ltf_regime: str) -> str:\n",
        "        trend_up = ('strong_trend_up', 'weak_trend_up')\n",
        "        trend_down = ('strong_trend_down', 'weak_trend_down')\n",
        "        cons = ('ranging_market', 'consolidation_high_vol', 'consolidation_low_vol')\n",
        "        if htf_regime in trend_up + trend_down:\n",
        "            return ltf_regime\n",
        "        if htf_regime in cons or htf_regime == 'uncertain':\n",
        "            if ltf_regime in trend_up + trend_down:\n",
        "                return 'ranging_market'\n",
        "            return ltf_regime\n",
        "        return ltf_regime\n",
        "\n",
        "    # 5) Формируем агрегированный режим (используем 1d, при его отсутствии — 4h)\n",
        "    htf_primary = aligned.get('1d', aligned.get('4h'))\n",
        "    if htf_primary is None:\n",
        "        print(\"⚠️ Нет HTF классификации — пропускаю top-down\")\n",
        "    else:\n",
        "        htf_series = htf_primary['regime']\n",
        "        ltf_series = cls_base['regime']\n",
        "        agg_regime = []\n",
        "        for t in d_base.index:\n",
        "            r_htf = htf_series.loc[t] if t in htf_series.index else 'uncertain'\n",
        "            r_ltf = ltf_series.loc[t] if t in ltf_series.index else 'uncertain'\n",
        "            agg_regime.append(gate_regime(r_htf, r_ltf))\n",
        "        agg_regime = pd.Series(agg_regime, index=d_base.index, name='regime_topdown')\n",
        "\n",
        "        # 6) Метрики как и раньше\n",
        "        fr = compute_forward_returns(d_base['close'])\n",
        "        joined = pd.concat([cls_base, agg_regime], axis=1).join(fr)\n",
        "\n",
        "        # Таблица метрик по агрегированному режиму\n",
        "        rows = []\n",
        "        for regime, grp in joined.groupby('regime_topdown'):\n",
        "            row = {'regime': regime}\n",
        "            for h in FORWARD_HORIZONS:\n",
        "                r = grp[f'r_forward_{h}']\n",
        "                row[f'mean_{h}'] = r.mean()\n",
        "                row[f'median_{h}'] = r.median()\n",
        "                row[f'sharpe_{h}'] = sharpe_ratio(r)\n",
        "            rows.append(row)\n",
        "        table_topdown = pd.DataFrame(rows).set_index('regime').sort_index()\n",
        "        print(\"\\n📊 Метрики по агрегированному режиму (top-down, базовый 1h):\")\n",
        "        print(table_topdown)\n",
        "\n",
        "        # Стабильность и бэктест\n",
        "        stab_td = stability_metrics(agg_regime)\n",
        "        bt_td = backtest_regime_on_off(d_base['close'], agg_regime)\n",
        "        print(\"\\nСтабильность top-down:\", stab_td)\n",
        "        print(\"\\nБэктест top-down vs buy&hold:\")\n",
        "        print(bt_td)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
