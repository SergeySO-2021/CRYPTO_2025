"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö CSV –¥–∞–Ω–Ω—ã—Ö (OHLCV + Trades) –≤ InfluxDB
"""

import sys
from pathlib import Path
import pandas as pd
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from binance_data_collector.utils.influxdb_client import InfluxDBWriter
from binance_data_collector.utils.logger import setup_logger

logger = setup_logger("load_combined_to_influxdb")

def load_combined_to_influxdb(
    csv_file: str,
    symbol: str = "BTCUSDT",
    timeframe: str = "15m",
    influxdb_url: str = "http://localhost:8086",
    influxdb_token: str = "my-super-secret-admin-token",
    org: str = "crypto",
    bucket: str = "binance_data"
):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö CSV –¥–∞–Ω–Ω—ã—Ö (OHLCV + Trades) –≤ InfluxDB
    
    Args:
        csv_file: –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É
        symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
        timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–∞–Ω–Ω—ã—Ö
        influxdb_url: URL InfluxDB —Å–µ—Ä–≤–µ—Ä–∞
        influxdb_token: –¢–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞
        org: –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è
        bucket: –ë–∞–∫–µ—Ç (–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö)
    """
    logger.info("="*70)
    logger.info("üìä –ó–ê–ì–†–£–ó–ö–ê –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–• –î–ê–ù–ù–´–• –í INFLUXDB")
    logger.info("="*70)
    logger.info(f"üìÅ –§–∞–π–ª: {csv_file}")
    logger.info(f"üìä –°–∏–º–≤–æ–ª: {symbol}")
    logger.info(f"‚è±Ô∏è  –¢–∞–π–º—Ñ—Ä–µ–π–º: {timeframe}")
    logger.info(f"üîó InfluxDB: {influxdb_url}")
    logger.info("="*70)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
    csv_path = Path(csv_file)
    if not csv_path.exists():
        logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_file}")
        return False
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ CSV
    logger.info(f"\nüìñ –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞...")
    try:
        df = pd.read_csv(csv_path)
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
        logger.info(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")
        return False
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–∏
    logger.info(f"\nüïê –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫...")
    if 'time' in df.columns:
        df['time'] = pd.to_datetime(df['time'])
        df.set_index('time', inplace=True)
        logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'time'")
    elif 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'timestamp'")
    else:
        logger.error(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π!")
        return False
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    df.sort_index(inplace=True)
    
    logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {df.index[0]} - {df.index[-1]}")
    logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ InfluxDB
    logger.info(f"\nüîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ InfluxDB...")
    writer = InfluxDBWriter(
        url=influxdb_url,
        token=influxdb_token,
        org=org,
        bucket=bucket
    )
    
    if writer.client is None:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ InfluxDB!")
        return False
    
    # –ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö
    logger.info(f"\nüíæ –ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –≤ InfluxDB...")
    try:
        from influxdb_client import Point
        
        chunk_size = 10000
        total_chunks = (len(df) + chunk_size - 1) // chunk_size
        
        for i in range(0, len(df), chunk_size):
            chunk = df.iloc[i:i+chunk_size]
            chunk_num = (i // chunk_size) + 1
            
            logger.info(f"   üì¶ –ó–∞–ø–∏—Å—ã–≤–∞—é —á–∞–Ω–∫ {chunk_num}/{total_chunks} ({len(chunk)} –∑–∞–ø–∏—Å–µ–π)...")
            
            points = []
            for timestamp, row in chunk.iterrows():
                point = Point("btc_combined") \
                    .tag("symbol", symbol) \
                    .tag("timeframe", timeframe) \
                    .time(pd.Timestamp(timestamp))
                
                # OHLCV –ø–æ–ª—è
                if 'open' in row and pd.notna(row['open']):
                    point = point.field("open", float(row['open']))
                if 'high' in row and pd.notna(row['high']):
                    point = point.field("high", float(row['high']))
                if 'low' in row and pd.notna(row['low']):
                    point = point.field("low", float(row['low']))
                if 'close' in row and pd.notna(row['close']):
                    point = point.field("close", float(row['close']))
                if 'volume' in row and pd.notna(row['volume']):
                    point = point.field("volume", float(row['volume']))
                if 'quote_volume' in row and pd.notna(row['quote_volume']):
                    point = point.field("quote_volume", float(row['quote_volume']))
                if 'taker_buy_base' in row and pd.notna(row['taker_buy_base']):
                    point = point.field("taker_buy_base", float(row['taker_buy_base']))
                if 'taker_buy_quote' in row and pd.notna(row['taker_buy_quote']):
                    point = point.field("taker_buy_quote", float(row['taker_buy_quote']))
                
                # Trades –ø–æ–ª—è
                if 'trades_buy_volume' in row and pd.notna(row['trades_buy_volume']):
                    point = point.field("trades_buy_volume", float(row['trades_buy_volume']))
                if 'trades_sell_volume' in row and pd.notna(row['trades_sell_volume']):
                    point = point.field("trades_sell_volume", float(row['trades_sell_volume']))
                if 'trades_total_volume' in row and pd.notna(row['trades_total_volume']):
                    point = point.field("trades_total_volume", float(row['trades_total_volume']))
                if 'trades_count' in row and pd.notna(row['trades_count']):
                    point = point.field("trades_count", int(row['trades_count']))
                
                points.append(point)
            
            writer.write_api.write(bucket=bucket, record=points)
            logger.info(f"   ‚úÖ –ß–∞–Ω–∫ {chunk_num} –∑–∞–ø–∏—Å–∞–Ω")
        
        logger.info(f"\n‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ InfluxDB!")
        logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–∞–Ω–æ: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {df.index[0]} - {df.index[-1]}")
        logger.info(f"\nüé® –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å Grafana: http://localhost:3001")
        logger.info(f"   –ò –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π –¥–∞—à–±–æ—Ä–¥ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ InfluxDB: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False
    finally:
        writer.close()


if __name__ == "__main__":
    csv_file = r"C:\Users\XE\Desktop\CRYPTO_2025\binance_data_collector\BTCUSDT_15m_COMBINED.csv"
    
    success = load_combined_to_influxdb(
        csv_file=csv_file,
        symbol="BTCUSDT",
        timeframe="15m"
    )
    
    sys.exit(0 if success else 1)

