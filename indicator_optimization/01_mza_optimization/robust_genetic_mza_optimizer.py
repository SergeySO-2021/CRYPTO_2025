"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ MZA
—Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import random
import warnings
from sklearn.model_selection import TimeSeriesSplit
warnings.filterwarnings('ignore')

class RobustGeneticMZAOptimizer:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    
    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–∞—Ö
    - –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ out-of-sample –¥–∞–Ω–Ω—ã—Ö
    - –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
    """
    
    def __init__(self, 
                 population_size: int = 50,
                 max_generations: int = 100,
                 mutation_rate: float = 0.1,
                 crossover_rate: float = 0.8,
                 elite_size: int = 5,
                 cv_folds: int = 3,
                 regularization_strength: float = 0.01):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞
        
        Args:
            population_size: –†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏
            max_generations: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∫–æ–ª–µ–Ω–∏–π
            mutation_rate: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º—É—Ç–∞—Ü–∏–∏
            crossover_rate: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏—è
            elite_size: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–∏—Ç–Ω—ã—Ö –æ—Å–æ–±–µ–π
            cv_folds: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
            regularization_strength: –°–∏–ª–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
        """
        self.population_size = population_size
        self.max_generations = max_generations
        self.mutation_rate = mutation_rate
        self.crossover_rate = crossover_rate
        self.elite_size = elite_size
        self.cv_folds = cv_folds
        self.regularization_strength = regularization_strength
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã MZA –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.param_ranges = {
            # Trend Indicators
            'adx_length': (10, 20, 1),
            'adx_threshold': (15, 30, 1),
            'fast_ma_length': (15, 25, 1),
            'slow_ma_length': (40, 60, 1),
            
            # Momentum Indicators
            'rsi_length': (10, 20, 1),
            'rsi_overbought': (65, 80, 1),
            'rsi_oversold': (20, 35, 1),
            'stoch_length': (10, 20, 1),
            'macd_fast': (8, 16, 1),
            'macd_slow': (20, 30, 1),
            
            # Price Action Indicators
            'bb_length': (15, 25, 1),
            'bb_std': (1.5, 3.0, 0.1),
            'atr_length': (10, 20, 1),
            
            # Dynamic Weights
            'trend_weight_high_vol': (0.4, 0.6, 0.05),
            'momentum_weight_high_vol': (0.3, 0.4, 0.05),
            'price_action_weight_low_vol': (0.4, 0.6, 0.05)
        }
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.best_individual = None
        self.best_fitness = -float('inf')
        self.generation_history = []
        self.cv_scores = []
        
    def create_random_individual(self) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é –æ—Å–æ–±—å (–Ω–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)"""
        individual = {}
        for param, (min_val, max_val, step) in self.param_ranges.items():
            if step >= 1:
                individual[param] = random.randint(int(min_val), int(max_val))
            else:
                steps = int((max_val - min_val) / step) + 1
                individual[param] = min_val + random.randint(0, steps - 1) * step
        return individual
    
    def create_initial_population(self) -> List[Dict]:
        """–°–æ–∑–¥–∞–µ—Ç –Ω–∞—á–∞–ª—å–Ω—É—é –ø–æ–ø—É–ª—è—Ü–∏—é"""
        population = []
        for _ in range(self.population_size):
            individual = self.create_random_individual()
            population.append(individual)
        return population
    
    def simple_mza_classify(self, params: Dict, data: pd.DataFrame) -> np.ndarray:
        """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è MZA –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—Ü–µ–Ω–∫–∏"""
        predictions = np.zeros(len(data))
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        rsi_length = params.get('rsi_length', 14)
        rsi_overbought = params.get('rsi_overbought', 70)
        rsi_oversold = params.get('rsi_oversold', 30)
        fast_ma_length = params.get('fast_ma_length', 20)
        slow_ma_length = params.get('slow_ma_length', 50)
        
        # –í—ã—á–∏—Å–ª—è–µ–º RSI
        delta = data['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=rsi_length).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=rsi_length).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
        fast_ma = data['close'].rolling(window=fast_ma_length).mean()
        slow_ma = data['close'].rolling(window=slow_ma_length).mean()
        
        # –ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        for i in range(len(data)):
            if i < max(rsi_length, slow_ma_length):
                predictions[i] = 0
            else:
                trend_signal = 1 if fast_ma.iloc[i] > slow_ma.iloc[i] else -1
                
                if rsi.iloc[i] > rsi_overbought:
                    momentum_signal = -1
                elif rsi.iloc[i] < rsi_oversold:
                    momentum_signal = 1
                else:
                    momentum_signal = 0
                
                if trend_signal == momentum_signal and momentum_signal != 0:
                    predictions[i] = momentum_signal
                elif trend_signal != 0:
                    predictions[i] = trend_signal * 0.5
                else:
                    predictions[i] = 0
        
        return predictions
    
    def calculate_economic_value(self, data: pd.DataFrame, predictions: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç Economic Value —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π"""
        # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
        returns = data['close'].pct_change().dropna()
        
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
        aligned_returns = returns.iloc[1:]
        aligned_predictions = predictions[1:len(aligned_returns)+1]
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º
        bull_mask = aligned_predictions > 0.5
        bear_mask = aligned_predictions < -0.5
        sideways_mask = (aligned_predictions >= -0.5) & (aligned_predictions <= 0.5)
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
        bull_returns = aligned_returns[bull_mask].mean() if bull_mask.any() else 0
        bear_returns = aligned_returns[bear_mask].mean() if bear_mask.any() else 0
        sideways_returns = aligned_returns[sideways_mask].mean() if sideways_mask.any() else 0
        
        # Economic Value
        return_spread = abs(bull_returns - bear_returns)
        sideways_vol = aligned_returns[sideways_mask].std() if sideways_mask.any() else 0
        economic_value = return_spread / (1 + sideways_vol) if sideways_vol > 0 else return_spread
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
        zone_changes = np.sum(np.diff(aligned_predictions) != 0)
        stability_penalty = zone_changes / len(aligned_predictions) * 0.1
        
        # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        regularization_penalty = self.regularization_strength * (
            abs(bull_returns) + abs(bear_returns) + abs(sideways_returns)
        )
        
        return economic_value - stability_penalty - regularization_penalty
    
    def cross_validate_fitness(self, individual: Dict, data: pd.DataFrame) -> Dict:
        """
        –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        
        Args:
            individual: –ù–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ train/test
        split_point = int(len(data) * 0.7)  # 70% –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, 30% –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        train_data = data.iloc[:split_point]
        test_data = data.iloc[split_point:]
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        train_predictions = self.simple_mza_classify(individual, train_data)
        train_score = self.calculate_economic_value(train_data, train_predictions)
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        test_predictions = self.simple_mza_classify(individual, test_data)
        test_score = self.calculate_economic_value(test_data, test_predictions)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
        stability = 1 - abs(train_score - test_score) / (abs(train_score) + abs(test_score) + 1e-8)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        combined_score = 0.7 * test_score + 0.3 * train_score
        
        return {
            'train_score': train_score,
            'test_score': test_score,
            'stability': stability,
            'combined_score': combined_score,
            'overfitting_risk': abs(train_score - test_score)
        }
    
    def evaluate_fitness(self, individual: Dict, data: pd.DataFrame) -> float:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å –æ—Å–æ–±–∏ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
        
        Args:
            individual: –ù–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –ó–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏ —Å —É—á–µ—Ç–æ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        """
        try:
            # –ü—Ä–æ–≤–æ–¥–∏–º –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é
            cv_results = self.cross_validate_fitness(individual, data)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            self.cv_scores.append(cv_results)
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É
            return cv_results['combined_score']
            
        except Exception as e:
            return -1000.0
    
    def tournament_selection(self, population: List[Dict], fitness_scores: List[float], 
                           tournament_size: int = 3) -> Dict:
        """–¢—É—Ä–Ω–∏—Ä–Ω–∞—è —Å–µ–ª–µ–∫—Ü–∏—è"""
        tournament_indices = random.sample(range(len(population)), tournament_size)
        tournament_fitness = [fitness_scores[i] for i in tournament_indices]
        winner_index = tournament_indices[np.argmax(tournament_fitness)]
        return population[winner_index]
    
    def crossover(self, parent1: Dict, parent2: Dict) -> Tuple[Dict, Dict]:
        """–°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–≤—É—Ö —Ä–æ–¥–∏—Ç–µ–ª–µ–π"""
        child1 = {}
        child2 = {}
        
        for param in self.param_ranges.keys():
            if random.random() < 0.5:
                child1[param] = parent1[param]
                child2[param] = parent2[param]
            else:
                child1[param] = parent2[param]
                child2[param] = parent1[param]
        
        return child1, child2
    
    def mutate(self, individual: Dict) -> Dict:
        """–ú—É—Ç–∞—Ü–∏—è –æ—Å–æ–±–∏"""
        mutated = individual.copy()
        
        for param, (min_val, max_val, step) in self.param_ranges.items():
            if random.random() < self.mutation_rate:
                if step >= 1:
                    mutated[param] = random.randint(int(min_val), int(max_val))
                else:
                    steps = int((max_val - min_val) / step) + 1
                    mutated[param] = min_val + random.randint(0, steps - 1) * step
        
        return mutated
    
    def optimize(self, data: pd.DataFrame, verbose: bool = True) -> Dict:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Args:
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            verbose: –í—ã–≤–æ–¥–∏—Ç—å –ª–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        """
        if verbose:
            print("üß¨ –ó–ê–ü–£–°–ö –£–õ–£–ß–®–ï–ù–ù–û–ì–û –ì–ï–ù–ï–¢–ò–ß–ï–°–ö–û–ì–û –ê–õ–ì–û–†–ò–¢–ú–ê –° –ó–ê–©–ò–¢–û–ô –û–¢ –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–Ø")
            print("=" * 80)
            print(f"üìä –†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏: {self.population_size}")
            print(f"üîÑ –ú–∞–∫—Å–∏–º—É–º –ø–æ–∫–æ–ª–µ–Ω–∏–π: {self.max_generations}")
            print(f"üß¨ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º—É—Ç–∞—Ü–∏–∏: {self.mutation_rate}")
            print(f"üîÄ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏—è: {self.crossover_rate}")
            print(f"üëë –†–∞–∑–º–µ—Ä —ç–ª–∏—Ç—ã: {self.elite_size}")
            print(f"üìä –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: {self.cv_folds} —Ñ–æ–ª–¥–æ–≤")
            print(f"üõ°Ô∏è –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è: {self.regularization_strength}")
            print("=" * 80)
        
        # –°–æ–∑–¥–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –ø–æ–ø—É–ª—è—Ü–∏—é
        population = self.create_initial_population()
        
        for generation in range(self.max_generations):
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –æ—Å–æ–±–µ–π
            fitness_scores = []
            for individual in population:
                fitness = self.evaluate_fitness(individual, data)
                fitness_scores.append(fitness)
            
            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –æ—Å–æ–±—å
            best_idx = np.argmax(fitness_scores)
            best_fitness = fitness_scores[best_idx]
            best_individual = population[best_idx]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if best_fitness > self.best_fitness:
                self.best_fitness = best_fitness
                self.best_individual = best_individual.copy()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ–∫–æ–ª–µ–Ω–∏—è
            self.generation_history.append({
                'generation': generation,
                'best_fitness': best_fitness,
                'avg_fitness': np.mean(fitness_scores),
                'worst_fitness': np.min(fitness_scores),
                'stability': np.mean([score['stability'] for score in self.cv_scores[-self.population_size:]])
            })
            
            if verbose and generation % 10 == 0:
                avg_stability = np.mean([score['stability'] for score in self.cv_scores[-self.population_size:]])
                print(f"üîÑ –ü–æ–∫–æ–ª–µ–Ω–∏–µ {generation:3d}: "
                      f"–õ—É—á—à–∏–π = {best_fitness:.6f}, "
                      f"–°—Ä–µ–¥–Ω–∏–π = {np.mean(fitness_scores):.6f}, "
                      f"–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å = {avg_stability:.3f}")
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –ø–æ–ø—É–ª—è—Ü–∏—é
            new_population = []
            
            # –≠–ª–∏—Ç–∏–∑–º
            elite_indices = np.argsort(fitness_scores)[-self.elite_size:]
            for idx in elite_indices:
                new_population.append(population[idx].copy())
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–π
            while len(new_population) < self.population_size:
                parent1 = self.tournament_selection(population, fitness_scores)
                parent2 = self.tournament_selection(population, fitness_scores)
                
                if random.random() < self.crossover_rate:
                    child1, child2 = self.crossover(parent1, parent2)
                else:
                    child1, child2 = parent1.copy(), parent2.copy()
                
                child1 = self.mutate(child1)
                child2 = self.mutate(child2)
                
                new_population.extend([child1, child2])
            
            population = new_population[:self.population_size]
        
        # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        overfitting_analysis = self.analyze_overfitting()
        
        if verbose:
            print(f"\n‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
            print(f"üèÜ –õ—É—á—à–∏–π Economic Value: {self.best_fitness:.6f}")
            print(f"üìä –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–∫–æ–ª–µ–Ω–∏–π: {self.max_generations}")
            print(f"üß¨ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω–æ–∫: {self.max_generations * self.population_size}")
            print(f"üõ°Ô∏è –†–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {overfitting_analysis['overfitting_risk']:.3f}")
            print(f"üìà –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {overfitting_analysis['stability']:.3f}")
        
        return {
            'best_parameters': self.best_individual,
            'best_score': self.best_fitness,
            'generation_history': self.generation_history,
            'total_evaluations': self.max_generations * self.population_size,
            'algorithm': 'robust_genetic',
            'overfitting_analysis': overfitting_analysis,
            'cv_scores': self.cv_scores
        }
    
    def analyze_overfitting(self) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
        if not self.cv_scores:
            return {'overfitting_risk': 0, 'stability': 0}
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        recent_scores = self.cv_scores[-self.population_size:]
        
        train_scores = [score['train_score'] for score in recent_scores]
        test_scores = [score['test_score'] for score in recent_scores]
        stabilities = [score['stability'] for score in recent_scores]
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        avg_train = np.mean(train_scores)
        avg_test = np.mean(test_scores)
        avg_stability = np.mean(stabilities)
        
        # –†–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        overfitting_risk = abs(avg_train - avg_test) / (abs(avg_train) + abs(avg_test) + 1e-8)
        
        return {
            'overfitting_risk': overfitting_risk,
            'stability': avg_stability,
            'train_test_gap': abs(avg_train - avg_test),
            'avg_train_score': avg_train,
            'avg_test_score': avg_test
        }
    
    def plot_convergence_with_stability(self):
        """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏"""
        if not self.generation_history:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞")
            return
        
        import matplotlib.pyplot as plt
        
        generations = [h['generation'] for h in self.generation_history]
        best_fitness = [h['best_fitness'] for h in self.generation_history]
        avg_fitness = [h['avg_fitness'] for h in self.generation_history]
        stability = [h['stability'] for h in self.generation_history]
        
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
        
        # –ì—Ä–∞—Ñ–∏–∫ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        ax1.plot(generations, best_fitness, 'b-', label='–õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç', linewidth=2)
        ax1.plot(generations, avg_fitness, 'r--', label='–°—Ä–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç', linewidth=1)
        ax1.set_xlabel('–ü–æ–∫–æ–ª–µ–Ω–∏–µ')
        ax1.set_ylabel('Economic Value')
        ax1.set_title('–°—Ö–æ–¥–∏–º–æ—Å—Ç—å —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        ax2.plot(generations, stability, 'g-', label='–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å', linewidth=2)
        ax2.set_xlabel('–ü–æ–∫–æ–ª–µ–Ω–∏–µ')
        ax2.set_ylabel('–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å')
        ax2.set_title('–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–æ –≤—Ä–µ–º–µ–Ω–∏')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def export_to_pine_script(self, output_file: str = "robust_genetic_optimized_mza.pine") -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Ñ–æ—Ä–º–∞—Ç Pine Script"""
        if not self.best_individual:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é")
        
        overfitting_analysis = self.analyze_overfitting()
        
        pine_code = f"""// –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã MZA —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
// –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö BTC
// –î–∞—Ç–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {pd.Timestamp.now().strftime('%d.%m.%Y %H:%M')}
// –õ—É—á—à–∏–π Economic Value: {self.best_fitness:.6f}
// –ê–ª–≥–æ—Ä–∏—Ç–º: –£–ª—É—á—à–µ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
// –†–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {overfitting_analysis['overfitting_risk']:.3f}
// –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {overfitting_analysis['stability']:.3f}

//@version=5
indicator("Robust Genetic Optimized MZA [BullByte]", overlay=true)

// ===== –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ (–° –ó–ê–©–ò–¢–û–ô –û–¢ –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–Ø) =====

// Trend Indicators
adx_length = input.int({self.best_individual.get('adx_length', 14)}, "ADX Length", minval=10, maxval=20)
adx_threshold = input.int({self.best_individual.get('adx_threshold', 20)}, "ADX Threshold", minval=15, maxval=30)
fast_ma_length = input.int({self.best_individual.get('fast_ma_length', 20)}, "Fast MA Length", minval=15, maxval=25)
slow_ma_length = input.int({self.best_individual.get('slow_ma_length', 50)}, "Slow MA Length", minval=40, maxval=60)

// Momentum Indicators
rsi_length = input.int({self.best_individual.get('rsi_length', 14)}, "RSI Length", minval=10, maxval=20)
rsi_overbought = input.int({self.best_individual.get('rsi_overbought', 70)}, "RSI Overbought", minval=65, maxval=80)
rsi_oversold = input.int({self.best_individual.get('rsi_oversold', 30)}, "RSI Oversold", minval=20, maxval=35)
stoch_length = input.int({self.best_individual.get('stoch_length', 14)}, "Stochastic Length", minval=10, maxval=20)
macd_fast = input.int({self.best_individual.get('macd_fast', 12)}, "MACD Fast", minval=8, maxval=16)
macd_slow = input.int({self.best_individual.get('macd_slow', 26)}, "MACD Slow", minval=20, maxval=30)

// Price Action Indicators
bb_length = input.int({self.best_individual.get('bb_length', 20)}, "Bollinger Bands Length", minval=15, maxval=25)
bb_std = input.float({self.best_individual.get('bb_std', 2.0)}, "Bollinger Bands Std Dev", minval=1.5, maxval=3.0)
atr_length = input.int({self.best_individual.get('atr_length', 14)}, "ATR Length", minval=10, maxval=20)

// Dynamic Weights
trend_weight_high_vol = input.float({self.best_individual.get('trend_weight_high_vol', 0.5)}, "Trend Weight (High Vol)", minval=0.4, maxval=0.6)
momentum_weight_high_vol = input.float({self.best_individual.get('momentum_weight_high_vol', 0.35)}, "Momentum Weight (High Vol)", minval=0.3, maxval=0.4)
price_action_weight_low_vol = input.float({self.best_individual.get('price_action_weight_low_vol', 0.45)}, "Price Action Weight (Low Vol)", minval=0.4, maxval=0.6)

// ===== –û–°–¢–ê–õ–¨–ù–û–ô –ö–û–î MZA –û–°–¢–ê–ï–¢–°–Ø –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô =====

// ===== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –£–õ–£–ß–®–ï–ù–ù–û–ô –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò =====
// Economic Value: {self.best_fitness:.6f}
// –†–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {overfitting_analysis['overfitting_risk']:.3f}
// –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {overfitting_analysis['stability']:.3f}
// –ü–æ–∫–æ–ª–µ–Ω–∏–π: {self.max_generations}
// –†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏: {self.population_size}
"""
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(pine_code)
        
        print(f"üìÑ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {output_file}")
        return pine_code


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    optimizer = RobustGeneticMZAOptimizer(
        population_size=30,
        max_generations=50,
        mutation_rate=0.1,
        crossover_rate=0.8,
        cv_folds=3,
        regularization_strength=0.01
    )
    
    print("üõ°Ô∏è Robust Genetic MZA Optimizer –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {len(optimizer.param_ranges)}")
    print(f"üîß –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {list(optimizer.param_ranges.keys())}")
    print(f"üõ°Ô∏è –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: –í–∫–ª—é—á–µ–Ω–∞")
    print(f"üìä –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: {optimizer.cv_folds} —Ñ–æ–ª–¥–æ–≤")
