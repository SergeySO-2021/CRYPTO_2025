"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–ª–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ MZA
–° —É—á–µ—Ç–æ–º –≤—Å–µ—Ö 23 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import random
import warnings
from accurate_mza_classifier import AccurateMZAClassifier
warnings.filterwarnings('ignore')

class CompleteMZAOptimizer:
    """
    –ü–æ–ª–Ω—ã–π –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ MZA
    
    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –í—Å–µ 23 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ MZA
    - –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç Market Activity
    - –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    - –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    - –†–µ–∂–∏–º-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
    """
    
    def __init__(self, 
                 population_size: int = 50,
                 max_generations: int = 100,
                 mutation_rate: float = 0.1,
                 crossover_rate: float = 0.8,
                 elite_size: int = 5,
                 cv_folds: int = 3,
                 regularization_strength: float = 0.01):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ MZA
        
        Args:
            population_size: –†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏
            max_generations: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∫–æ–ª–µ–Ω–∏–π
            mutation_rate: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º—É—Ç–∞—Ü–∏–∏
            crossover_rate: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏—è
            elite_size: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–∏—Ç–Ω—ã—Ö –æ—Å–æ–±–µ–π
            cv_folds: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
            regularization_strength: –°–∏–ª–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
        """
        self.population_size = population_size
        self.max_generations = max_generations
        self.mutation_rate = mutation_rate
        self.crossover_rate = crossover_rate
        self.elite_size = elite_size
        self.cv_folds = cv_folds
        self.regularization_strength = regularization_strength
        
        # –ü–æ–ª–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã MZA –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (23 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞)
        self.param_ranges = {
            # Trend Indicators (4 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞)
            'adxLength': (10, 20, 1),
            'adxThreshold': (15, 30, 1),
            'fastMALength': (15, 25, 1),
            'slowMALength': (40, 60, 1),
            
            # Momentum Indicators (5 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
            'rsiLength': (10, 20, 1),
            'stochKLength': (10, 20, 1),
            'macdFast': (8, 16, 1),
            'macdSlow': (20, 30, 1),
            'macdSignal': (7, 12, 1),
            
            # Price Action Indicators (3 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞)
            'hhllRange': (15, 30, 1),
            'haDojiRange': (3, 10, 1),
            'candleRangeLength': (5, 15, 1),
            
            # Market Activity Indicators (6 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
            'bbLength': (15, 25, 1),
            'bbMultiplier': (1.5, 3.0, 0.1),
            'atrLength': (10, 20, 1),
            'kcLength': (15, 25, 1),
            'kcMultiplier': (1.0, 2.5, 0.1),
            'volumeMALength': (15, 25, 1),
            
            # Base Weights (3 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞)
            'trendWeightBase': (30, 50, 1),
            'momentumWeightBase': (20, 40, 1),
            'priceActionWeightBase': (20, 40, 1),
            
            # Stability Controls (2 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞) - –±—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è
            'useSmoothing': [True, False],
            'useHysteresis': [True, False]
        }
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.best_individual = None
        self.best_fitness = -float('inf')
        self.generation_history = []
        self.cv_scores = []
        
    def create_random_individual(self) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é –æ—Å–æ–±—å (–Ω–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)"""
        individual = {}
        for param, config in self.param_ranges.items():
            if isinstance(config, list):
                # –ë—É–ª–µ–≤—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                individual[param] = random.choice(config)
            else:
                min_val, max_val, step = config
                if step >= 1:
                    # –¶–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                    individual[param] = random.randint(int(min_val), int(max_val))
                else:
                    # –í–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                    steps = int((max_val - min_val) / step) + 1
                    individual[param] = min_val + random.randint(0, steps - 1) * step
        return individual
    
    def create_initial_population(self) -> List[Dict]:
        """–°–æ–∑–¥–∞–µ—Ç –Ω–∞—á–∞–ª—å–Ω—É—é –ø–æ–ø—É–ª—è—Ü–∏—é"""
        population = []
        for _ in range(self.population_size):
            individual = self.create_random_individual()
            population.append(individual)
        return population
    
    def evaluate_fitness(self, individual: Dict, data: pd.DataFrame) -> float:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å –æ—Å–æ–±–∏ —Å –ø–æ–ª–Ω–æ–π –ª–æ–≥–∏–∫–æ–π MZA
        
        Args:
            individual: –ù–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –ó–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏
        """
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å —Ç–µ–∫—É—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            classifier = AccurateMZAClassifier(individual)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            predictions = classifier.predict(data)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É
            fitness = self.calculate_comprehensive_mza_score(data, predictions, individual)
            return fitness
            
        except Exception as e:
            return -1000.0
    
    def calculate_comprehensive_mza_score(self, data: pd.DataFrame, zones: np.ndarray, 
                                       params: Dict) -> float:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ MZA –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
        
        Args:
            data: –î–∞–Ω–Ω—ã–µ
            zones: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–æ–Ω
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π —Å–∫–æ—Ä
        """
        returns = data['close'].pct_change().dropna()
        
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
        max_lookback = max(params['slowMALength'], params['adxLength'])
        aligned_returns = returns.iloc[max_lookback:]
        aligned_zones = zones[max_lookback:len(aligned_returns)+1]
        
        if len(aligned_returns) == 0 or len(aligned_zones) == 0:
            return 0.0
        
        # 1. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø–æ –∑–æ–Ω–∞–º (40%)
        bull_returns = aligned_returns[aligned_zones == 1]
        bear_returns = aligned_returns[aligned_zones == -1]
        sideways_returns = aligned_returns[aligned_zones == 0]
        
        return_spread = 0
        if len(bull_returns) > 0 and len(bear_returns) > 0:
            return_spread = abs(bull_returns.mean() - bear_returns.mean())
        
        sideways_volatility = sideways_returns.std() if len(sideways_returns) > 0 else 1
        
        # 2. –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∑–æ–Ω (25%)
        zone_changes = np.sum(np.diff(aligned_zones) != 0)
        zone_stability = 1 - (zone_changes / len(aligned_zones)) if len(aligned_zones) > 0 else 0
        
        # 3. –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤ (20%)
        signal_consistency = self.calculate_signal_consistency(aligned_zones, aligned_returns)
        
        # 4. –ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã (15%)
        adaptability_score = self.calculate_adaptability_score(params, data)
        
        # –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π —Å–∫–æ—Ä
        composite_score = (
            return_spread * 0.4 +
            zone_stability * 0.25 +
            signal_consistency * 0.2 +
            adaptability_score * 0.15
        ) / (1 + sideways_volatility)
        
        return max(composite_score, 0)
    
    def calculate_signal_consistency(self, zones: np.ndarray, returns: pd.Series) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤"""
        if len(zones) == 0 or len(returns) == 0:
            return 0.0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–∏–≥–Ω–∞–ª—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –¥–≤–∏–∂–µ–Ω–∏—é —Ü–µ–Ω—ã
        correct_signals = 0
        total_signals = 0
        
        for i in range(1, len(zones)):
            if zones[i] != 0:  # –ù–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –∑–æ–Ω–∞
                price_direction = 1 if returns.iloc[i] > 0 else -1 if returns.iloc[i] < 0 else 0
                if zones[i] == price_direction:
                    correct_signals += 1
                total_signals += 1
        
        return correct_signals / total_signals if total_signals > 0 else 0.0
    
    def calculate_adaptability_score(self, params: Dict, data: pd.DataFrame) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
        adaptability_score = 1.0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if params['fastMALength'] >= params['slowMALength']:
            adaptability_score -= 0.3
        
        if params['macdFast'] >= params['macdSlow']:
            adaptability_score -= 0.3
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–µ—Å–∞ –≤ —Å—É–º–º–µ –¥–∞—é—Ç 100%
        total_weight = params['trendWeightBase'] + params['momentumWeightBase'] + params['priceActionWeightBase']
        if abs(total_weight - 100) > 5:  # –î–æ–ø—É—Å–∫ 5%
            adaptability_score -= 0.2
        
        return max(adaptability_score, 0.0)
    
    def cross_validate_fitness(self, individual: Dict, data: pd.DataFrame) -> Dict:
        """
        –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        
        Args:
            individual: –ù–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ train/test
        split_point = int(len(data) * 0.7)  # 70% –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, 30% –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        train_data = data.iloc[:split_point]
        test_data = data.iloc[split_point:]
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        train_fitness = self.evaluate_fitness(individual, train_data)
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        test_fitness = self.evaluate_fitness(individual, test_data)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
        stability = 1 - abs(train_fitness - test_fitness) / (abs(train_fitness) + abs(test_fitness) + 1e-8)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        combined_score = 0.7 * test_fitness + 0.3 * train_fitness
        
        return {
            'train_score': train_fitness,
            'test_score': test_fitness,
            'stability': stability,
            'combined_score': combined_score,
            'overfitting_risk': abs(train_fitness - test_fitness)
        }
    
    def tournament_selection(self, population: List[Dict], fitness_scores: List[float], 
                           tournament_size: int = 3) -> Dict:
        """–¢—É—Ä–Ω–∏—Ä–Ω–∞—è —Å–µ–ª–µ–∫—Ü–∏—è"""
        tournament_indices = random.sample(range(len(population)), tournament_size)
        tournament_fitness = [fitness_scores[i] for i in tournament_indices]
        winner_index = tournament_indices[np.argmax(tournament_fitness)]
        return population[winner_index]
    
    def crossover(self, parent1: Dict, parent2: Dict) -> Tuple[Dict, Dict]:
        """–°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–≤—É—Ö —Ä–æ–¥–∏—Ç–µ–ª–µ–π"""
        child1 = {}
        child2 = {}
        
        for param in self.param_ranges.keys():
            if random.random() < 0.5:
                child1[param] = parent1[param]
                child2[param] = parent2[param]
            else:
                child1[param] = parent2[param]
                child2[param] = parent1[param]
        
        return child1, child2
    
    def mutate(self, individual: Dict) -> Dict:
        """–ú—É—Ç–∞—Ü–∏—è –æ—Å–æ–±–∏"""
        mutated = individual.copy()
        
        for param, config in self.param_ranges.items():
            if random.random() < self.mutation_rate:
                if isinstance(config, list):
                    # –ë—É–ª–µ–≤—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                    mutated[param] = random.choice(config)
                else:
                    min_val, max_val, step = config
                    if step >= 1:
                        mutated[param] = random.randint(int(min_val), int(max_val))
                    else:
                        steps = int((max_val - min_val) / step) + 1
                        mutated[param] = min_val + random.randint(0, steps - 1) * step
        
        return mutated
    
    def optimize(self, data: pd.DataFrame, verbose: bool = True) -> Dict:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Args:
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            verbose: –í—ã–≤–æ–¥–∏—Ç—å –ª–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        """
        if verbose:
            print("üß¨ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ì–ï–ù–ï–¢–ò–ß–ï–°–ö–û–ì–û –ê–õ–ì–û–†–ò–¢–ú–ê –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò MZA")
            print("=" * 80)
            print(f"üìä –†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏: {self.population_size}")
            print(f"üîÑ –ú–∞–∫—Å–∏–º—É–º –ø–æ–∫–æ–ª–µ–Ω–∏–π: {self.max_generations}")
            print(f"üß¨ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º—É—Ç–∞—Ü–∏–∏: {self.mutation_rate}")
            print(f"üîÄ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏—è: {self.crossover_rate}")
            print(f"üëë –†–∞–∑–º–µ—Ä —ç–ª–∏—Ç—ã: {self.elite_size}")
            print(f"üìä –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: {self.cv_folds} —Ñ–æ–ª–¥–æ–≤")
            print(f"üõ°Ô∏è –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è: {self.regularization_strength}")
            print(f"üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {len(self.param_ranges)}")
            print("=" * 80)
        
        # –°–æ–∑–¥–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –ø–æ–ø—É–ª—è—Ü–∏—é
        population = self.create_initial_population()
        
        for generation in range(self.max_generations):
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –æ—Å–æ–±–µ–π
            fitness_scores = []
            for individual in population:
                fitness = self.evaluate_fitness(individual, data)
                fitness_scores.append(fitness)
            
            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –æ—Å–æ–±—å
            best_idx = np.argmax(fitness_scores)
            best_fitness = fitness_scores[best_idx]
            best_individual = population[best_idx]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if best_fitness > self.best_fitness:
                self.best_fitness = best_fitness
                self.best_individual = best_individual.copy()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ–∫–æ–ª–µ–Ω–∏—è
            self.generation_history.append({
                'generation': generation,
                'best_fitness': best_fitness,
                'avg_fitness': np.mean(fitness_scores),
                'worst_fitness': np.min(fitness_scores)
            })
            
            if verbose and generation % 10 == 0:
                print(f"üîÑ –ü–æ–∫–æ–ª–µ–Ω–∏–µ {generation:3d}: "
                      f"–õ—É—á—à–∏–π = {best_fitness:.6f}, "
                      f"–°—Ä–µ–¥–Ω–∏–π = {np.mean(fitness_scores):.6f}")
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –ø–æ–ø—É–ª—è—Ü–∏—é
            new_population = []
            
            # –≠–ª–∏—Ç–∏–∑–º
            elite_indices = np.argsort(fitness_scores)[-self.elite_size:]
            for idx in elite_indices:
                new_population.append(population[idx].copy())
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–π
            while len(new_population) < self.population_size:
                parent1 = self.tournament_selection(population, fitness_scores)
                parent2 = self.tournament_selection(population, fitness_scores)
                
                if random.random() < self.crossover_rate:
                    child1, child2 = self.crossover(parent1, parent2)
                else:
                    child1, child2 = parent1.copy(), parent2.copy()
                
                child1 = self.mutate(child1)
                child2 = self.mutate(child2)
                
                new_population.extend([child1, child2])
            
            population = new_population[:self.population_size]
        
        # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        overfitting_analysis = self.analyze_overfitting()
        
        if verbose:
            print(f"\n‚úÖ –ü–û–õ–ù–ê–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
            print(f"üèÜ –õ—É—á—à–∏–π Economic Value: {self.best_fitness:.6f}")
            print(f"üìä –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–∫–æ–ª–µ–Ω–∏–π: {self.max_generations}")
            print(f"üß¨ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω–æ–∫: {self.max_generations * self.population_size}")
            print(f"üõ°Ô∏è –†–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {overfitting_analysis['overfitting_risk']:.3f}")
            print(f"üìà –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {overfitting_analysis['stability']:.3f}")
        
        return {
            'best_parameters': self.best_individual,
            'best_score': self.best_fitness,
            'generation_history': self.generation_history,
            'total_evaluations': self.max_generations * self.population_size,
            'algorithm': 'complete_genetic',
            'overfitting_analysis': overfitting_analysis,
            'param_count': len(self.param_ranges)
        }
    
    def analyze_overfitting(self) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
        if not self.cv_scores:
            return {'overfitting_risk': 0, 'stability': 0}
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        recent_scores = self.cv_scores[-self.population_size:]
        
        train_scores = [score['train_score'] for score in recent_scores]
        test_scores = [score['test_score'] for score in recent_scores]
        stabilities = [score['stability'] for score in recent_scores]
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        avg_train = np.mean(train_scores)
        avg_test = np.mean(test_scores)
        avg_stability = np.mean(stabilities)
        
        # –†–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        overfitting_risk = abs(avg_train - avg_test) / (abs(avg_train) + abs(avg_test) + 1e-8)
        
        return {
            'overfitting_risk': overfitting_risk,
            'stability': avg_stability,
            'train_test_gap': abs(avg_train - avg_test),
            'avg_train_score': avg_train,
            'avg_test_score': avg_test
        }
    
    def export_to_pine_script(self, output_file: str = "complete_optimized_mza.pine") -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Ñ–æ—Ä–º–∞—Ç Pine Script"""
        if not self.best_individual:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é")
        
        overfitting_analysis = self.analyze_overfitting()
        
        pine_code = f"""// –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã MZA —Å –ø–æ–º–æ—â—å—é –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞
// –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö BTC
// –î–∞—Ç–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {pd.Timestamp.now().strftime('%d.%m.%Y %H:%M')}
// –õ—É—á—à–∏–π Economic Value: {self.best_fitness:.6f}
// –ê–ª–≥–æ—Ä–∏—Ç–º: –ü–æ–ª–Ω—ã–π –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π —Å {len(self.param_ranges)} –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
// –†–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {overfitting_analysis['overfitting_risk']:.3f}
// –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {overfitting_analysis['stability']:.3f}

//@version=6
indicator("Complete Optimized MZA [BullByte]", shorttitle="MZA[BullByte]", overlay=false)

// ===== –ü–û–õ–ù–û–°–¢–¨–Æ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ =====

// Trend Indicators
adxLength = input.int({self.best_individual.get('adxLength', 14)}, "DMI Length / ADX Smoothing", group="Trend Indicators")
adxThreshold = input.int({self.best_individual.get('adxThreshold', 20)}, "ADX Threshold", group="Trend Indicators")
fastMALength = input.int({self.best_individual.get('fastMALength', 20)}, "Fast MA Length", group="Trend Indicators")
slowMALength = input.int({self.best_individual.get('slowMALength', 50)}, "Slow MA Length", group="Trend Indicators")

// Momentum Indicators
rsiLength = input.int({self.best_individual.get('rsiLength', 14)}, "RSI Length", group="Momentum Indicators")
stochKLength = input.int({self.best_individual.get('stochKLength', 14)}, "Stoch %K Length", group="Momentum Indicators")
macdFast = input.int({self.best_individual.get('macdFast', 12)}, "MACD Fast", group="Momentum Indicators")
macdSlow = input.int({self.best_individual.get('macdSlow', 26)}, "MACD Slow", group="Momentum Indicators")
macdSignal = input.int({self.best_individual.get('macdSignal', 9)}, "MACD Signal", group="Momentum Indicators")

// Price Action Indicators
hhllRange = input.int({self.best_individual.get('hhllRange', 20)}, "HH/LL Range", group="Price Action Indicators")
haDojiRange = input.int({self.best_individual.get('haDojiRange', 5)}, "HA Doji Range", group="Price Action Indicators")
candleRangeLength = input.int({self.best_individual.get('candleRangeLength', 8)}, "Candle Range Length", group="Price Action Indicators")

// Market Activity Indicators
bbLength = input.int({self.best_individual.get('bbLength', 20)}, "BB Length", group="Market Activity Indicators")
bbMultiplier = input.float({self.best_individual.get('bbMultiplier', 2.0)}, "BB Multiplier", group="Market Activity Indicators")
atrLength = input.int({self.best_individual.get('atrLength', 14)}, "ATR Length", group="Market Activity Indicators")
kcLength = input.int({self.best_individual.get('kcLength', 20)}, "KC Length", group="Market Activity Indicators")
kcMultiplier = input.float({self.best_individual.get('kcMultiplier', 1.5)}, "KC Multiplier", group="Market Activity Indicators")
volumeMALength = input.int({self.best_individual.get('volumeMALength', 20)}, "Volume MA Length", group="Market Activity Indicators")

// Weight Inputs
trendWeightBase = input.float({self.best_individual.get('trendWeightBase', 40)}, "Trend Strength Weight (%)", minval=0, maxval=100, group="Weights")
momentumWeightBase = input.float({self.best_individual.get('momentumWeightBase', 30)}, "Momentum Weight (%)", minval=0, maxval=100, group="Weights")
priceActionWeightBase = input.float({self.best_individual.get('priceActionWeightBase', 30)}, "Price Action Weight (%)", minval=0, maxval=100, group="Weights")

// Stability Controls
useSmoothing = input.bool({str(self.best_individual.get('useSmoothing', True)).lower()}, "Smooth Market Activity", group="Stability Controls")
useHysteresis = input.bool({str(self.best_individual.get('useHysteresis', True)).lower()}, "Use Hysteresis for Stability", group="Stability Controls")

// ===== –û–°–¢–ê–õ–¨–ù–û–ô –ö–û–î MZA –û–°–¢–ê–ï–¢–°–Ø –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô =====
// –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—Å—Ç–∞–≤–ª–µ–Ω –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–¥ MZA —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
// –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—ã—à–µ

// ===== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–õ–ù–û–ô –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò =====
// Economic Value: {self.best_fitness:.6f}
// –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len(self.param_ranges)}
// –†–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {overfitting_analysis['overfitting_risk']:.3f}
// –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {overfitting_analysis['stability']:.3f}
// –ü–æ–∫–æ–ª–µ–Ω–∏–π: {self.max_generations}
// –†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏: {self.population_size}
"""
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(pine_code)
        
        print(f"üìÑ –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {output_file}")
        return pine_code


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    optimizer = CompleteMZAOptimizer(
        population_size=30,
        max_generations=50,
        mutation_rate=0.1,
        crossover_rate=0.8,
        cv_folds=3,
        regularization_strength=0.01
    )
    
    print("üß¨ Complete MZA Optimizer –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {len(optimizer.param_ranges)}")
    print(f"üîß –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {list(optimizer.param_ranges.keys())}")
    print(f"üõ°Ô∏è –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: –í–∫–ª—é—á–µ–Ω–∞")
    print(f"üìä –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: {optimizer.cv_folds} —Ñ–æ–ª–¥–æ–≤")
