"""
Market Zone Classifier - Parameter Optimizer
–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –∑–æ–Ω
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit
import warnings
warnings.filterwarnings('ignore')

# Try to import optimization libraries
try:
    from skopt import gp_minimize
    from skopt.space import Integer, Real
    from skopt.utils import use_named_args
    BAYESIAN_AVAILABLE = True
except ImportError:
    BAYESIAN_AVAILABLE = False
    print("‚ö†Ô∏è scikit-optimize –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º Genetic Algorithm")
    print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install scikit-optimize")

try:
    from deap import base, creator, tools, algorithms
    GA_AVAILABLE = True
except ImportError:
    GA_AVAILABLE = False
    print("‚ö†Ô∏è DEAP –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π Random Search")
    print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install deap")


class ZoneClassifierOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ Market Zone Classifier"""
    
    def __init__(self, data, optimization_method='bayesian', 
                 metric_weights=None):
        """
        Args:
            data: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏
            optimization_method: 'bayesian', 'genetic', –∏–ª–∏ 'random'
            metric_weights: –°–ª–æ–≤–∞—Ä—å —Å –≤–µ—Å–∞–º–∏ –º–µ—Ç—Ä–∏–∫. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é:
                {
                    'stability': 0.3,    # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∑–æ–Ω
                    'separation': 0.3,   # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∑–æ–Ω
                    'economic': 0.4      # –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å
                }
        """
        self.data = data.copy()
        self.method = optimization_method
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ—Å–æ–≤ –º–µ—Ç—Ä–∏–∫
        if metric_weights is None:
            self.metric_weights = {
                'stability': 0.3,
                'separation': 0.3,
                'economic': 0.4
            }
        else:
            self.metric_weights = metric_weights
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
            total = sum(self.metric_weights.values())
            self.metric_weights = {k: v/total for k, v in self.metric_weights.items()}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤
        if optimization_method == 'bayesian' and not BAYESIAN_AVAILABLE:
            print("‚ö†Ô∏è Bayesian Optimization –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º Genetic Algorithm")
            self.method = 'genetic'
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º—É–ª—å—Ç–∏-–æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ NSGA-II
        if optimization_method and optimization_method.lower() in ['nsga2', 'genetic_multi']:
            if not GA_AVAILABLE:
                print("‚ö†Ô∏è DEAP –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º Random Search")
                self.method = 'random'
            else:
                self.method = 'nsga2'
        
        if optimization_method == 'genetic' and not GA_AVAILABLE:
            print("‚ö†Ô∏è Genetic Algorithm –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º Random Search")
            self.method = 'random'
    
    def classify_zones(self, lookback_period, trend_threshold, 
                      volatility_period, volatility_threshold):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–æ–Ω —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
        df = self.data.copy()
        # Ensure DateTimeIndex named 'timestamps'
        if 'timestamps' in df.columns and not isinstance(df.index, pd.DatetimeIndex):
            df['timestamps'] = pd.to_datetime(df['timestamps'])
            df = df.set_index('timestamps')
        if not isinstance(df.index, pd.DatetimeIndex):
            # try to coerce existing index to datetime
            try:
                df.index = pd.to_datetime(df.index)
            except Exception:
                pass
        df.index.name = 'timestamps'
        df.sort_index(inplace=True)
        
        # Price extremes (–±–µ–∑ look ahead)
        df['highest_high'] = df['high'].shift(1).rolling(window=lookback_period-1).max()
        df['lowest_low'] = df['low'].shift(1).rolling(window=lookback_period-1).min()
        df['price_range'] = df['highest_high'] - df['lowest_low']
        
        # Moving averages
        df['fast_ma'] = df['close'].shift(1).rolling(window=10).mean()
        df['slow_ma'] = df['close'].shift(1).rolling(window=20).mean()
        df['ma_slope'] = df['fast_ma'] - df['slow_ma']
        
        # Volatility (vectorized True Range without look-ahead)
        prev_close = df['close'].shift(1)
        tr1 = (df['high'] - df['low']).abs()
        tr2 = (df['high'] - prev_close).abs()
        tr3 = (df['low'] - prev_close).abs()
        df['atr'] = np.maximum(tr1, np.maximum(tr2, tr3))
        df['atr'] = df['atr'].rolling(window=volatility_period).mean()
        df['atr_ma'] = df['atr'].rolling(window=volatility_period).mean()
        df['volatility_ratio'] = df['atr'] / df['atr_ma']
        
        # Bollinger Bands
        df['bb_basis'] = df['close'].rolling(window=volatility_period).mean()
        df['bb_dev'] = df['close'].rolling(window=volatility_period).std()
        df['bb_width'] = (df['bb_basis'] + 2 * df['bb_dev'] - (df['bb_basis'] - 2 * df['bb_dev'])) / df['bb_basis']
        
        # Trend classification
        df['trend_up'] = (df['ma_slope'] > trend_threshold) & (df['close'].shift(1) > df['fast_ma'])
        df['trend_down'] = (df['ma_slope'] < -trend_threshold) & (df['close'].shift(1) < df['fast_ma'])
        
        # Volatility classification
        df['high_volatility'] = (df['volatility_ratio'] > volatility_threshold) | (df['bb_width'] > 0.1)
        df['low_volatility'] = (df['volatility_ratio'] < (1 / volatility_threshold)) & (df['bb_width'] < 0.05)
        
        # Zone determination
        df['primary_zone'] = np.where(df['trend_up'], 1,
                                    np.where(df['trend_down'], -1, 0))
        df['secondary_zone'] = np.where(df['high_volatility'], 2,
                                       np.where(df['low_volatility'], -2, 0))
        df['zone'] = df['primary_zone'] + df['secondary_zone']
        
        return df['zone'].dropna()
    
    def calculate_zone_stability(self, zones):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –∑–æ–Ω"""
        if len(zones) < 2:
            return 0.0
        
        changes = (zones != zones.shift(1)).sum()
        total = len(zones) - 1
        stability = 1 - (changes / total) if total > 0 else 0
        return max(0, min(1, stability))
    
    def calculate_zone_separation(self, zones, returns):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∑–æ–Ω –ø–æ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏"""
        if len(zones) == 0 or len(returns) == 0:
            return 0.0
        
        try:
            by_zone = returns.groupby(zones).mean()
            if len(by_zone) < 2:
                return 0.0
            
            separation = by_zone.max() - by_zone.min()
            return abs(separation) if not pd.isna(separation) else 0.0
        except:
            return 0.0
    
    def calculate_economic_value(self, zones, returns):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∑–æ–Ω"""
        if len(zones) == 0 or len(returns) == 0:
            return 0.0
        
        try:
            by_zone = returns.groupby(zones).mean()
            
            # –°—Ä–µ–¥–Ω–∏–µ –¥–æ—Ö–æ–¥—ã –¥–ª—è –±—ã—á—å–∏—Ö –∏ –º–µ–¥–≤–µ–∂—å–∏—Ö –∑–æ–Ω
            bull_zones = [1, 2, 3]
            bear_zones = [-1, -2, -3]
            
            bull_returns = by_zone[by_zone.index.isin(bull_zones)].mean()
            bear_returns = by_zone[by_zone.index.isin(bear_zones)].mean()
            
            if pd.isna(bull_returns):
                bull_returns = 0
            if pd.isna(bear_returns):
                bear_returns = 0
            
            economic_value = abs(bull_returns - bear_returns)
            return economic_value if not pd.isna(economic_value) else 0.0
        except:
            return 0.0
    
    def calculate_combined_score(self, zones, returns):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ—Å–∞ –∏–∑ self.metric_weights:
        - stability: —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∑–æ–Ω
        - separation: —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∑–æ–Ω
        - economic: —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å
        """
        stability = self.calculate_zone_stability(zones) * self.metric_weights.get('stability', 0.3)
        separation = self.calculate_zone_separation(zones, returns) * self.metric_weights.get('separation', 0.3)
        economic = self.calculate_economic_value(zones, returns) * self.metric_weights.get('economic', 0.4)
        
        return stability + separation + economic
    
    def get_metric_breakdown(self, zones, returns):
        """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é —Ä–∞–∑–±–∏–≤–∫—É –º–µ—Ç—Ä–∏–∫"""
        stability = self.calculate_zone_stability(zones)
        separation = self.calculate_zone_separation(zones, returns)
        economic = self.calculate_economic_value(zones, returns)
        
        return {
            'stability': stability,
            'separation': separation,
            'economic': economic,
            'stability_weighted': stability * self.metric_weights.get('stability', 0.3),
            'separation_weighted': separation * self.metric_weights.get('separation', 0.3),
            'economic_weighted': economic * self.metric_weights.get('economic', 0.4),
            'total_score': self.calculate_combined_score(zones, returns)
        }
    
    def objective_function(self, params):
        """–¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        lookback, trend_thresh, vol_period, vol_thresh = params
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∑–æ–Ω—ã
        try:
            zones = self.classify_zones(
                int(lookback), 
                float(trend_thresh),
                int(vol_period),
                float(vol_thresh)
            )
            
            # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
            returns = self.data['close'].pct_change().dropna()
            
            # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
            common_idx = zones.index.intersection(returns.index)
            if len(common_idx) < 100:  # –ú–∏–Ω–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö
                return -1000  # –û—á–µ–Ω—å –ø–ª–æ—Ö–∞—è –æ—Ü–µ–Ω–∫–∞
            
            zones_aligned = zones.loc[common_idx]
            returns_aligned = returns.loc[common_idx]
            
            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            score = self.calculate_combined_score(zones_aligned, returns_aligned)
            
            # –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π score
            return -score
            
        except Exception as e:
            return -1000  # –û—à–∏–±–∫–∞ - –æ—á–µ–Ω—å –ø–ª–æ—Ö–∞—è –æ—Ü–µ–Ω–∫–∞

    def multi_objective(self, params):
        """–ú—É–ª—å—Ç–∏-–æ–±—ä–µ–∫—Ç–∏–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: (stability, separation, economic) —Å —à—Ç—Ä–∞—Ñ–∞–º–∏."""
        lookback, trend_thresh, vol_period, vol_thresh = params
        try:
            zones = self.classify_zones(int(lookback), float(trend_thresh), int(vol_period), float(vol_thresh))
            returns = self.data['close'].pct_change().dropna()
            common_idx = zones.index.intersection(returns.index)
            if len(common_idx) < 100:
                return (0.0, 0.0, 0.0)
            z = zones.loc[common_idx]
            r = returns.loc[common_idx]

            stability = self.calculate_zone_stability(z)
            separation = self.calculate_zone_separation(z, r)
            economic = self.calculate_economic_value(z, r)

            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–æ–Ω
            dist = z.value_counts(normalize=True)
            pct_high_vol = float(dist.get(2, 0) + dist.get(-2, 0) + dist.get(3, 0) + dist.get(-3, 0))
            pct_trend = float(dist.get(1, 0) + dist.get(-1, 0) + dist.get(2, 0) + dist.get(-2, 0) + dist.get(3, 0) + dist.get(-3, 0))

            # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –∑–æ–Ω
            durations = []
            prev = None
            cur_len = 0
            for val in z:
                if val == prev:
                    cur_len += 1
                else:
                    if prev is not None:
                        durations.append(cur_len)
                    prev = val
                    cur_len = 1
            if cur_len > 0:
                durations.append(cur_len)
            avg_zone_len = np.mean(durations) if durations else 0.0

            # –®—Ç—Ä–∞—Ñ—ã –∑–∞ –≤—ã—Ä–æ–∂–¥–µ–Ω–Ω–æ—Å—Ç—å
            penalty = 0.0
            if pct_high_vol < 0.05:
                penalty += (0.05 - pct_high_vol) * 1.0
            if pct_trend < 0.30:
                penalty += (0.30 - pct_trend) * 1.0
            if avg_zone_len < 8:
                penalty += (8 - avg_zone_len) * 0.02

            return (max(0.0, stability - penalty),
                    max(0.0, separation - penalty),
                    max(0.0, economic - penalty))
        except Exception:
            return (0.0, 0.0, 0.0)
    
    def optimize_bayesian(self, n_calls=100, n_initial_points=20):
        """Bayesian Optimization"""
        if not BAYESIAN_AVAILABLE:
            raise ImportError("scikit-optimize –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        dimensions = [
            Integer(5, 100, name='lookbackPeriod'),
            Real(0.1, 2.0, name='trendThreshold'),
            Integer(5, 50, name='volatilityPeriod'),
            Real(0.5, 3.0, name='volatilityThreshold')
        ]
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        result = gp_minimize(
            func=self.objective_function,
            dimensions=dimensions,
            n_calls=n_calls,
            acq_func='EI',
            n_initial_points=n_initial_points,
            random_state=42,
            verbose=True
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π (–∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã)
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
            if hasattr(result, 'x_iters') and len(result.x_iters) > 0:
                iterations = len(result.x_iters)
            elif hasattr(result, 'func_vals') and len(result.func_vals) > 0:
                iterations = len(result.func_vals)
            else:
                iterations = n_calls  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        except:
            iterations = n_calls
        
        best_params = {
            'lookbackPeriod': int(result.x[0]),
            'trendThreshold': float(result.x[1]),
            'volatilityPeriod': int(result.x[2]),
            'volatilityThreshold': float(result.x[3]),
            'score': -result.fun,
            'iterations': iterations,
            'method': 'Bayesian Optimization'
        }
        
        return best_params
    
    def optimize_genetic(self, population_size=30, generations=50):
        """Genetic Algorithm Optimization"""
        if not GA_AVAILABLE:
            raise ImportError("DEAP –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DEAP
        creator.create("FitnessMax", base.Fitness, weights=(1.0,))
        creator.create("Individual", list, fitness=creator.FitnessMax)
        
        toolbox = base.Toolbox()
        
        # –ì–µ–Ω—ã (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
        toolbox.register("attr_lookback", np.random.randint, 5, 101)
        toolbox.register("attr_trend", lambda: np.round(np.random.uniform(0.1, 2.0), 1))
        toolbox.register("attr_vol_period", np.random.randint, 5, 51)
        toolbox.register("attr_vol_thresh", lambda: np.round(np.random.uniform(0.5, 3.0), 1))
        
        toolbox.register("individual", tools.initCycle, creator.Individual,
                        (toolbox.attr_lookback, toolbox.attr_trend,
                         toolbox.attr_vol_period, toolbox.attr_vol_thresh), n=1)
        
        toolbox.register("population", tools.initRepeat, list, toolbox.individual)
        toolbox.register("evaluate", lambda ind: (self.objective_function(ind),))
        toolbox.register("mate", tools.cxTwoPoint)
        toolbox.register("mutate", self.mutate_individual, indpb=0.2)
        toolbox.register("select", tools.selTournament, tournsize=3)
        
        # –ú—É—Ç–∞—Ü–∏—è
        def mutate_individual(individual):
            if np.random.random() < 0.25:
                individual[0] = np.random.randint(5, 101)  # lookback
            if np.random.random() < 0.25:
                individual[1] = np.round(np.random.uniform(0.1, 2.0), 1)  # trend
            if np.random.random() < 0.25:
                individual[2] = np.random.randint(5, 51)  # vol_period
            if np.random.random() < 0.25:
                individual[3] = np.round(np.random.uniform(0.5, 3.0), 1)  # vol_thresh
            return individual
        
        toolbox.register("mutate", mutate_individual)
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–ø—É–ª—è—Ü–∏—é
        population = toolbox.population(n=population_size)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –ø–æ–ø—É–ª—è—Ü–∏—é
        fitnesses = list(map(toolbox.evaluate, population))
        for ind, fit in zip(population, fitnesses):
            ind.fitness.values = fit
        
        # –≠–≤–æ–ª—é—Ü–∏—è
        best_individual = None
        best_fitness = float('-inf')
        
        for gen in range(generations):
            # –û—Ç–±–æ—Ä
            offspring = toolbox.select(population, len(population))
            offspring = list(map(toolbox.clone, offspring))
            
            # –ö—Ä–æ—Å—Å–æ–≤–µ—Ä
            for child1, child2 in zip(offspring[::2], offspring[1::2]):
                if np.random.random() < 0.8:
                    toolbox.mate(child1, child2)
                    del child1.fitness.values
                    del child2.fitness.values
            
            # –ú—É—Ç–∞—Ü–∏—è
            for mutant in offspring:
                if np.random.random() < 0.2:
                    toolbox.mutate(mutant)
                    del mutant.fitness.values
            
            # –û—Ü–µ–Ω–∫–∞ –Ω–æ–≤—ã—Ö –æ—Å–æ–±–µ–π
            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
            fitnesses = map(toolbox.evaluate, invalid_ind)
            for ind, fit in zip(invalid_ind, fitnesses):
                ind.fitness.values = fit
            
            # –ó–∞–º–µ–Ω—è–µ–º –ø–æ–ø—É–ª—è—Ü–∏—é
            population[:] = offspring
            
            # –¢—Ä–µ–∫ –ª—É—á—à–µ–π –æ—Å–æ–±–∏
            best_gen = tools.selBest(population, 1)[0]
            if best_gen.fitness.values[0] > best_fitness:
                best_fitness = best_gen.fitness.values[0]
                best_individual = best_gen
            
            if (gen + 1) % 10 == 0:
                print(f"–ü–æ–∫–æ–ª–µ–Ω–∏–µ {gen + 1}/{generations}: –õ—É—á—à–∏–π score = {-best_fitness:.6f}")
        
        best_params = {
            'lookbackPeriod': int(best_individual[0]),
            'trendThreshold': float(best_individual[1]),
            'volatilityPeriod': int(best_individual[2]),
            'volatilityThreshold': float(best_individual[3]),
            'score': -best_fitness,
            'iterations': generations * population_size,
            'method': 'Genetic Algorithm'
        }
        
        return best_params
    
    def optimize_random(self, n_trials=500):
        """Random Search Optimization"""
        best_score = float('-inf')
        best_params = None
        
        for i in range(n_trials):
            params = [
                np.random.randint(5, 101),  # lookback
                np.round(np.random.uniform(0.1, 2.0), 1),  # trend_thresh
                np.random.randint(5, 51),  # vol_period
                np.round(np.random.uniform(0.5, 3.0), 1)  # vol_thresh
            ]
            
            score = -self.objective_function(params)
            
            if score > best_score:
                best_score = score
                best_params = params
                print(f"–ü–æ–ø—ã—Ç–∫–∞ {i+1}/{n_trials}: –ù–æ–≤—ã–π –ª—É—á—à–∏–π score = {score:.6f}")
        
        return {
            'lookbackPeriod': int(best_params[0]),
            'trendThreshold': float(best_params[1]),
            'volatilityPeriod': int(best_params[2]),
            'volatilityThreshold': float(best_params[3]),
            'score': best_score,
            'iterations': n_trials,
            'method': 'Random Search'
        }
    
    def optimize(self, **kwargs):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        print(f"üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–µ—Ç–æ–¥–æ–º: {self.method}")
        print("=" * 50)
        
        if self.method == 'bayesian':
            return self.optimize_bayesian(
                n_calls=kwargs.get('n_calls', 100),
                n_initial_points=kwargs.get('n_initial_points', 20)
            )
        elif self.method == 'genetic':
            return self.optimize_genetic(
                population_size=kwargs.get('population_size', 30),
                generations=kwargs.get('generations', 50)
            )
        elif self.method == 'nsga2':
            return self.optimize_nsga2(
                population_size=kwargs.get('population_size', 50),
                generations=kwargs.get('generations', 60)
            )
        else:  # random
            return self.optimize_random(
                n_trials=kwargs.get('n_trials', 500)
            )

    def optimize_nsga2(self, population_size=50, generations=60):
        """NSGA-II –º—É–ª—å—Ç–∏-–æ–±—ä–µ–∫—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (stability, separation, economic)."""
        if not GA_AVAILABLE:
            raise ImportError("DEAP –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è NSGA-II")

        # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–∞–¥–µ–∫–≤–∞—Ç–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–ª—è 1h)
        lookback_min, lookback_max = 15, 50
        trend_min, trend_max = 0.3, 0.9
        volp_min, volp_max = 10, 26
        volt_min, volt_max = 1.2, 2.0

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã —Ñ–∏—Ç–Ω–µ—Å–∞ –∏ –∏–Ω–¥–∏–≤–∏–¥—É—É–º–æ–≤
        if not hasattr(creator, 'FitnessMulti'):
            creator.create("FitnessMulti", base.Fitness, weights=(1.0, 1.0, 1.0))
        if not hasattr(creator, 'IndividualMulti'):
            creator.create("IndividualMulti", list, fitness=creator.FitnessMulti)

        toolbox = base.Toolbox()
        toolbox.register("attr_lookback", np.random.randint, lookback_min, lookback_max + 1)
        toolbox.register("attr_trend", np.random.uniform, trend_min, trend_max)
        toolbox.register("attr_volp", np.random.randint, volp_min, volp_max + 1)
        toolbox.register("attr_volt", np.random.uniform, volt_min, volt_max)
        toolbox.register("individual", tools.initCycle, creator.IndividualMulti,
                         (toolbox.attr_lookback, toolbox.attr_trend, toolbox.attr_volp, toolbox.attr_volt), n=1)
        toolbox.register("population", tools.initRepeat, list, toolbox.individual)

        toolbox.register("evaluate", lambda ind: self.multi_objective(ind))
        
        # –ö–∞—Å—Ç–æ–º–Ω—ã–π –∫—Ä–æ—Å—Å–æ–≤–µ—Ä: —Ü–µ–ª—ã–µ –∏ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–¥–µ–ª—å–Ω–æ
        def mate_custom(ind1, ind2):
            # lookback (int) - –ø—Ä–æ—Å—Ç–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –∏ –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ
            if np.random.rand() < 0.5:
                ind1[0], ind2[0] = int((ind1[0] + ind2[0]) / 2), int((ind1[0] + ind2[0]) / 2)
            # trend (float) - blend
            if np.random.rand() < 0.5:
                alpha = 0.5
                temp = ind1[1]
                ind1[1] = alpha * ind1[1] + (1 - alpha) * ind2[1]
                ind2[1] = (1 - alpha) * temp + alpha * ind2[1]
                ind1[1] = np.clip(ind1[1], trend_min, trend_max)
                ind2[1] = np.clip(ind2[1], trend_min, trend_max)
            # vol_period (int)
            if np.random.rand() < 0.5:
                ind1[2], ind2[2] = int((ind1[2] + ind2[2]) / 2), int((ind1[2] + ind2[2]) / 2)
            # vol_threshold (float) - blend
            if np.random.rand() < 0.5:
                alpha = 0.5
                temp = ind1[3]
                ind1[3] = alpha * ind1[3] + (1 - alpha) * ind2[3]
                ind2[3] = (1 - alpha) * temp + alpha * ind2[3]
                ind1[3] = np.clip(ind1[3], volt_min, volt_max)
                ind2[3] = np.clip(ind2[3], volt_min, volt_max)
            return ind1, ind2
        
        toolbox.register("mate", mate_custom)
        
        # –ö–∞—Å—Ç–æ–º–Ω–∞—è –º—É—Ç–∞—Ü–∏—è: —Ü–µ–ª—ã–µ –∏ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–¥–µ–ª—å–Ω–æ
        def mutate_custom(individual):
            # lookback (int)
            if np.random.rand() < 0.25:
                individual[0] = np.random.randint(lookback_min, lookback_max + 1)
            # trend (float)
            if np.random.rand() < 0.25:
                individual[1] = np.clip(individual[1] + np.random.normal(0, 0.1), trend_min, trend_max)
            # vol_period (int)
            if np.random.rand() < 0.25:
                individual[2] = np.random.randint(volp_min, volp_max + 1)
            # vol_threshold (float)
            if np.random.rand() < 0.25:
                individual[3] = np.clip(individual[3] + np.random.normal(0, 0.1), volt_min, volt_max)
            return individual,
        
        toolbox.register("mutate", mutate_custom)
        toolbox.register("select", tools.selNSGA2)

        pop = toolbox.population(n=population_size)
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∏—Ç–Ω–µ—Å –∏ —Ñ—Ä–æ–Ω—Ç
        invalid_ind = [ind for ind in pop if not ind.fitness.valid]
        fitnesses = list(map(toolbox.evaluate, invalid_ind))
        for ind, fit in zip(invalid_ind, fitnesses):
            ind.fitness.values = fit
        pop = tools.selNSGA2(pop, k=len(pop))

        for gen in range(generations):
            offspring = tools.selTournamentDCD(pop, len(pop))
            offspring = [toolbox.clone(ind) for ind in offspring]

            for ind1, ind2 in zip(offspring[::2], offspring[1::2]):
                if np.random.rand() < 0.9:
                    toolbox.mate(ind1, ind2)
                    del ind1.fitness.values
                    del ind2.fitness.values
            for ind in offspring:
                if np.random.rand() < 0.3:
                    toolbox.mutate(ind)
                    del ind.fitness.values

            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
            fitnesses = list(map(toolbox.evaluate, invalid_ind))
            for ind, fit in zip(invalid_ind, fitnesses):
                ind.fitness.values = fit

            pop = tools.selNSGA2(pop + offspring, k=population_size)

        # Pareto-—Ñ—Ä–æ–Ω—Ç
        pareto = tools.sortNondominated(pop, k=len(pop), first_front_only=True)[0]
        results = []
        for ind in pareto:
            lookback, trend, volp, volt = ind
            results.append({
                'lookbackPeriod': int(lookback),
                'trendThreshold': float(trend),
                'volatilityPeriod': int(volp),
                'volatilityThreshold': float(volt),
                'stability': ind.fitness.values[0],
                'separation': ind.fitness.values[1],
                'economic': ind.fitness.values[2]
            })

        best = max(results, key=lambda x: x['stability'] + x['separation'] + x['economic']) if results else None
        return {
            'method': 'NSGA-II',
            'population_size': population_size,
            'generations': generations,
            'pareto': results,
            'best': best
        }


def load_btc_data(base_path=None):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö BTC –∏–∑ CSV —Ñ–∞–π–ª–æ–≤
    
    Args:
        base_path: –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                   –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º
    """
    import sys
    import os
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å
    if base_path is None:
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
        current_file = os.path.abspath(__file__)
        if 'market_zone_classifier' in current_file:
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ (–Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ market_zone_classifier)
            base_path = os.path.dirname(os.path.dirname(current_file))
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            base_path = os.getcwd()
    
    print(f"üìÅ –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å: {base_path}")
    
    # –°–ø–∏—Å–æ–∫ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
    timeframes = ['15m', '30m', '1h', '4h', '1d']
    
    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
    file_priorities = [
        'df_btc_{tf}_complete.csv',
        'df_btc_{tf}_matching.csv',
        'df_btc_{tf}_large.csv',
        'df_btc_{tf}_real.csv',
        'df_btc_{tf}.csv'
    ]
    
    dataframes = {}
    
    print("\nüìä –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• BTC –ò–ó –§–ê–ô–õ–û–í")
    print("=" * 40)
    
    for tf in timeframes:
        df = None
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤
        for file_template in file_priorities:
            filename = file_template.format(tf=tf)
            filepath = os.path.join(base_path, filename)
            
            if os.path.exists(filepath):
                try:
                    df = pd.read_csv(filepath)
                    print(f"‚úÖ {tf}: –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ {filename} ({len(df)} –∑–∞–ø–∏—Å–µ–π)")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                    required_columns = ['timestamps', 'open', 'high', 'low', 'close']
                    missing_columns = [col for col in required_columns if col not in df.columns]
                    
                    if missing_columns:
                        print(f"‚ö†Ô∏è {tf}: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
                        df = None
                        continue
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º timestamps
                    if 'timestamps' in df.columns:
                        df['timestamps'] = pd.to_datetime(df['timestamps'])
                        df.set_index('timestamps', inplace=True)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º volume –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                    if 'volume' not in df.columns:
                        print(f"‚ö†Ô∏è {tf}: Volume –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π")
                        price_range = df['high'] - df['low']
                        avg_price = df['close'].mean()
                        np.random.seed(42)
                        random_factor = np.random.uniform(0.5, 2.0, len(df))
                        df['volume'] = (price_range * avg_price * random_factor).astype(int)
                    
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–Ω–¥–µ–∫—Å—É
                    df.sort_index(inplace=True)
                    
                    dataframes[tf] = df
                    break
                    
                except Exception as e:
                    print(f"‚ùå {tf}: –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filename} - {e}")
                    continue
        
        if df is None:
            print(f"‚ùå {tf}: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
    
    if not dataframes:
        print("\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤!")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:")
        print(f"   {base_path}")
        print("\nüìã –û–∂–∏–¥–∞–µ–º—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤:")
        for tf in timeframes:
            print(f"   - df_btc_{tf}.csv (–∏–ª–∏ –¥—Ä—É–≥–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã)")
        print("\nüí° –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏...")
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        dates = pd.date_range(start='2023-01-01', end='2024-12-31', freq='1H')
        np.random.seed(42)
        
        data = []
        price = 30000
        
        for date in dates:
            price += np.random.normal(0, 100)
            data.append({
                'open': price + np.random.normal(0, 50),
                'high': price + abs(np.random.normal(0, 100)),
                'low': price - abs(np.random.normal(0, 100)),
                'close': price,
                'volume': np.random.uniform(1000, 10000)
            })
        
        df = pd.DataFrame(data, index=dates)
        dataframes['1h'] = df
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df)} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ 1h")
    
    return dataframes


if __name__ == "__main__":
    print("üîß Market Zone Classifier - Parameter Optimizer")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    btc_data = load_btc_data()
    
    # –í—ã–±–∏—Ä–∞–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1h)
    if '1h' in btc_data:
        df = btc_data['1h']
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ 1h")
    else:
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
        tf = list(btc_data.keys())[0]
        df = btc_data[tf]
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {tf}")
    
    # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    print("\nüéØ –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤
    if BAYESIAN_AVAILABLE:
        print("‚úÖ Bayesian Optimization –¥–æ—Å—Ç—É–ø–µ–Ω - –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø")
        method = 'bayesian'
    elif GA_AVAILABLE:
        print("‚úÖ Genetic Algorithm –¥–æ—Å—Ç—É–ø–µ–Ω")
        method = 'genetic'
    else:
        print("‚ö†Ô∏è –¢–æ–ª—å–∫–æ Random Search –¥–æ—Å—Ç—É–ø–µ–Ω")
        method = 'random'
    
    optimizer = ZoneClassifierOptimizer(df, optimization_method=method)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ ({method})...")
    results = optimizer.optimize()
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 50)
    print("üèÜ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò")
    print("=" * 50)
    print(f"–ú–µ—Ç–æ–¥: {results['method']}")
    print(f"–ò—Ç–µ—Ä–∞—Ü–∏–π: {results['iterations']}")
    print(f"–õ—É—á—à–∏–π Score: {results['score']:.6f}")
    print(f"\nüìä –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´:")
    print(f"   Lookback Period: {results['lookbackPeriod']}")
    print(f"   Trend Threshold: {results['trendThreshold']}")
    print(f"   Volatility Period: {results['volatilityPeriod']}")
    print(f"   Volatility Threshold: {results['volatilityThreshold']}")
    print("\n‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
