"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ CSV –¥–∞–Ω–Ω—ã—Ö –≤ InfluxDB –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ Grafana
"""

import sys
from pathlib import Path
import pandas as pd
from datetime import datetime
import argparse

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from binance_data_collector.utils.influxdb_client import InfluxDBWriter
from binance_data_collector.utils.logger import setup_logger

logger = setup_logger("load_csv_to_influxdb")

def load_csv_to_influxdb(
    csv_file: str,
    symbol: str = "BTCUSDT",
    timeframe: str = "15m",
    influxdb_url: str = "http://localhost:8086",
    influxdb_token: str = "my-super-secret-admin-token",
    org: str = "crypto",
    bucket: str = "binance_data"
):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞ –≤ InfluxDB
    
    Args:
        csv_file: –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É
        symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
        timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–∞–Ω–Ω—ã—Ö
        influxdb_url: URL InfluxDB —Å–µ—Ä–≤–µ—Ä–∞
        influxdb_token: –¢–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞
        org: –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è
        bucket: –ë–∞–∫–µ—Ç (–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö)
    """
    logger.info("="*70)
    logger.info("üìä –ó–ê–ì–†–£–ó–ö–ê CSV –î–ê–ù–ù–´–• –í INFLUXDB")
    logger.info("="*70)
    logger.info(f"üìÅ –§–∞–π–ª: {csv_file}")
    logger.info(f"üìä –°–∏–º–≤–æ–ª: {symbol}")
    logger.info(f"‚è±Ô∏è  –¢–∞–π–º—Ñ—Ä–µ–π–º: {timeframe}")
    logger.info(f"üîó InfluxDB: {influxdb_url}")
    logger.info("="*70)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
    csv_path = Path(csv_file)
    if not csv_path.exists():
        logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_file}")
        return False
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ CSV
    logger.info(f"\nüìñ –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞...")
    try:
        df = pd.read_csv(csv_path)
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
        logger.info(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    required_columns = ['open', 'high', 'low', 'close', 'volume']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
        return False
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–∏
    logger.info(f"\nüïê –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫...")
    if 'timestamps' in df.columns:
        df['timestamps'] = pd.to_datetime(df['timestamps'])
        df.set_index('timestamps', inplace=True)
        logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'timestamps'")
    elif 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'timestamp'")
    else:
        logger.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π, —Å–æ–∑–¥–∞—é –∏–Ω–¥–µ–∫—Å...")
        df.index = pd.date_range(start='2020-01-01', periods=len(df), freq='15min')
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    df.sort_index(inplace=True)
    
    logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {df.index[0]} - {df.index[-1]}")
    logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
    duplicates = df.index.duplicated().sum()
    if duplicates > 0:
        logger.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, —É–¥–∞–ª—è—é...")
        df = df[~df.index.duplicated(keep='first')]
        logger.info(f"‚úÖ –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(df)} –∑–∞–ø–∏—Å–µ–π")
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ InfluxDB
    logger.info(f"\nüîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ InfluxDB...")
    writer = InfluxDBWriter(
        url=influxdb_url,
        token=influxdb_token,
        org=org,
        bucket=bucket
    )
    
    if writer.client is None:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ InfluxDB!")
        logger.error("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:")
        logger.error("   1. InfluxDB –∑–∞–ø—É—â–µ–Ω (docker-compose up -d)")
        logger.error("   2. –£–∫–∞–∑–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω")
        logger.error("   3. –£–∫–∞–∑–∞–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ org –∏ bucket")
        return False
    
    # –ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö
    logger.info(f"\nüíæ –ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –≤ InfluxDB...")
    try:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ —á–∞—Å—Ç—è–º
        chunk_size = 10000
        total_chunks = (len(df) + chunk_size - 1) // chunk_size
        
        for i in range(0, len(df), chunk_size):
            chunk = df.iloc[i:i+chunk_size]
            chunk_num = (i // chunk_size) + 1
            
            logger.info(f"   üì¶ –ó–∞–ø–∏—Å—ã–≤–∞—é —á–∞–Ω–∫ {chunk_num}/{total_chunks} ({len(chunk)} –∑–∞–ø–∏—Å–µ–π)...")
            
            writer.write_ohlcv(chunk, symbol=symbol, timeframe=timeframe)
            
            logger.info(f"   ‚úÖ –ß–∞–Ω–∫ {chunk_num} –∑–∞–ø–∏—Å–∞–Ω")
        
        logger.info(f"\n‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ InfluxDB!")
        logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–∞–Ω–æ: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {df.index[0]} - {df.index[-1]}")
        logger.info(f"\nüé® –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å Grafana: http://localhost:3000")
        logger.info(f"   –ò –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ InfluxDB: {e}")
        return False
    finally:
        writer.close()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ó–∞–≥—Ä—É–∑–∫–∞ CSV –¥–∞–Ω–Ω—ã—Ö –≤ InfluxDB')
    parser.add_argument('--csv-file', type=str, required=True, help='–ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É')
    parser.add_argument('--symbol', type=str, default='BTCUSDT', help='–¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: BTCUSDT)')
    parser.add_argument('--timeframe', type=str, default='15m', help='–¢–∞–π–º—Ñ—Ä–µ–π–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 15m)')
    parser.add_argument('--influxdb-url', type=str, default='http://localhost:8086', help='URL InfluxDB')
    parser.add_argument('--influxdb-token', type=str, default='my-super-secret-admin-token', help='–¢–æ–∫–µ–Ω InfluxDB')
    parser.add_argument('--org', type=str, default='crypto', help='–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è')
    parser.add_argument('--bucket', type=str, default='binance_data', help='–ë–∞–∫–µ—Ç')
    
    args = parser.parse_args()
    
    success = load_csv_to_influxdb(
        csv_file=args.csv_file,
        symbol=args.symbol,
        timeframe=args.timeframe,
        influxdb_url=args.influxdb_url,
        influxdb_token=args.influxdb_token,
        org=args.org,
        bucket=args.bucket
    )
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()

