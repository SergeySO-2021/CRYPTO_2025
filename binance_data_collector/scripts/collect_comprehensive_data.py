"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–±–æ—Ä –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å Binance
–°–æ–±–∏—Ä–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤ –æ–¥–∏–Ω DataFrame
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import requests
import gc
from typing import Dict, List, Optional, Tuple

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(str(Path(__file__).parent.parent.parent))

from binance_data_collector.config import config
from binance_data_collector.utils.logger import setup_logger
from binance_data_collector.utils.file_handler import save_data

# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Binance
try:
    from binance.client import Client
except ImportError:
    print("‚ùå –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ python-binance!")
    print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-binance")
    sys.exit(1)

try:
    from tqdm import tqdm
except ImportError:
    print("‚ö†Ô∏è  tqdm –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –Ω–µ –±—É–¥–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è")
    print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install tqdm")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
    def tqdm(iterable, *args, **kwargs):
        return iterable

logger = setup_logger("comprehensive_collector")

def get_memory_usage_mb() -> float:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –≤ MB"""
    try:
        import psutil
        import os
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024
    except ImportError:
        # –ï—Å–ª–∏ psutil –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
        return 0
    except Exception:
        return 0

def optimize_dataframe_memory(df: pd.DataFrame) -> pd.DataFrame:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ DataFrame"""
    start_memory = df.memory_usage(deep=True).sum() / 1024**2
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    for col in df.select_dtypes(include=['int64']).columns:
        df[col] = pd.to_numeric(df[col], downcast='integer')
    
    for col in df.select_dtypes(include=['float64']).columns:
        df[col] = pd.to_numeric(df[col], downcast='float')
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    for col in df.select_dtypes(include=['object']).columns:
        if df[col].dtype == 'object':
            try:
                df[col] = df[col].astype('category')
            except:
                pass
    
    end_memory = df.memory_usage(deep=True).sum() / 1024**2
    if end_memory < start_memory:
        logger.info(f"   üíæ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏: {start_memory:.2f} MB ‚Üí {end_memory:.2f} MB (—ç–∫–æ–Ω–æ–º–∏—è {start_memory - end_memory:.2f} MB)")
    
    return df


class ComprehensiveBinanceCollector:
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–±–æ—Ä –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å Binance"""
    
    def __init__(self, symbol: str = "BTCUSDT"):
        """
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, BTCUSDT)
        """
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
        if config.BINANCE_API_KEY and config.BINANCE_API_SECRET:
            self.spot_client = Client(config.BINANCE_API_KEY, config.BINANCE_API_SECRET)
            self.futures_client = Client(
                config.BINANCE_API_KEY, 
                config.BINANCE_API_SECRET, 
                testnet=False
            )
        else:
            self.spot_client = Client()
            # –î–ª—è —Ñ—å—é—á–µ—Ä—Å–æ–≤ –Ω—É–∂–µ–Ω –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
            try:
                self.futures_client = Client()
            except:
                self.futures_client = None
                logger.warning("‚ö†Ô∏è  –§—å—é—á–µ—Ä—Å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)")
        
        self.symbol = symbol
        self.symbol_futures = symbol  # –î–ª—è —Ñ—å—é—á–µ—Ä—Å–æ–≤
        
        # –ì–ª—É–±–∏–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ order book (–≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)
        self.orderbook_depths = [0.03, 0.08, 0.15, 0.60]  # 3%, 8%, 15%, 60%
        
    def get_klines_batch(
        self,
        interval: str,
        start_time: datetime,
        end_time: datetime,
        limit: int = 1000
    ) -> pd.DataFrame:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö OHLCV –¥–∞–Ω–Ω—ã—Ö —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π
        
        Args:
            interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª (1m, 5m, 15m, 1h, 1d –∏ —Ç.–¥.)
            start_time: –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
            end_time: –ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π –∑–∞ –∑–∞–ø—Ä–æ—Å
        
        Returns:
            DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏
        """
        all_klines = []
        current_start = start_time
        
        logger.info(f"üìä –°–±–æ—Ä OHLCV –¥–ª—è {self.symbol} ({interval}) —Å {start_time.date()} –ø–æ {end_time.date()}")
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
        total_days = (end_time - start_time).days
        if interval.endswith('m'):
            minutes = int(interval[:-1])
            estimated_requests = max(1, total_days * 24 * 60 // minutes // limit)
        elif interval.endswith('h'):
            hours = int(interval[:-1])
            estimated_requests = max(1, total_days * 24 // hours // limit)
        elif interval.endswith('d'):
            days = int(interval[:-1]) if interval[:-1] != '' else 1
            estimated_requests = max(1, total_days // days // limit)
        else:
            estimated_requests = 100
        
        pbar = tqdm(total=estimated_requests, desc=f"OHLCV ({interval})", unit="batch")
        
        while current_start < end_time:
            try:
                klines = self.spot_client.get_klines(
                    symbol=self.symbol,
                    interval=interval,
                    startTime=int(current_start.timestamp() * 1000),
                    endTime=int(end_time.timestamp() * 1000),
                    limit=limit
                )
                
                if not klines:
                    break
                
                all_klines.extend(klines)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
                last_timestamp = klines[-1][0] / 1000
                current_start = datetime.fromtimestamp(last_timestamp) + timedelta(seconds=1)
                
                pbar.update(1)
                time.sleep(config.REQUEST_DELAY)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ OHLCV: {e}")
                time.sleep(config.REQUEST_DELAY * 10)
        
        pbar.close()
        
        if not all_klines:
            logger.warning("‚ö†Ô∏è OHLCV –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã")
            return pd.DataFrame()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
        logger.info(f"   üìä –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ {len(all_klines)} –∑–∞–ø–∏—Å–µ–π –≤ DataFrame...")
        memory_before = get_memory_usage_mb()
        
        df = pd.DataFrame(all_klines, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_volume', 'trades', 'taker_buy_base',
            'taker_buy_quote', 'ignore'
        ])
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–∏–ø—ã
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        
        numeric_cols = ['open', 'high', 'low', 'close', 'volume', 
                       'quote_volume', 'taker_buy_base', 'taker_buy_quote']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], downcast='float')
        
        df['trades'] = pd.to_numeric(df['trades'], downcast='integer')
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        df = df[~df.index.duplicated(keep='first')]
        df.sort_index(inplace=True)
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –ø–∞–º—è—Ç—å
        df = optimize_dataframe_memory(df)
        
        # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑ –ø–∞–º—è—Ç–∏
        del all_klines
        gc.collect()
        
        memory_after = get_memory_usage_mb()
        memory_used = memory_after - memory_before
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(df)} —Å–≤–µ—á–µ–π OHLCV")
        if memory_used > 0:
            logger.info(f"   üíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {memory_used:.2f} MB")
        
        return df
    
    def get_aggregated_trades_batch(
        self,
        start_time: datetime,
        end_time: datetime
    ) -> pd.DataFrame:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (—Ä—ã–Ω–æ—á–Ω—ã–µ –æ–±—ä–µ–º—ã –ø–æ–∫—É–ø–æ–∫/–ø—Ä–æ–¥–∞–∂)
        
        Args:
            start_time: –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
            end_time: –ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è
        
        Returns:
            DataFrame —Å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–¥–µ–ª–∫–∞–º–∏
        """
        logger.info(f"üìä –°–±–æ—Ä –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ —Å {start_time.date()} –ø–æ {end_time.date()}")
        
        all_trades = []
        from_time = start_time
        
        # –û—Ü–µ–Ω–∫–∞ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ (–¥–æ 1000 —Å–¥–µ–ª–æ–∫ –∑–∞ –∑–∞–ø—Ä–æ—Å)
        # –ü—Ä–∏–º–µ—Ä–Ω–æ 1000 —Å–¥–µ–ª–æ–∫ = 1-5 –º–∏–Ω—É—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        estimated_duration = (end_time - start_time).total_seconds() / 60  # –≤ –º–∏–Ω—É—Ç–∞—Ö
        estimated_requests = max(1, int(estimated_duration / 2))  # –ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤
        CHUNK_SIZE = 50000  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ 50k –∑–∞–ø–∏—Å–µ–π
        chunk_counter = 0
        temp_dfs = []
        
        pbar = tqdm(total=estimated_requests, desc="Aggregated Trades", unit="batch")
        
        while from_time < end_time:
            try:
                trades = self.spot_client.get_aggregate_trades(
                    symbol=self.symbol,
                    startTime=int(from_time.timestamp() * 1000),
                    endTime=int(end_time.timestamp() * 1000),
                    limit=1000
                )
                
                if not trades:
                    break
                
                all_trades.extend(trades)
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ —á–∞—Å—Ç—è–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
                if len(all_trades) >= CHUNK_SIZE:
                    chunk_counter += 1
                    memory_usage = get_memory_usage_mb()
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                    chunk_df = pd.DataFrame(all_trades)
                    chunk_df['timestamp'] = pd.to_datetime(chunk_df['T'], unit='ms')
                    chunk_df.set_index('timestamp', inplace=True)
                    
                    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                    chunk_df['price'] = pd.to_numeric(chunk_df['p'], downcast='float')
                    chunk_df['quantity'] = pd.to_numeric(chunk_df['q'], downcast='float')
                    chunk_df['buy_volume'] = chunk_df.apply(lambda x: float(x['q']) if not x['m'] else 0, axis=1)
                    chunk_df['sell_volume'] = chunk_df.apply(lambda x: float(x['q']) if x['m'] else 0, axis=1)
                    
                    temp_dfs.append(chunk_df[['buy_volume', 'sell_volume', 'price', 'quantity']])
                    
                    # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫
                    all_trades = []
                    gc.collect()
                    
                    if chunk_counter % 10 == 0:
                        logger.info(f"   üíæ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {chunk_counter} —á–∞–Ω–∫–æ–≤. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {memory_usage:.2f} MB")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
                last_trade_time = trades[-1]['T'] / 1000
                from_time = datetime.fromtimestamp(last_trade_time) + timedelta(milliseconds=1)
                
                pbar.update(1)
                time.sleep(config.REQUEST_DELAY)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫: {e}")
                time.sleep(config.REQUEST_DELAY * 10)
        
        pbar.close()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ
        if all_trades:
            chunk_df = pd.DataFrame(all_trades)
            chunk_df['timestamp'] = pd.to_datetime(chunk_df['T'], unit='ms')
            chunk_df.set_index('timestamp', inplace=True)
            chunk_df['price'] = pd.to_numeric(chunk_df['p'], downcast='float')
            chunk_df['quantity'] = pd.to_numeric(chunk_df['q'], downcast='float')
            chunk_df['buy_volume'] = chunk_df.apply(lambda x: float(x['q']) if not x['m'] else 0, axis=1)
            chunk_df['sell_volume'] = chunk_df.apply(lambda x: float(x['q']) if x['m'] else 0, axis=1)
            temp_dfs.append(chunk_df[['buy_volume', 'sell_volume', 'price', 'quantity']])
            all_trades = []
        
        if not temp_dfs:
            logger.warning("‚ö†Ô∏è –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã")
            return pd.DataFrame()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏
        logger.info(f"   üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ {len(temp_dfs)} —á–∞–Ω–∫–æ–≤...")
        memory_before = get_memory_usage_mb()
        
        df = pd.concat(temp_dfs, ignore_index=False)
        del temp_dfs
        gc.collect()
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        df = df[~df.index.duplicated(keep='first')]
        df.sort_index(inplace=True)
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –ø–∞–º—è—Ç—å
        df = optimize_dataframe_memory(df)
        
        memory_after = get_memory_usage_mb()
        memory_used = memory_after - memory_before
        
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(df)} –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫")
        if memory_used > 0:
            logger.info(f"   üíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {memory_used:.2f} MB")
        
        return df[['buy_volume', 'sell_volume', 'price', 'quantity']]
    
    def get_liquidations_batch(
        self,
        start_time: datetime,
        end_time: datetime
    ) -> pd.DataFrame:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ª–∏–∫–≤–∏–¥–∞—Ü–∏—è—Ö (–¥–ª—è —Ñ—å—é—á–µ—Ä—Å–æ–≤)
        
        Args:
            start_time: –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
            end_time: –ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è
        
        Returns:
            DataFrame —Å –ª–∏–∫–≤–∏–¥–∞—Ü–∏—è–º–∏
        """
        logger.info(f"üìä –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ –ª–∏–∫–≤–∏–¥–∞—Ü–∏—è—Ö —Å {start_time.date()} –ø–æ {end_time.date()}")
        
        try:
            url = "https://fapi.binance.com/fapi/v1/forceOrders"
            
            all_liquidations = []
            from_time = start_time
            
            # –û—Ü–µ–Ω–∫–∞ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            estimated_days = (end_time - start_time).days
            estimated_requests = max(1, estimated_days)
            
            pbar = tqdm(total=estimated_requests, desc="Liquidations", unit="batch")
            
            while from_time < end_time:
                params = {
                    'symbol': self.symbol_futures,
                    'startTime': int(from_time.timestamp() * 1000),
                    'endTime': int(end_time.timestamp() * 1000),
                    'limit': 1000
                }
                
                try:
                    response = requests.get(url, params=params, timeout=config.REQUEST_TIMEOUT)
                    
                    if response.status_code == 200:
                        data = response.json()
                        if not data:
                            break
                        
                        all_liquidations.extend(data)
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
                        last_time = data[-1]['time'] / 1000
                        from_time = datetime.fromtimestamp(last_time) + timedelta(milliseconds=1)
                        
                        pbar.update(1)
                        time.sleep(config.REQUEST_DELAY)
                    elif response.status_code == 429:
                        logger.warning("‚ö†Ô∏è Rate limit, —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏...")
                        time.sleep(config.REQUEST_DELAY * 10)
                        continue
                    else:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API: {response.status_code}")
                        break
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –ª–∏–∫–≤–∏–¥–∞—Ü–∏–π: {e}")
                    break
            
            pbar.close()
            
            if not all_liquidations:
                logger.warning("‚ö†Ô∏è –õ–∏–∫–≤–∏–¥–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞)")
                return pd.DataFrame()
            
            df = pd.DataFrame(all_liquidations)
            df['timestamp'] = pd.to_datetime(df['time'], unit='ms')
            df.set_index('timestamp', inplace=True)
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ long –∏ short –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏
            df['liquidation_type'] = df['side'].apply(lambda x: 'long' if x == 'SELL' else 'short')
            df['liquidation_quantity'] = df['executedQty'].astype(float)
            df['liquidation_price'] = df['price'].astype(float)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            df = df[~df.index.duplicated(keep='first')]
            df.sort_index(inplace=True)
            
            logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(df)} –ª–∏–∫–≤–∏–¥–∞—Ü–∏–π")
            
            return df[['liquidation_type', 'liquidation_quantity', 'liquidation_price']]
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ª–∏–∫–≤–∏–¥–∞—Ü–∏–π: {e}")
            return pd.DataFrame()
    
    def get_open_interest_history_batch(
        self,
        start_time: datetime,
        end_time: datetime,
        period: str = "15m"
    ) -> pd.DataFrame:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞
        
        Args:
            start_time: –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
            end_time: –ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è
            period: –ü–µ—Ä–∏–æ–¥ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (5m, 15m, 30m, 1h, 2h, 4h, 6h, 12h, 1d)
        
        Returns:
            DataFrame —Å –∏—Å—Ç–æ—Ä–∏–µ–π –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞
        """
        logger.info(f"üìä –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏–∏ –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞ —Å {start_time.date()} –ø–æ {end_time.date()}")
        
        try:
            url = "https://fapi.binance.com/futures/data/openInterestHist"
            
            oi_data = []
            current_time = start_time
            
            # –û—Ü–µ–Ω–∫–∞ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            total_days = (end_time - start_time).days
            estimated_requests = max(1, total_days // 30)  # API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ 30 –¥–Ω–µ–π –∑–∞ –∑–∞–ø—Ä–æ—Å
            
            pbar = tqdm(total=estimated_requests, desc="Open Interest", unit="batch")
            
            while current_time < end_time:
                params = {
                    'symbol': self.symbol_futures,
                    'period': period,
                    'startTime': int(current_time.timestamp() * 1000),
                    'endTime': int(min(current_time + timedelta(days=30), end_time).timestamp() * 1000),
                    'limit': 500
                }
                
                try:
                    response = requests.get(url, params=params, timeout=config.REQUEST_TIMEOUT)
                    
                    if response.status_code == 200:
                        data = response.json()
                        if not data:
                            break
                        
                        oi_data.extend(data)
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è
                        last_time = data[-1]['timestamp'] / 1000
                        current_time = datetime.fromtimestamp(last_time) + timedelta(minutes=15)
                        
                        pbar.update(1)
                        time.sleep(config.REQUEST_DELAY)
                    elif response.status_code == 429:
                        logger.warning("‚ö†Ô∏è Rate limit, —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏...")
                        time.sleep(config.REQUEST_DELAY * 10)
                        continue
                    else:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API: {response.status_code}")
                        break
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞: {e}")
                    break
            
            pbar.close()
            
            if not oi_data:
                logger.warning("‚ö†Ô∏è –ò—Å—Ç–æ—Ä–∏—è –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                return pd.DataFrame()
            
            df = pd.DataFrame(oi_data)
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            
            df['open_interest'] = df['sumOpenInterest'].astype(float)
            df['open_interest_value'] = df['sumOpenInterestValue'].astype(float)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            df = df[~df.index.duplicated(keep='first')]
            df.sort_index(inplace=True)
            
            logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞")
            
            return df[['open_interest', 'open_interest_value']]
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞: {e}")
            return pd.DataFrame()
    
    def get_order_book_depth(self, price: float, depth_percent: float) -> Dict[str, float]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—ä–µ–º–∞ –ª–∏–º–∏—Ç–Ω—ã—Ö –∑–∞—è–≤–æ–∫ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–π –≥–ª—É–±–∏–Ω–µ –æ—Ç —Ü–µ–Ω—ã
        
        Args:
            price: –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
            depth_percent: –ì–ª—É–±–∏–Ω–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (0.03 = 3%)
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ–±—ä–µ–º–∞–º–∏ –ø–æ–∫—É–ø–æ–∫ –∏ –ø—Ä–æ–¥–∞–∂ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–π –≥–ª—É–±–∏–Ω–µ
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º order book —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≥–ª—É–±–∏–Ω–æ–π (5000 —É—Ä–æ–≤–Ω–µ–π)
            order_book = self.spot_client.get_order_book(symbol=self.symbol, limit=5000)
            
            # –¶–µ–Ω—ã –¥–ª—è –ø–æ–∫—É–ø–æ–∫ (bid) –∏ –ø—Ä–æ–¥–∞–∂ (ask)
            bid_price_threshold = price * (1 - depth_percent)
            ask_price_threshold = price * (1 + depth_percent)
            
            # –°—É–º–º–∏—Ä—É–µ–º –æ–±—ä–µ–º—ã –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø–æ–∫—É–ø–æ–∫ (bids) - –ª–∏–º–∏—Ç–Ω—ã–µ –∑–∞—è–≤–∫–∏ –Ω–∞ –ø–æ–∫—É–ø–∫—É
            bid_volume = 0.0
            for bid in order_book['bids']:
                bid_price = float(bid[0])
                if bid_price >= bid_price_threshold:
                    bid_volume += float(bid[1])
                else:
                    break
            
            # –°—É–º–º–∏—Ä—É–µ–º –æ–±—ä–µ–º—ã –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–æ–¥–∞–∂ (asks) - –ª–∏–º–∏—Ç–Ω—ã–µ –∑–∞—è–≤–∫–∏ –Ω–∞ –ø—Ä–æ–¥–∞–∂—É
            ask_volume = 0.0
            for ask in order_book['asks']:
                ask_price = float(ask[0])
                if ask_price <= ask_price_threshold:
                    ask_volume += float(ask[1])
                else:
                    break
            
            total_volume = bid_volume + ask_volume
            imbalance = (bid_volume - ask_volume) / total_volume if total_volume > 0 else 0
            
            return {
                'bid_volume': bid_volume,
                'ask_volume': ask_volume,
                'total_volume': total_volume,
                'imbalance': imbalance
            }
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è order book: {e}")
            return {
                'bid_volume': 0.0,
                'ask_volume': 0.0,
                'total_volume': 0.0,
                'imbalance': 0.0
            }
    
    def collect_order_book_snapshots(
        self,
        ohlcv_df: pd.DataFrame,
        sample_rate: int = 10
    ) -> pd.DataFrame:
        """
        –°–±–æ—Ä –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö —Å–Ω–∏–º–∫–æ–≤ order book –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω
        
        –í–∞–∂–Ω–æ: Binance –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é order book, –ø–æ—ç—Ç–æ–º—É –º—ã –¥–µ–ª–∞–µ–º
        –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —Å–Ω–∏–º–∫–∏ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è order book. –≠—Ç–æ –Ω–µ —Ç–æ—á–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è,
        –Ω–æ –¥–∞–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ –≥–ª—É–±–∏–Ω–µ —Ä—ã–Ω–∫–∞.
        
        Args:
            ohlcv_df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ (–Ω—É–∂–µ–Ω –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω)
            sample_rate: –ö–∞–∂–¥—É—é N-—é —Å–≤–µ—á—É –¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫ order book
        
        Returns:
            DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ order book
        """
        logger.info(f"üìä –°–±–æ—Ä –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö —Å–Ω–∏–º–∫–æ–≤ order book (–∫–∞–∂–¥—É—é {sample_rate}-—é —Å–≤–µ—á—É)...")
        
        if ohlcv_df.empty:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö OHLCV –¥–ª—è —Å–±–æ—Ä–∞ order book")
            return pd.DataFrame()
        
        order_book_data = []
        
        # –ë–µ—Ä–µ–º –∫–∞–∂–¥—É—é sample_rate-—é —Å–≤–µ—á—É
        sample_indices = range(0, len(ohlcv_df), sample_rate)
        total_samples = len(sample_indices)
        
        pbar = tqdm(total=total_samples, desc="Order Book Snapshots", unit="snapshot")
        
        for idx in sample_indices:
            try:
                timestamp = ohlcv_df.index[idx]
                current_price = ohlcv_df.loc[timestamp, 'close']
                
                snapshot = {
                    'timestamp': timestamp
                }
                
                # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–π –≥–ª—É–±–∏–Ω—ã
                for depth in self.orderbook_depths:
                    depth_key = f"{int(depth * 100)}pct"
                    depth_data = self.get_order_book_depth(current_price, depth)
                    
                    snapshot[f'bid_volume_{depth_key}'] = depth_data['bid_volume']
                    snapshot[f'ask_volume_{depth_key}'] = depth_data['ask_volume']
                    snapshot[f'total_volume_{depth_key}'] = depth_data['total_volume']
                    snapshot[f'imbalance_{depth_key}'] = depth_data['imbalance']
                
                order_book_data.append(snapshot)
                
                pbar.update(1)
                time.sleep(config.REQUEST_DELAY)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ —Å–Ω–∏–º–∫–∞ order book: {e}")
                continue
        
        pbar.close()
        
        if not order_book_data:
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ order book")
            return pd.DataFrame()
        
        df = pd.DataFrame(order_book_data)
        df.set_index('timestamp', inplace=True)
        df.sort_index(inplace=True)
        
        logger.info(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df)} —Å–Ω–∏–º–∫–æ–≤ order book")
        
        return df
    
    def get_24h_ticker_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ 24 —á–∞—Å–∞"""
        try:
            ticker = self.spot_client.get_ticker(symbol=self.symbol)
            return {
                'price_change_24h': float(ticker.get('priceChange', 0)),
                'price_change_percent_24h': float(ticker.get('priceChangePercent', 0)),
                'high_24h': float(ticker.get('highPrice', 0)),
                'low_24h': float(ticker.get('lowPrice', 0)),
                'volume_24h': float(ticker.get('volume', 0)),
                'quote_volume_24h': float(ticker.get('quoteVolume', 0)),
                'count_24h': int(ticker.get('count', 0))
            }
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è 24h —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}
    
    def combine_all_data(
        self,
        ohlcv_df: pd.DataFrame,
        trades_df: pd.DataFrame,
        liquidations_df: pd.DataFrame,
        oi_df: pd.DataFrame,
        order_book_df: pd.DataFrame = None,
        target_interval: str = "15m"
    ) -> pd.DataFrame:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –æ–¥–∏–Ω DataFrame —Å –∑–∞–¥–∞–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
        
        Args:
            ohlcv_df: OHLCV –¥–∞–Ω–Ω—ã–µ
            trades_df: –î–∞–Ω–Ω—ã–µ –æ —Å–¥–µ–ª–∫–∞—Ö
            liquidations_df: –î–∞–Ω–Ω—ã–µ –æ –ª–∏–∫–≤–∏–¥–∞—Ü–∏—è—Ö
            oi_df: –î–∞–Ω–Ω—ã–µ –æ–± –æ—Ç–∫—Ä—ã—Ç–æ–º –∏–Ω—Ç–µ—Ä–µ—Å–µ
            order_book_df: –î–∞–Ω–Ω—ã–µ order book (–ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —Å–Ω–∏–º–∫–∏)
            target_interval: –¶–µ–ª–µ–≤–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '15m', '1h', '1d')
        
        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame
        """
        logger.info(f"\nüìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {target_interval}...")
        
        if ohlcv_df.empty:
            logger.error("‚ùå –ù–µ—Ç OHLCV –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è!")
            return pd.DataFrame()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º OHLCV –∫–∞–∫ –æ—Å–Ω–æ–≤—É
        result_df = ohlcv_df.copy()
        
        # –†–µ—Å–µ–º–ø–ª–∏—Ä—É–µ–º OHLCV –Ω–∞ —Ü–µ–ª–µ–≤–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if target_interval and ohlcv_df.index[0] < ohlcv_df.index[-1]:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
            time_diff = (ohlcv_df.index[1] - ohlcv_df.index[0]).total_seconds() / 60
            target_minutes = self._interval_to_minutes(target_interval)
            
            if target_minutes > time_diff:
                # –ù—É–∂–Ω–æ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å
                result_df = result_df.resample(target_interval).agg({
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last',
                    'volume': 'sum',
                    'quote_volume': 'sum',
                    'taker_buy_base': 'sum',
                    'taker_buy_quote': 'sum',
                    'trades': 'sum'
                })
                result_df = result_df.dropna()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏
        if not trades_df.empty:
            trades_resampled = trades_df.resample(target_interval).agg({
                'buy_volume': 'sum',
                'sell_volume': 'sum',
                'quantity': 'sum',
                'price': 'last'
            })
            trades_resampled.columns = ['market_buy_volume', 'market_sell_volume', 
                                        'total_trade_quantity', 'last_trade_price']
            result_df = result_df.join(trades_resampled, how='left')
            result_df['market_buy_volume'] = result_df['market_buy_volume'].fillna(0)
            result_df['market_sell_volume'] = result_df['market_sell_volume'].fillna(0)
            result_df['total_trade_quantity'] = result_df['total_trade_quantity'].fillna(0)
        else:
            result_df['market_buy_volume'] = 0
            result_df['market_sell_volume'] = 0
            result_df['total_trade_quantity'] = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏
        if not liquidations_df.empty:
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏ –ø–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º
            liquidations_resampled = liquidations_df.resample(target_interval).agg({
                'liquidation_quantity': 'sum'
            })
            liquidations_resampled.columns = ['total_liquidations']
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ long –∏ short
            long_liq = liquidations_df[liquidations_df['liquidation_type'] == 'long'].resample(target_interval)['liquidation_quantity'].sum()
            short_liq = liquidations_df[liquidations_df['liquidation_type'] == 'short'].resample(target_interval)['liquidation_quantity'].sum()
            
            result_df['long_liquidations'] = long_liq
            result_df['short_liquidations'] = short_liq
            result_df['total_liquidations'] = liquidations_resampled['total_liquidations']
            
            result_df['long_liquidations'] = result_df['long_liquidations'].fillna(0)
            result_df['short_liquidations'] = result_df['short_liquidations'].fillna(0)
            result_df['total_liquidations'] = result_df['total_liquidations'].fillna(0)
        else:
            result_df['long_liquidations'] = 0
            result_df['short_liquidations'] = 0
            result_df['total_liquidations'] = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–∫—Ä—ã—Ç—ã–π –∏–Ω—Ç–µ—Ä–µ—Å
        if not oi_df.empty:
            # –†–µ—Å–µ–º–ø–ª–∏—Ä—É–µ–º –Ω–∞ —Ü–µ–ª–µ–≤–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
            oi_resampled = oi_df.resample(target_interval).agg({
                'open_interest': 'last',
                'open_interest_value': 'last'
            })
            result_df = result_df.join(oi_resampled, how='left')
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ forward fill
            result_df['open_interest'] = result_df['open_interest'].ffill().fillna(0)
            result_df['open_interest_value'] = result_df['open_interest_value'].ffill().fillna(0)
        else:
            result_df['open_interest'] = 0
            result_df['open_interest_value'] = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ order book (–ª–∏–º–∏—Ç–Ω—ã–µ –∑–∞—è–≤–∫–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≥–ª—É–±–∏–Ω–∞—Ö)
        if order_book_df is not None and not order_book_df.empty:
            # –†–µ—Å–µ–º–ø–ª–∏—Ä—É–µ–º order book –Ω–∞ —Ü–µ–ª–µ–≤–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª, –∏—Å–ø–æ–ª—å–∑—É—è –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (forward fill)
            # –≠—Ç–æ –Ω—É–∂–Ω–æ, —Ç–∞–∫ –∫–∞–∫ order book –¥–∞–Ω–Ω—ã–µ —Å–æ–±–∏—Ä–∞—é—Ç—Å—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏
            order_book_cols = order_book_df.columns
            
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º, –∏—Å–ø–æ–ª—å–∑—É—è –ø–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ—Å—Ç—É–ø–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            order_book_resampled = order_book_df.resample(target_interval).last()
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –æ—Å–Ω–æ–≤–Ω—ã–º DataFrame
            result_df = result_df.join(order_book_resampled, how='left')
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ forward fill (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–≤–µ—Å—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
            for col in order_book_cols:
                if col in result_df.columns:
                    result_df[col] = result_df[col].ffill().fillna(0)
            
            logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ order book –¥–ª—è {len(order_book_cols)} –∫–æ–ª–æ–Ω–æ–∫")
        else:
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –¥–ª—è –≤—Å–µ—Ö –≥–ª—É–±–∏–Ω order book
            for depth in self.orderbook_depths:
                depth_key = f"{int(depth * 100)}pct"
                result_df[f'bid_volume_{depth_key}'] = 0
                result_df[f'ask_volume_{depth_key}'] = 0
                result_df[f'total_volume_{depth_key}'] = 0
                result_df[f'imbalance_{depth_key}'] = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        result_df['buy_sell_ratio'] = np.where(
            result_df['market_sell_volume'] > 0,
            result_df['market_buy_volume'] / result_df['market_sell_volume'],
            0
        )
        
        result_df['liquidation_ratio'] = np.where(
            result_df['total_liquidations'] > 0,
            result_df['long_liquidations'] / (result_df['long_liquidations'] + result_df['short_liquidations']),
            0
        )
        
        # –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        result_df = result_df.dropna(how='all')
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–Ω–¥–µ–∫—Å—É
        result_df.sort_index(inplace=True)
        
        logger.info(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(result_df)} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"üìä –ö–æ–ª–æ–Ω–∫–∏: {list(result_df.columns)}")
        
        return result_df
    
    def _interval_to_minutes(self, interval: str) -> int:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –≤ –º–∏–Ω—É—Ç—ã"""
        if interval.endswith('m'):
            return int(interval[:-1])
        elif interval.endswith('h'):
            return int(interval[:-1]) * 60
        elif interval.endswith('d'):
            return int(interval[:-1]) * 24 * 60
        elif interval.endswith('w'):
            return int(interval[:-1]) * 7 * 24 * 60
        elif interval.endswith('M'):
            return int(interval[:-1]) * 30 * 24 * 60
        else:
            return 15  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 15 –º–∏–Ω—É—Ç
    
    def collect_comprehensive_data(
        self,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        interval: str = "15m",
        target_interval: str = "15m",
        include_all_timeframes: bool = False,
        skip_aggregated_trades: bool = False
    ) -> pd.DataFrame:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–±–æ—Ä –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            start_date: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è —Å –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã Binance - 2017-08-01)
            end_date: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (–µ—Å–ª–∏ None, —Ç–µ–∫—É—â–∞—è –¥–∞—Ç–∞)
            interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è —Å–±–æ—Ä–∞ OHLCV (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π, –Ω–∞–ø—Ä–∏–º–µ—Ä '1m', '5m')
            target_interval: –¶–µ–ª–µ–≤–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä '15m', '1h', '1d')
            include_all_timeframes: –°–æ–±–∏—Ä–∞—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        
        Returns:
            DataFrame —Å–æ –≤—Å–µ–º–∏ —Å–æ–±—Ä–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥
        if end_date is None:
            end_date = datetime.now()
        
        if start_date is None:
            # Binance –Ω–∞—á–∞–ª —Ä–∞–±–æ—Ç—É –≤ –∞–≤–≥—É—Å—Ç–µ 2017
            start_date = datetime(2017, 8, 1)
        
        logger.info("="*70)
        logger.info("üöÄ –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –°–ë–û–† –î–ê–ù–ù–´–• –° BINANCE")
        logger.info("="*70)
        logger.info(f"üìä –°–∏–º–≤–æ–ª: {self.symbol}")
        logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {start_date.date()} - {end_date.date()}")
        logger.info(f"‚è±Ô∏è  –ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–±–æ—Ä–∞: {interval}")
        logger.info(f"‚è±Ô∏è  –¶–µ–ª–µ–≤–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: {target_interval}")
        logger.info(f"‚è∞ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è...")
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏
        initial_memory = get_memory_usage_mb()
        if initial_memory > 0:
            logger.info(f"üíæ –ù–∞—á–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {initial_memory:.2f} MB")
        logger.info("="*70)
        
        # 1. –°–æ–±–∏—Ä–∞–µ–º OHLCV –¥–∞–Ω–Ω—ã–µ (–æ—Å–Ω–æ–≤–∞)
        logger.info("\nüìä –®–∞–≥ 1/5: –°–±–æ—Ä OHLCV –¥–∞–Ω–Ω—ã—Ö...")
        ohlcv_df = self.get_klines_batch(interval, start_date, end_date)
        
        if ohlcv_df.empty:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å OHLCV –¥–∞–Ω–Ω—ã–µ!")
            return pd.DataFrame()
        
        # 2. –°–æ–±–∏—Ä–∞–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏ (—Ä—ã–Ω–æ—á–Ω—ã–µ –ø–æ–∫—É–ø–∫–∏ –∏ –ø—Ä–æ–¥–∞–∂–∏)
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –ø–µ—Ä–∏–æ–¥ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (> 90 –¥–Ω–µ–π) –∏–ª–∏ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
        period_days = (end_date - start_date).days
        if skip_aggregated_trades or period_days > 90:
            if period_days > 90:
                logger.warning(f"\n‚ö†Ô∏è –ü–µ—Ä–∏–æ–¥ {period_days} –¥–Ω–µ–π —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫.")
                logger.warning("   –°–±–æ—Ä –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–µ—Å—è—Ç–∫–∏ —á–∞—Å–æ–≤. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏.")
                logger.warning("   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à–∏–π –ø–µ—Ä–∏–æ–¥ –∏–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å skip_aggregated_trades=False –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–±–æ—Ä–∞.")
            else:
                logger.info("\nüìä –®–∞–≥ 2/5: –ü—Ä–æ–ø—É—Å–∫ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (skip_aggregated_trades=True)...")
            trades_df = pd.DataFrame()
        else:
            logger.info("\nüìä –®–∞–≥ 2/5: –°–±–æ—Ä –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (—Ä—ã–Ω–æ—á–Ω—ã–µ –æ–±—ä–µ–º—ã)...")
            trades_df = self.get_aggregated_trades_batch(start_date, end_date)
        
        # 3. –°–æ–±–∏—Ä–∞–µ–º –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏
        logger.info("\nüìä –®–∞–≥ 3/5: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ –ª–∏–∫–≤–∏–¥–∞—Ü–∏—è—Ö...")
        liquidations_df = self.get_liquidations_batch(start_date, end_date)
        
        # 4. –°–æ–±–∏—Ä–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞
        logger.info("\nüìä –®–∞–≥ 4/5: –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏–∏ –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞...")
        oi_period = target_interval if target_interval in ['5m', '15m', '30m', '1h', '2h', '4h', '6h', '12h', '1d'] else '15m'
        oi_df = self.get_open_interest_history_batch(start_date, end_date, period=oi_period)
        
        # 5. –°–æ–±–∏—Ä–∞–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —Å–Ω–∏–º–∫–∏ order book (–ª–∏–º–∏—Ç–Ω—ã–µ –∑–∞—è–≤–∫–∏ –Ω–∞ –≥–ª—É–±–∏–Ω–∞—Ö 3%, 8%, 15%, 60%)
        logger.info("\nüìä –®–∞–≥ 5/5: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö order book (–ª–∏–º–∏—Ç–Ω—ã–µ –∑–∞—è–≤–∫–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≥–ª—É–±–∏–Ω–∞—Ö)...")
        logger.info("   ‚ö†Ô∏è  –í–∞–∂–Ω–æ: Binance –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é order book.")
        logger.info("   üì∏ –°–æ–±–∏—Ä–∞–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —Å–Ω–∏–º–∫–∏ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è order book.")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º sample_rate –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
        # –ß–µ–º –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö, —Ç–µ–º —Ä–µ–∂–µ –¥–µ–ª–∞–µ–º —Å–Ω–∏–º–∫–∏
        if len(ohlcv_df) > 10000:
            sample_rate = 50  # –ö–∞–∂–¥—É—é 50-—é —Å–≤–µ—á—É
        elif len(ohlcv_df) > 5000:
            sample_rate = 30  # –ö–∞–∂–¥—É—é 30-—é —Å–≤–µ—á—É
        elif len(ohlcv_df) > 1000:
            sample_rate = 20  # –ö–∞–∂–¥—É—é 20-—é —Å–≤–µ—á—É
        else:
            sample_rate = 10  # –ö–∞–∂–¥—É—é 10-—é —Å–≤–µ—á—É
        
        order_book_df = self.collect_order_book_snapshots(ohlcv_df, sample_rate=sample_rate)
        
        # 6. –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        logger.info("\nüìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...")
        result_df = self.combine_all_data(
            ohlcv_df, 
            trades_df, 
            liquidations_df, 
            oi_df,
            order_book_df=order_book_df,
            target_interval=target_interval
        )
        
        logger.info("\n" + "="*70)
        logger.info("‚úÖ –°–ë–û–† –î–ê–ù–ù–´–• –ó–ê–í–ï–†–®–ï–ù!")
        logger.info("="*70)
        logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(result_df)}")
        logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {result_df.index[0]} - {result_df.index[-1]}")
        logger.info(f"üìà –ö–æ–ª–æ–Ω–æ–∫: {len(result_df.columns)}")
        logger.info(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {', '.join(result_df.columns)}")
        
        return result_df


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å Binance')
    parser.add_argument('--symbol', type=str, default='BTCUSDT', help='–¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞')
    parser.add_argument('--start-date', type=str, help='–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 2017-08-01')
    parser.add_argument('--end-date', type=str, help='–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Å–µ–≥–æ–¥–Ω—è')
    parser.add_argument('--interval', type=str, default='15m', help='–ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–±–æ—Ä–∞ OHLCV (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1m, 5m, 15m, 1h, 1d)')
    parser.add_argument('--target-interval', type=str, default='15m', help='–¶–µ–ª–µ–≤–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 15m, 1h, 1d)')
    parser.add_argument('--output', type=str, help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)')
    parser.add_argument('--skip-trades', action='store_true', help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–±–æ—Ä –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (–±—ã—Å—Ç—Ä–µ–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤)')
    
    args = parser.parse_args()
    
    collector = ComprehensiveBinanceCollector(symbol=args.symbol)
    
    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—ã
    start_date = None
    if args.start_date:
        start_date = datetime.strptime(args.start_date, '%Y-%m-%d')
    
    end_date = None
    if args.end_date:
        end_date = datetime.strptime(args.end_date, '%Y-%m-%d')
    
    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = collector.collect_comprehensive_data(
        start_date=start_date,
        end_date=end_date,
        interval=args.interval,
        target_interval=args.target_interval,
        skip_aggregated_trades=args.skip_trades
    )
    
    if not df.empty:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        if args.output:
            filepath = Path(args.output)
        else:
            start_str = df.index[0].strftime('%Y%m%d')
            end_str = df.index[-1].strftime('%Y%m%d')
            filename = f"{args.symbol}_comprehensive_{args.target_interval}_{start_str}_{end_str}.csv"
            filepath = config.DATA_DIR / "historical" / filename
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        logger.info(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ {filepath}...")
        save_data(df, filepath, format="csv")
        
        logger.info(f"\n‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")
        logger.info(f"üìÅ –§–∞–π–ª: {filepath}")
        logger.info(f"üìä –†–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫ √ó {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
        logger.info(f"\nüìã –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö:")
        logger.info(f"\n{df.head(10)}")
        logger.info(f"\n...")
        logger.info(f"\n{df.tail(10)}")
    else:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ!")


if __name__ == "__main__":
    main()
