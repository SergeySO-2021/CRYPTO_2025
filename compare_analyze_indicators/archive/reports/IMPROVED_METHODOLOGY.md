# –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –≤—ã–±–æ—Ä–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö –∑–æ–Ω

## üéØ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏–≤—ã –∏ —É–ª—É—á—à–µ–Ω–∏—è

### 1. –ü—Ä–æ–±–ª–µ–º–∞: –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ ground truth –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

**–¢–µ–∫—É—â–∏–π –ø–æ–¥—Ö–æ–¥:** –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏  
**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ–¥—Ö–æ–¥:** –û—Ü–µ–Ω–∫–∞ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–π –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

```python
def calculate_economic_metrics(data, predictions):
    """–ú–µ—Ç—Ä–∏–∫–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–π —Ü–µ–ª–µ—Å–æ–æ–±—Ä–∞–∑–Ω–æ—Å—Ç–∏"""
    
    # 1. –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
    bull_returns = data[predictions == 1]['close'].pct_change().mean()
    bear_returns = data[predictions == -1]['close'].pct_change().mean()
    sideways_returns = data[predictions == 0]['close'].pct_change().mean()
    
    # 2. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
    volatility_ratio = (
        data[predictions == 0]['close'].pct_change().std() / 
        data[predictions != 0]['close'].pct_change().std()
    )
    
    # 3. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ç—Ä–µ–Ω–¥—É
    trend_following_efficiency = calculate_trend_efficiency(data, predictions)
    
    return {
        'return_spread': bull_returns - bear_returns,
        'volatility_ratio': volatility_ratio,
        'trend_efficiency': trend_following_efficiency,
        'economic_value': (bull_returns - bear_returns) * volatility_ratio
    }
```

### 2. –£–ª—É—á—à–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

```python
class PurgedWalkForward:
    """Purged Walk-Forward Validation –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, n_splits=5, purge_days=2, embargo_days=1):
        self.n_splits = n_splits
        self.purge_days = purge_days
        self.embargo_days = embargo_days
    
    def split(self, data):
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å —É—á–µ—Ç–æ–º purge –∏ embargo –ø–µ—Ä–∏–æ–¥–æ–≤"""
        total_length = len(data)
        split_size = total_length // (self.n_splits + 1)
        
        for i in range(self.n_splits):
            train_end = (i + 1) * split_size
            test_start = train_end + self.purge_days
            test_end = test_start + split_size - self.embargo_days
            
            if test_end <= total_length:
                train_indices = list(range(0, train_end))
                test_indices = list(range(test_start, test_end))
                
                yield train_indices, test_indices
    
    def evaluate_classifier(self, classifier, data):
        """–û—Ü–µ–Ω–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å Purged Walk-Forward"""
        results = []
        
        for train_idx, test_idx in self.split(data):
            train_data = data.iloc[train_idx]
            test_data = data.iloc[test_idx]
            
            # –û–±—É—á–∞–µ–º –Ω–∞ train_data
            classifier.fit(train_data)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ test_data
            predictions = classifier.predict(test_data)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            metrics = calculate_economic_metrics(test_data, predictions)
            results.append(metrics)
        
        return results
```

### 3. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –≤—ã–±–æ—Ä–∞

```python
# –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≤–µ—Å–æ–≤ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å
OPTIMIZATION_WEIGHTS = {
    'economic_value': 0.35,      # –°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ä–∞–∑–¥–µ–ª—è—Ç—å —Ä–µ–∂–∏–º—ã –ø–æ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
    'stability': 0.25,          # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–∞—Ö
    'computational_efficiency': 0.15,  # –°–∫–æ—Ä–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    'robustness': 0.15,         # –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —à—É–º—É
    'interpretability': 0.10    # –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
}

def calculate_comprehensive_score(classifier_results):
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
    
    economic_score = (
        classifier_results['return_spread'] * 0.6 +
        classifier_results['volatility_ratio'] * 0.4
    )
    
    stability_score = np.mean([
        classifier_results['temporal_stability'],
        classifier_results['parameter_stability']
    ])
    
    return (
        economic_score * OPTIMIZATION_WEIGHTS['economic_value'] +
        stability_score * OPTIMIZATION_WEIGHTS['stability'] +
        classifier_results['speed_score'] * OPTIMIZATION_WEIGHTS['computational_efficiency'] +
        classifier_results['robustness_score'] * OPTIMIZATION_WEIGHTS['robustness'] +
        classifier_results['interpretability'] * OPTIMIZATION_WEIGHTS['interpretability']
    )
```

### 4. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è

```python
def overfitting_analysis(classifier, data, n_iterations=100):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
    
    results = {
        'parameter_sensitivity': [],
        'noise_robustness': [],
        'temporal_stability': []
    }
    
    # –ê–Ω–∞–ª–∏–∑ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
    for _ in range(n_iterations):
        # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º –∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
        noisy_params = add_parameter_noise(classifier.parameters)
        noisy_classifier = classifier.__class__(parameters=noisy_params)
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        original_perf = evaluate_classifier(classifier, data)
        noisy_perf = evaluate_classifier(noisy_classifier, data)
        
        sensitivity = abs(original_perf - noisy_perf) / original_perf
        results['parameter_sensitivity'].append(sensitivity)
    
    # –ê–Ω–∞–ª–∏–∑ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∫ —à—É–º—É –≤ –¥–∞–Ω–Ω—ã—Ö
    for noise_level in [0.01, 0.02, 0.05]:
        noisy_data = add_market_noise(data, noise_level)
        noisy_perf = evaluate_classifier(classifier, noisy_data)
        results['noise_robustness'].append(noisy_perf)
    
    return results

def add_parameter_noise(parameters, noise_level=0.1):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞ –∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    noisy_params = {}
    
    for key, value in parameters.items():
        if isinstance(value, (int, float)):
            noise = np.random.normal(0, noise_level * abs(value))
            noisy_params[key] = value + noise
        else:
            noisy_params[key] = value
    
    return noisy_params

def add_market_noise(data, noise_level):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞ –∫ —Ä—ã–Ω–æ—á–Ω—ã–º –¥–∞–Ω–Ω—ã–º"""
    noisy_data = data.copy()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º –∫ —Ü–µ–Ω–∞–º
    price_noise = np.random.normal(0, noise_level, len(data))
    noisy_data['close'] = noisy_data['close'] * (1 + price_noise)
    noisy_data['open'] = noisy_data['open'] * (1 + price_noise)
    noisy_data['high'] = noisy_data['high'] * (1 + price_noise)
    noisy_data['low'] = noisy_data['low'] * (1 + price_noise)
    
    return noisy_data
```

### 5. –ê–Ω–∞–ª–∏–∑ –µ–º–∫–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

```python
def capacity_analysis(classifier, data, position_sizes):
    """–ê–Ω–∞–ª–∏–∑ –µ–º–∫–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
    
    capacity_metrics = {}
    
    for size in position_sizes:
        # –°–∏–º—É–ª—è—Ü–∏—è –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Ä—ã–Ω–æ–∫
        simulated_impact = simulate_market_impact(
            classifier.predictions, 
            size
        )
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ —Å —É—á–µ—Ç–æ–º –≤–ª–∏—è–Ω–∏—è
        adjusted_returns = calculate_adjusted_returns(
            data, simulated_impact
        )
        
        capacity_metrics[size] = adjusted_returns
    
    return capacity_metrics

def simulate_market_impact(predictions, position_size):
    """–°–∏–º—É–ª—è—Ü–∏—è –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Ä—ã–Ω–æ–∫ –æ—Ç —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏–π"""
    # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Ä—ã–Ω–æ–∫
    impact_factor = position_size * 0.001  # 0.1% –Ω–∞ –∫–∞–∂–¥—ã–π –º–∏–ª–ª–∏–æ–Ω
    return predictions * impact_factor

def calculate_adjusted_returns(data, market_impact):
    """–†–∞—Å—á–µ—Ç —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ —Å —É—á–µ—Ç–æ–º –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Ä—ã–Ω–æ–∫"""
    base_returns = data['close'].pct_change()
    adjusted_returns = base_returns - market_impact
    return adjusted_returns
```

### 6. –£–ª—É—á—à–µ–Ω–∏–µ –º—É–ª—å—Ç–∏—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

```python
def hierarchical_timeframe_analysis(data_dict, classifier):
    """–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤"""
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
    dominant_timeframes = []
    
    for main_tf in ['1d', '4h', '1h']:
        main_predictions = classifier.predict(data_dict[main_tf])
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å –º–ª–∞–¥—à–∏–º–∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º–∏
        consistency_scores = []
        
        for lower_tf in ['1h', '30m', '15m']:
            if lower_tf != main_tf:
                lower_predictions = classifier.predict(data_dict[lower_tf])
                consistency = calculate_temporal_consistency(
                    main_predictions, lower_predictions, main_tf, lower_tf
                )
                consistency_scores.append(consistency)
        
        dominant_timeframes.append({
            'timeframe': main_tf,
            'consistency_score': np.mean(consistency_scores),
            'predictive_power': calculate_predictive_power(data_dict[main_tf])
        })
    
    return sorted(dominant_timeframes, key=lambda x: x['predictive_power'], reverse=True)

def calculate_temporal_consistency(main_predictions, lower_predictions, main_tf, lower_tf):
    """–†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º–∏"""
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫ –æ–±—â–µ–º—É –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—é
    scale_factor = get_timeframe_scale(main_tf, lower_tf)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
    correlation = np.corrcoef(main_predictions, lower_predictions[::scale_factor])[0, 1]
    
    return correlation

def get_timeframe_scale(main_tf, lower_tf):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –º–µ–∂–¥—É —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º–∏"""
    timeframe_minutes = {
        '15m': 15, '30m': 30, '1h': 60, '4h': 240, '1d': 1440
    }
    
    return timeframe_minutes[main_tf] // timeframe_minutes[lower_tf]
```

## üìä –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ü–µ–Ω–∫–∏

### –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã–±–æ—Ä–∞ (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –≤–µ—Å–∞):
- **–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å (35%)** - —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ä–∞–∑–¥–µ–ª—è—Ç—å —Ä—ã–Ω–æ—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã
- **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≤–æ –≤—Ä–µ–º–µ–Ω–∏ (25%)** - —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–∞—Ö
- **–†–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å (20%)** - —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —à—É–º—É –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (15%)** - —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã
- **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å (5%)** - –ø–æ–Ω—è—Ç–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
- **–ù–µ–¥–µ–ª—è 1:** –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö + —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫
- **–ù–µ–¥–µ–ª—è 2:** –†–µ–∞–ª–∏–∑–∞—Ü–∏—è improved validation (Purged Walk-Forward)
- **–ù–µ–¥–µ–ª—è 3:** –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏ —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç–∏
- **–ù–µ–¥–µ–ª—è 4:** –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ —Ä–µ—à–µ–Ω–∏—è

## üí° –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã

1. **–°–º–µ—Å—Ç–∏—Ç–µ —Ñ–æ–∫—É—Å** —Å —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫—É—é –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å
2. **–£—Å–∏–ª—å—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é** —á–µ—Ä–µ–∑ Purged Walk-Forward –∏ –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
3. **–î–æ–±–∞–≤—å—Ç–µ –∞–Ω–∞–ª–∏–∑ –µ–º–∫–æ—Å—Ç–∏** –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏
4. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥** –∫ –º—É–ª—å—Ç–∏—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤–æ–º—É –∞–Ω–∞–ª–∏–∑—É

---

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 24.10.2025  
**–ê–≤—Ç–æ—Ä:** AI Assistant  
**–°—Ç–∞—Ç—É—Å:** –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** –í—ã—Å–æ–∫–∏–π
