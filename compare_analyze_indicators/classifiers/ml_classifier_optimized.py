"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
–£–ª—É—á—à–µ–Ω–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
from sklearn.mixture import GaussianMixture
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')


class OptimizedMarketRegimeMLClassifier:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏"""
    
    def __init__(self, n_clusters=4, method='kmeans'):
        self.n_clusters = n_clusters
        self.method = method
        self.scaler = StandardScaler()
        self.model = None
        self.feature_names = []
        self.cluster_labels = []
        self.regime_names = {}
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        if method == 'kmeans':
            # –£–ª—É—á—à–µ–Ω–Ω—ã–π KMeans —Å –ª—É—á—à–µ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π
            self.model = KMeans(
                n_clusters=n_clusters, 
                random_state=42, 
                n_init=20,  # –ë–æ–ª—å—à–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–π
                max_iter=300,  # –ë–æ–ª—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π
                init='k-means++'  # –õ—É—á—à–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            )
        elif method == 'dbscan':
            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π DBSCAN - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±—É–¥—É—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            self.model = None  # –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –ø–æ–∑–∂–µ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        elif method == 'gmm':
            # –£–ª—É—á—à–µ–Ω–Ω—ã–π GMM
            self.model = GaussianMixture(
                n_components=n_clusters, 
                random_state=42,
                covariance_type='full',  # –ü–æ–ª–Ω–∞—è –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
                max_iter=200,
                init_params='kmeans'  # K-means –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            )
        
        print(f"‚úÖ OptimizedMarketRegimeMLClassifier –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
        print(f"ü§ñ –ú–µ—Ç–æ–¥ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {method.upper()}")
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {n_clusters}")
    
    def extract_classification_features(self, data):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        print("üîç –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)...")
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ data - —ç—Ç–æ DataFrame
        if not isinstance(data, pd.DataFrame):
            print("‚ö†Ô∏è –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ DataFrame")
            data = pd.DataFrame(data)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        required_columns = ['open', 'high', 'low', 'close']
        if not all(col in data.columns for col in required_columns):
            print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {list(data.columns)}")
            # –ï—Å–ª–∏ —ç—Ç–æ numpy array, —Å–æ–∑–¥–∞–µ–º DataFrame —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
            if isinstance(data, np.ndarray):
                data = pd.DataFrame(data, columns=['open', 'high', 'low', 'close'])
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–≤—ã–µ 4 –∫–æ–ª–æ–Ω–∫–∏ –∫–∞–∫ OHLC
                data = data.iloc[:, :4]
                data.columns = ['open', 'high', 'low', 'close']
        
        features = pd.DataFrame(index=data.index)
        
        # ===== –ì–†–£–ü–ü–ê 1: –¢–†–ï–ù–î –ò –°–ò–õ–ê (–£–õ–£–ß–®–ï–ù–ù–ê–Ø) =====
        
        # ADX - —Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        high_low = data['high'] - data['low']
        high_close = np.abs(data['high'] - data['close'].shift(1))
        low_close = np.abs(data['low'] - data['close'].shift(1))
        true_range = np.maximum(high_low, np.maximum(high_close, low_close))
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy array –≤ pandas Series
        true_range = pd.Series(true_range, index=data.index)
        atr = true_range.rolling(14).mean()
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π ADX
        plus_dm = np.where((data['high'].diff() > data['low'].diff().abs()) & (data['high'].diff() > 0), data['high'].diff(), 0)
        minus_dm = np.where((data['low'].diff().abs() > data['high'].diff()) & (data['low'].diff() < 0), data['low'].diff().abs(), 0)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy arrays –æ–±—Ä–∞—Ç–Ω–æ –≤ pandas Series
        plus_dm = pd.Series(plus_dm, index=data.index)
        minus_dm = pd.Series(minus_dm, index=data.index)
        
        plus_di = 100 * (plus_dm.rolling(14).mean() / atr)
        minus_di = 100 * (minus_dm.rolling(14).mean() / atr)
        dx = 100 * np.abs(plus_di - minus_di) / (plus_di + minus_di)
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy array –≤ pandas Series
        dx = pd.Series(dx, index=data.index)
        adx = dx.rolling(14).mean()
        
        features['adx_value'] = adx
        features['adx_trend'] = (adx > 25).astype(int)
        
        # ===== –ì–†–£–ü–ü–ê 2: –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨ (–£–õ–£–ß–®–ï–ù–ù–ê–Ø) =====
        
        # Bollinger Bands Width
        bb_period = 20
        bb_std = 2
        bb_middle = data['close'].rolling(bb_period).mean()
        bb_std_val = data['close'].rolling(bb_period).std()
        bb_upper = bb_middle + (bb_std_val * bb_std)
        bb_lower = bb_middle - (bb_std_val * bb_std)
        bb_width = (bb_upper - bb_lower) / bb_middle
        
        features['bb_width'] = bb_width
        features['bb_position'] = (data['close'] - bb_lower) / (bb_upper - bb_lower)
        
        # ATR (—É–∂–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω –≤—ã—à–µ)
        features['atr_value'] = atr
        features['atr_ratio'] = atr / data['close']
        
        # ===== –ì–†–£–ü–ü–ê 3: –ú–û–ú–ï–ù–¢–£–ú (–£–õ–£–ß–®–ï–ù–ù–ê–Ø) =====
        
        # RSI
        delta = data['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        
        features['rsi_value'] = rsi
        features['rsi_zone'] = pd.cut(rsi, bins=[0, 30, 70, 100], labels=[0, 1, 2])  # 0=oversold, 1=neutral, 2=overbought
        
        # MACD
        ema_12 = data['close'].ewm(span=12).mean()
        ema_26 = data['close'].ewm(span=26).mean()
        macd = ema_12 - ema_26
        macd_signal = macd.ewm(span=9).mean()
        macd_histogram = macd - macd_signal
        
        features['macd_value'] = macd
        features['macd_signal'] = macd_signal
        features['macd_histogram'] = macd_histogram
        
        # ===== –ì–†–£–ü–ü–ê 4: –¶–ï–ù–û–í–û–ï –î–í–ò–ñ–ï–ù–ò–ï (–ù–û–í–ê–Ø) =====
        
        # Price momentum
        features['price_momentum_5'] = data['close'].pct_change(5)
        features['price_momentum_10'] = data['close'].pct_change(10)
        features['price_momentum_20'] = data['close'].pct_change(20)
        
        # Volume (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        if 'volume' in data.columns:
            volume_ma = data['volume'].rolling(20).mean()
            features['volume_ratio'] = data['volume'] / volume_ma
        else:
            features['volume_ratio'] = 1.0  # –ó–∞–≥–ª—É—à–∫–∞
        
        # ===== –ì–†–£–ü–ü–ê 5: –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –£–†–û–í–ù–ò (–ù–û–í–ê–Ø) =====
        
        # Support/Resistance levels
        features['high_20'] = data['high'].rolling(20).max()
        features['low_20'] = data['low'].rolling(20).min()
        features['close_vs_high'] = (data['close'] - features['low_20']) / (features['high_20'] - features['low_20'])
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        features = features.fillna(method='bfill').fillna(method='ffill').fillna(0)
        
        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(features.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
        return features
    
    def _optimize_dbscan_parameters(self, features):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ DBSCAN –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
        print("üîß –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã DBSCAN...")
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features_scaled = self.scaler.fit_transform(features)
        
        # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        from sklearn.neighbors import NearestNeighbors
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ k-–≥–æ —Å–æ—Å–µ–¥–∞
        k = min(20, len(features) // 10)  # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π k
        nbrs = NearestNeighbors(n_neighbors=k).fit(features_scaled)
        distances, indices = nbrs.kneighbors(features_scaled)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        distances = np.sort(distances[:, k-1])
        
        # –ù–∞—Ö–æ–¥–∏–º "–ª–æ–∫–æ—Ç—å" –≤ –∫—Ä–∏–≤–æ–π —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º 75-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –∫–∞–∫ eps
        eps = np.percentile(distances, 75)
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
        min_samples = max(5, len(features) // 100)
        
        print(f"üìä –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã DBSCAN: eps={eps:.4f}, min_samples={min_samples}")
        
        return DBSCAN(eps=eps, min_samples=min_samples)
    
    def _improved_cluster_interpretation(self, features, cluster_labels):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        print("üìä –£–ª—É—á—à–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")
        
        regime_names = {}
        unique_labels = np.unique(cluster_labels)
        
        for label in unique_labels:
            if label == -1:  # Noise –¥–ª—è DBSCAN
                regime_names[label] = "Noise"
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞
            cluster_mask = cluster_labels == label
            cluster_features = features[cluster_mask]
            
            if len(cluster_features) == 0:
                regime_names[label] = "Empty"
                continue
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            avg_rsi = cluster_features['rsi_value'].mean() if 'rsi_value' in cluster_features.columns else 50
            avg_momentum = cluster_features['price_momentum_5'].mean() if 'price_momentum_5' in cluster_features.columns else 0
            avg_adx = cluster_features['adx_value'].mean() if 'adx_value' in cluster_features.columns else 0
            avg_bb_position = cluster_features['bb_position'].mean() if 'bb_position' in cluster_features.columns else 0.5
            
            # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            regime_score = 0
            
            # RSI –∞–Ω–∞–ª–∏–∑
            if avg_rsi > 70:
                regime_score += 2  # –°–∏–ª—å–Ω—ã–π –±—ã—á–∏–π —Å–∏–≥–Ω–∞–ª
            elif avg_rsi > 60:
                regime_score += 1  # –°–ª–∞–±—ã–π –±—ã—á–∏–π —Å–∏–≥–Ω–∞–ª
            elif avg_rsi < 30:
                regime_score -= 2  # –°–∏–ª—å–Ω—ã–π –º–µ–¥–≤–µ–∂–∏–π —Å–∏–≥–Ω–∞–ª
            elif avg_rsi < 40:
                regime_score -= 1  # –°–ª–∞–±—ã–π –º–µ–¥–≤–µ–∂–∏–π —Å–∏–≥–Ω–∞–ª
            
            # Momentum –∞–Ω–∞–ª–∏–∑
            if avg_momentum > 0.02:  # 2% —Ä–æ—Å—Ç
                regime_score += 2
            elif avg_momentum > 0.01:  # 1% —Ä–æ—Å—Ç
                regime_score += 1
            elif avg_momentum < -0.02:  # 2% –ø–∞–¥–µ–Ω–∏–µ
                regime_score -= 2
            elif avg_momentum < -0.01:  # 1% –ø–∞–¥–µ–Ω–∏–µ
                regime_score -= 1
            
            # ADX –∞–Ω–∞–ª–∏–∑ (—Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞)
            if avg_adx > 30:
                regime_score *= 1.5  # –£—Å–∏–ª–∏–≤–∞–µ–º —Å–∏–≥–Ω–∞–ª –ø—Ä–∏ —Å–∏–ª—å–Ω–æ–º —Ç—Ä–µ–Ω–¥–µ
            elif avg_adx < 15:
                regime_score *= 0.5  # –û—Å–ª–∞–±–ª—è–µ–º —Å–∏–≥–Ω–∞–ª –ø—Ä–∏ —Å–ª–∞–±–æ–º —Ç—Ä–µ–Ω–¥–µ
            
            # Bollinger Bands –ø–æ–∑–∏—Ü–∏—è
            if avg_bb_position > 0.8:
                regime_score += 1  # –ë–ª–∏–∑–∫–æ –∫ –≤–µ—Ä—Ö–Ω–µ–π –ø–æ–ª–æ—Å–µ
            elif avg_bb_position < 0.2:
                regime_score -= 1  # –ë–ª–∏–∑–∫–æ –∫ –Ω–∏–∂–Ω–µ–π –ø–æ–ª–æ—Å–µ
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º
            if regime_score >= 3:
                regime_names[label] = "Strong Bull"
            elif regime_score >= 1:
                regime_names[label] = "Bull"
            elif regime_score <= -3:
                regime_names[label] = "Strong Bear"
            elif regime_score <= -1:
                regime_names[label] = "Bear"
            else:
                regime_names[label] = "Sideways"
        
        return regime_names
    
    def fit(self, data):
        """–û–±—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
        print("ü§ñ –û–±—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = self.extract_classification_features(data)
        self.feature_names = features.columns.tolist()
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features_scaled = self.scaler.fit_transform(features)
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç–æ–¥–∞
        if self.method == 'dbscan':
            self.model = self._optimize_dbscan_parameters(features)
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        if self.method == 'gmm':
            self.model.fit(features_scaled)
            self.cluster_labels = self.model.predict(features_scaled)
        else:
            self.cluster_labels = self.model.fit_predict(features_scaled)
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã
        self.regime_names = self._improved_cluster_interpretation(features, self.cluster_labels)
        
        print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π ML-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±—É—á–µ–Ω!")
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {len(np.unique(self.cluster_labels))}")
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        for label, regime in self.regime_names.items():
            print(f"   –ö–ª–∞—Å—Ç–µ—Ä {label}: {regime}")
        
        return self
    
    def predict(self, data):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤"""
        print("üîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤...")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = self.extract_classification_features(data)
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features_scaled = self.scaler.transform(features)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã
        if self.method == 'dbscan':
            # DBSCAN –Ω–µ –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥–∞ predict, –∏—Å–ø–æ–ª—å–∑—É–µ–º fit_predict –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            cluster_predictions = self.model.fit_predict(features_scaled)
        else:
            cluster_predictions = self.model.predict(features_scaled)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã –≤ —Ä–µ–∂–∏–º—ã
        predictions = []
        for cluster in cluster_predictions:
            if cluster in self.regime_names:
                regime = self.regime_names[cluster]
                if regime in ["Strong Bull", "Bull"]:
                    predictions.append(1)
                elif regime in ["Strong Bear", "Bear"]:
                    predictions.append(-1)
                else:
                    predictions.append(0)
            else:
                predictions.append(0)
        
        print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ {len(predictions)} —Ä–µ–∂–∏–º–æ–≤")
        return np.array(predictions)
    
    def fit_predict(self, data):
        """–û–±—É—á–∞–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏ —Å—Ä–∞–∑—É –¥–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        self.fit(data)
        return self.predict(data)
