{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05. ÐœÑƒÐ»ÑŒÑ‚Ð¸Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð²Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·\n",
        "\n",
        "## Ð¦ÐµÐ»ÑŒ\n",
        "Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð²Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð² Ð¼ÐµÐ¶Ð´Ñƒ Ñ€Ð°Ð·Ð½Ñ‹Ð¼Ð¸ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð°Ð¼Ð¸.\n",
        "\n",
        "## Ð—Ð°Ð´Ð°Ñ‡Ð¸\n",
        "1. Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð²ÑÐµÑ… Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð² (15m, 30m, 1h, 4h, 1d)\n",
        "2. Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð· ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²\n",
        "3. Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Lead/Lag Ð°Ð½Ð°Ð»Ð¸Ð·\n",
        "4. Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸ÐµÑ€Ð°Ñ€Ñ…Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð²\n",
        "5. Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ðº Ð½Ð°ÑˆÐ¸Ð¼ Ð¼Ð¾Ð´ÑƒÐ»ÑÐ¼\n",
        "sys.path.append('../evaluation')\n",
        "sys.path.append('../classifiers')\n",
        "\n",
        "from economic_metrics import EconomicMetrics\n",
        "from classifiers import MZAClassifier\n",
        "\n",
        "print(\"Ð‘Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!\")\n",
        "print(f\"Ð¢ÐµÐºÑƒÑ‰Ð°Ñ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð²ÑÐµÑ… Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð²\n",
        "print(\"=== Ð—ÐÐ“Ð Ð£Ð—ÐšÐ Ð”ÐÐÐÐ«Ð¥ Ð”Ð›Ð¯ Ð’Ð¡Ð•Ð¥ Ð¢ÐÐ™ÐœÐ¤Ð Ð•Ð™ÐœÐžÐ’ ===\")\n",
        "\n",
        "timeframes = ['15m', '30m', '1h', '4h', '1d']\n",
        "data = {}\n",
        "\n",
        "for tf in timeframes:\n",
        "    try:\n",
        "        file_path = f'../../indicators/data_frames/df_btc_{tf}.csv'\n",
        "        df = pd.read_csv(file_path)\n",
        "        df['timestamps'] = pd.to_datetime(df['timestamps'])\n",
        "        df.set_index('timestamps', inplace=True)\n",
        "        data[tf] = df\n",
        "        print(f\"âœ… {tf}: {len(df)} Ð·Ð°Ð¿Ð¸ÑÐµÐ¹, Ð¿ÐµÑ€Ð¸Ð¾Ð´: {df.index[0]} - {df.index[-1]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ {tf}: {e}\")\n",
        "\n",
        "print(f\"\\nÐ—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(data)} Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð²\")\n",
        "print(f\"Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ñ‹: {list(data.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð´Ð»Ñ Ð²ÑÐµÑ… Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð²\n",
        "print(\"=== ÐŸÐžÐ›Ð£Ð§Ð•ÐÐ˜Ð• ÐŸÐ Ð•Ð”Ð¡ÐšÐÐ—ÐÐÐ˜Ð™ Ð”Ð›Ð¯ Ð’Ð¡Ð•Ð¥ Ð¢ÐÐ™ÐœÐ¤Ð Ð•Ð™ÐœÐžÐ’ ===\")\n",
        "\n",
        "# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ MZA ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€\n",
        "mza = MZAClassifier()\n",
        "\n",
        "# ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð°\n",
        "predictions = {}\n",
        "for tf, df in data.items():\n",
        "    try:\n",
        "        # ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ Ð½Ð° Ð¿ÐµÑ€Ð²Ñ‹Ñ… 70% Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
        "        train_size = int(len(df) * 0.7)\n",
        "        train_data = df.iloc[:train_size]\n",
        "        test_data = df.iloc[train_size:]\n",
        "        \n",
        "        # ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ Ð¸ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼\n",
        "        mza.fit(train_data)\n",
        "        pred = mza.predict(test_data)\n",
        "        predictions[tf] = pred\n",
        "        \n",
        "        print(f\"âœ… {tf}: {len(pred)} Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹\")\n",
        "        \n",
        "        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹\n",
        "        unique, counts = np.unique(pred, return_counts=True)\n",
        "        for regime, count in zip(unique, counts):\n",
        "            regime_name = {-1: 'ÐœÐµÐ´Ð²ÐµÐ¶Ð¸Ð¹', 0: 'Ð‘Ð¾ÐºÐ¾Ð²Ð¾Ð¹', 1: 'Ð‘Ñ‹Ñ‡Ð¸Ð¹'}.get(regime, f'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹_{regime}')\n",
        "            percentage = count / len(pred) * 100\n",
        "            print(f\"    {regime_name}: {count} ({percentage:.1f}%)\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð´Ð»Ñ {tf}: {e}\")\n",
        "\n",
        "print(f\"\\nÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹ Ð´Ð»Ñ {len(predictions)} Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð²\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð² Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð°Ð¼Ð¸\n",
        "print(\"=== ÐÐÐÐ›Ð˜Ð— Ð¡ÐžÐ“Ð›ÐÐ¡ÐžÐ’ÐÐÐÐžÐ¡Ð¢Ð˜ Ð¡Ð˜Ð“ÐÐÐ›ÐžÐ’ ===\")\n",
        "\n",
        "def calculate_signal_consistency(predictions_dict):\n",
        "    \"\"\"Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð² Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð°Ð¼Ð¸\"\"\"\n",
        "    timeframes = list(predictions_dict.keys())\n",
        "    consistency_matrix = pd.DataFrame(index=timeframes, columns=timeframes)\n",
        "    \n",
        "    for tf1 in timeframes:\n",
        "        for tf2 in timeframes:\n",
        "            if tf1 != tf2:\n",
        "                # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð¾Ð±Ñ‰Ð¸Ðµ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ñ‹ (ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ)\n",
        "                min_length = min(len(predictions_dict[tf1]), len(predictions_dict[tf2]))\n",
        "                pred1 = predictions_dict[tf1][:min_length]\n",
        "                pred2 = predictions_dict[tf2][:min_length]\n",
        "                \n",
        "                # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ ÐºÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸ÑŽ\n",
        "                correlation = np.corrcoef(pred1, pred2)[0, 1]\n",
        "                consistency_matrix.loc[tf1, tf2] = correlation\n",
        "            else:\n",
        "                consistency_matrix.loc[tf1, tf2] = 1.0\n",
        "    \n",
        "    return consistency_matrix\n",
        "\n",
        "# Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ñƒ ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸\n",
        "consistency_matrix = calculate_signal_consistency(predictions)\n",
        "\n",
        "print(\"ðŸ“Š ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ð° ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²:\")\n",
        "print(consistency_matrix.round(4))\n",
        "\n",
        "# ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð°Ñ€Ñ‹\n",
        "print(\"\\nðŸ”— ÐÐ°Ð¸Ð±Ð¾Ð»ÐµÐµ ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð°Ñ€Ñ‹ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð²:\")\n",
        "for tf1 in consistency_matrix.index:\n",
        "    for tf2 in consistency_matrix.columns:\n",
        "        if tf1 != tf2:\n",
        "            correlation = consistency_matrix.loc[tf1, tf2]\n",
        "            print(f\"  {tf1} â†” {tf2}: {correlation:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lead/Lag Ð°Ð½Ð°Ð»Ð¸Ð·\n",
        "print(\"=== LEAD/LAG ÐÐÐÐ›Ð˜Ð— ===\")\n",
        "\n",
        "def analyze_lead_lag(predictions_dict, reference_tf='1d'):\n",
        "    \"\"\"ÐÐ½Ð°Ð»Ð¸Ð· Ð¾Ð¿ÐµÑ€ÐµÐ¶Ð°ÑŽÑ‰Ð¸Ñ… Ð¸ Ð·Ð°Ð¿Ð°Ð·Ð´Ñ‹Ð²Ð°ÑŽÑ‰Ð¸Ñ… ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²\"\"\"\n",
        "    lead_lag_results = {}\n",
        "    \n",
        "    # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð´Ð½ÐµÐ²Ð½Ð¾Ð¹ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼ ÐºÐ°Ðº ÑÑ‚Ð°Ð»Ð¾Ð½\n",
        "    if reference_tf not in predictions_dict:\n",
        "        print(f\"âŒ Ð­Ñ‚Ð°Ð»Ð¾Ð½Ð½Ñ‹Ð¹ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼ {reference_tf} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½\")\n",
        "        return {}\n",
        "    \n",
        "    reference_predictions = predictions_dict[reference_tf]\n",
        "    \n",
        "    for tf, pred in predictions_dict.items():\n",
        "        if tf != reference_tf:\n",
        "            # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ ÐºÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸Ð¸ Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ð¼Ð¸ Ð»Ð°Ð³Ð°Ð¼Ð¸\n",
        "            lags = range(-5, 6)  # Ð¾Ñ‚ -5 Ð´Ð¾ +5 Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð¾Ð²\n",
        "            correlations = []\n",
        "            \n",
        "            for lag in lags:\n",
        "                if lag > 0:\n",
        "                    # Ð¢ÐµÐºÑƒÑ‰Ð¸Ð¹ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼ Ð¾Ð¿ÐµÑ€ÐµÐ¶Ð°ÐµÑ‚ ÑÑ‚Ð°Ð»Ð¾Ð½Ð½Ñ‹Ð¹\n",
        "                    if len(pred) > lag and len(reference_predictions) > lag:\n",
        "                        corr = np.corrcoef(pred[:-lag], reference_predictions[lag:])[0, 1]\n",
        "                    else:\n",
        "                        corr = 0\n",
        "                elif lag < 0:\n",
        "                    # Ð­Ñ‚Ð°Ð»Ð¾Ð½Ð½Ñ‹Ð¹ Ð¾Ð¿ÐµÑ€ÐµÐ¶Ð°ÐµÑ‚ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼\n",
        "                    if len(pred) > abs(lag) and len(reference_predictions) > abs(lag):\n",
        "                        corr = np.corrcoef(pred[-lag:], reference_predictions[:lag])[0, 1]\n",
        "                    else:\n",
        "                        corr = 0\n",
        "                else:\n",
        "                    # Ð‘ÐµÐ· Ð»Ð°Ð³Ð°\n",
        "                    min_length = min(len(pred), len(reference_predictions))\n",
        "                    if min_length > 0:\n",
        "                        corr = np.corrcoef(pred[:min_length], reference_predictions[:min_length])[0, 1]\n",
        "                    else:\n",
        "                        corr = 0\n",
        "                \n",
        "                correlations.append(corr)\n",
        "            \n",
        "            lead_lag_results[tf] = {\n",
        "                'lags': lags,\n",
        "                'correlations': correlations,\n",
        "                'best_lag': lags[np.argmax(correlations)],\n",
        "                'max_correlation': max(correlations)\n",
        "            }\n",
        "    \n",
        "    return lead_lag_results\n",
        "\n",
        "# Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Lead/Lag Ð°Ð½Ð°Ð»Ð¸Ð·\n",
        "lead_lag_results = analyze_lead_lag(predictions, reference_tf='1d')\n",
        "\n",
        "print(\"ðŸ“ˆ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Lead/Lag Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:\")\n",
        "for tf, result in lead_lag_results.items():\n",
        "    print(f\"  {tf}:\")\n",
        "    print(f\"    Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ Ð»Ð°Ð³: {result['best_lag']}\")\n",
        "    print(f\"    ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ ÐºÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸Ñ: {result['max_correlation']:.4f}\")\n",
        "    \n",
        "    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ‚Ð¸Ð¿ ÑÐ²ÑÐ·Ð¸\n",
        "    if result['best_lag'] > 0:\n",
        "        print(f\"    {tf} Ð¾Ð¿ÐµÑ€ÐµÐ¶Ð°ÐµÑ‚ 1d Ð½Ð° {result['best_lag']} Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð¾Ð²\")\n",
        "    elif result['best_lag'] < 0:\n",
        "        print(f\"    1d Ð¾Ð¿ÐµÑ€ÐµÐ¶Ð°ÐµÑ‚ {tf} Ð½Ð° {abs(result['best_lag'])} Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð¾Ð²\")\n",
        "    else:\n",
        "        print(f\"    {tf} ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½ÐµÐ½ Ñ 1d\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ñ‚Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð²Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°\n",
        "print(\"=== Ð’Ð˜Ð—Ð£ÐÐ›Ð˜Ð—ÐÐ¦Ð˜Ð¯ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐžÐ’ ===\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Ð“Ñ€Ð°Ñ„Ð¸Ðº 1: ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ð° ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸\n",
        "ax1 = axes[0, 0]\n",
        "sns.heatmap(consistency_matrix.astype(float), annot=True, cmap='RdYlBu_r', \n",
        "            center=0, ax=ax1, cbar_kws={'label': 'ÐšÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸Ñ'})\n",
        "ax1.set_title('ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ð° ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²')\n",
        "ax1.set_xlabel('Ð¢Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼')\n",
        "ax1.set_ylabel('Ð¢Ð°Ð¹Ð¼Ñ„Ñ€ÐµÐ¹Ð¼')\n",
        "\n",
        "# Ð“Ñ€Ð°Ñ„Ð¸Ðº 2: Lead/Lag Ð°Ð½Ð°Ð»Ð¸Ð·\n",
        "ax2 = axes[0, 1]\n",
        "for tf, result in lead_lag_results.items():\n",
        "    ax2.plot(result['lags'], result['correlations'], 'o-', label=tf, alpha=0.7)\n",
        "ax2.set_title('Lead/Lag Ð°Ð½Ð°Ð»Ð¸Ð· (Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ 1d)')\n",
        "ax2.set_xlabel('Ð›Ð°Ð³ (Ð¿ÐµÑ€Ð¸Ð¾Ð´Ñ‹)')\n",
        "ax2.set_ylabel('ÐšÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸Ñ')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Ð“Ñ€Ð°Ñ„Ð¸Ðº 3: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸Ð¸\n",
        "ax3 = axes[1, 0]\n",
        "max_correlations = [result['max_correlation'] for result in lead_lag_results.values()]\n",
        "timeframes = list(lead_lag_results.keys())\n",
        "bars = ax3.bar(timeframes, max_correlations, alpha=0.7, color='skyblue')\n",
        "ax3.set_title('ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸Ð¸ Ñ 1d')\n",
        "ax3.set_ylabel('ÐšÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸Ñ')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð½Ð° ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹\n",
        "for bar, value in zip(bars, max_correlations):\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
        "             f'{value:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Ð“Ñ€Ð°Ñ„Ð¸Ðº 4: Ð›ÑƒÑ‡ÑˆÐ¸Ðµ Ð»Ð°Ð³Ð¸\n",
        "ax4 = axes[1, 1]\n",
        "best_lags = [result['best_lag'] for result in lead_lag_results.values()]\n",
        "colors = ['green' if lag > 0 else 'red' if lag < 0 else 'gray' for lag in best_lags]\n",
        "bars = ax4.bar(timeframes, best_lags, alpha=0.7, color=colors)\n",
        "ax4.set_title('Ð›ÑƒÑ‡ÑˆÐ¸Ðµ Ð»Ð°Ð³Ð¸ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ 1d')\n",
        "ax4.set_ylabel('Ð›Ð°Ð³ (Ð¿ÐµÑ€Ð¸Ð¾Ð´Ñ‹)')\n",
        "ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð½Ð° ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹\n",
        "for bar, value in zip(bars, best_lags):\n",
        "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
        "             f'{value}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… Ð“Ñ€Ð°Ñ„Ð¸ÐºÐ¸ ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
